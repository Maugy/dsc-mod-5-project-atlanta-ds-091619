{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.299672Z",
     "start_time": "2020-01-02T04:34:20.544287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "import WebScrape_Indeed\n",
    "import WebScrape_LinkedIn\n",
    "import streamlit as st \n",
    "import terms \n",
    "import Cities \n",
    "import functions\n",
    "import time\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig\n",
    "\n",
    "import chart_studio.plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "import pydeck as pdk\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)   \n",
    "\n",
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.304507Z",
     "start_time": "2020-01-02T04:34:22.302114Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.312085Z",
     "start_time": "2020-01-02T04:34:22.306839Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.325232Z",
     "start_time": "2020-01-02T04:34:22.313992Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.335046Z",
     "start_time": "2020-01-02T04:34:22.329643Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import (make_blobs,\n",
    "                                                make_circles,\n",
    "                                                make_moons)\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('fivethirtyeight')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.343656Z",
     "start_time": "2020-01-02T04:34:22.339054Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:22.513333Z",
     "start_time": "2020-01-02T04:34:22.345712Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:23.904778Z",
     "start_time": "2020-01-02T04:34:22.514820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:36:17.050672Z",
     "start_time": "2020-01-02T04:36:17.046000Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(raw):\n",
    "    raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    raw = nltk.regexp_tokenize(raw, pattern)\n",
    "#     raw = str(raw)\n",
    "    return raw\n",
    "\n",
    "def cleanC(raw):\n",
    "#     raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    return raw\n",
    "\n",
    "def C_plus(raw):\n",
    "    Cplus = re.findall(r'(?i)\\bC\\+\\+(?!\\w)', str(raw))\n",
    "    return Cplus\n",
    "\n",
    "def C_sharp(raw):\n",
    "    Csharp = re.findall(r'(?i)\\bC\\#(?!\\w)', str(raw))\n",
    "    return Csharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.174693Z",
     "start_time": "2020-01-02T04:34:23.912401Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco, CA 94105</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kohl's</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Palo Alto, CA 94304</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title              company  \\\n",
       "0                   Data Scientist             Esurance   \n",
       "1                   DATA SCIENTIST              Walmart   \n",
       "2                   Data Scientist               Kohl's   \n",
       "3  Staff Data Scientist (GEC11903)    Walmart eCommerce   \n",
       "4               Sr. Data Scientist  Silicon Valley Bank   \n",
       "\n",
       "                  location                                        description  \\\n",
       "0  San Francisco, CA 94105  [     Summary       Esurance is looking for a ...   \n",
       "1      Sunnyvale, CA 94087  [     Position Description    Data Scientist i...   \n",
       "2       Milpitas, CA 95035  [  Interpret and apply data analyses and expla...   \n",
       "3      Sunnyvale, CA 94087  [     Position Description      Understands an...   \n",
       "4      Palo Alto, CA 94304  [       Silicon Valley Bank is the market lead...   \n",
       "\n",
       "         date  \n",
       "0  12-01-2019  \n",
       "1  12-01-2019  \n",
       "2  12-01-2019  \n",
       "3  12-01-2019  \n",
       "4  12-01-2019  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('total_data_date.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.179256Z",
     "start_time": "2020-01-02T04:34:24.176849Z"
    }
   },
   "outputs": [],
   "source": [
    "search_terms = terms.total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.186135Z",
     "start_time": "2020-01-02T04:34:24.181752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AJAX',\n",
       " 'ASP',\n",
       " 'ASP.NET',\n",
       " 'AWS',\n",
       " 'Acrobat',\n",
       " 'Airflow',\n",
       " 'Alteryx',\n",
       " 'Android',\n",
       " 'Angular',\n",
       " 'Ansible',\n",
       " 'Apache',\n",
       " 'Arduino',\n",
       " 'Atom',\n",
       " 'Azure',\n",
       " 'BSD',\n",
       " 'Bash',\n",
       " 'BigQuery',\n",
       " 'C#',\n",
       " 'C++',\n",
       " 'CSS',\n",
       " 'Caffe',\n",
       " 'Cassandra',\n",
       " 'Chef',\n",
       " 'Couchbase',\n",
       " 'CryEngine',\n",
       " 'D3',\n",
       " 'Databricks',\n",
       " 'Django',\n",
       " 'Docker',\n",
       " 'Drupal',\n",
       " 'DynamoDB',\n",
       " 'Elixir',\n",
       " 'Excel',\n",
       " 'Fastai',\n",
       " 'Firebase',\n",
       " 'Flask',\n",
       " 'GCP',\n",
       " 'Git',\n",
       " 'Google Cloud',\n",
       " 'HTML',\n",
       " 'Hadoop',\n",
       " 'Hbase',\n",
       " 'Hive',\n",
       " 'IBM',\n",
       " 'IPython',\n",
       " 'Illustrator',\n",
       " 'InDesign',\n",
       " 'IntelliJ',\n",
       " 'Java',\n",
       " 'Javascript',\n",
       " 'Julia',\n",
       " 'Jupyter',\n",
       " 'Keras',\n",
       " 'Komodo',\n",
       " 'Kubernetes',\n",
       " 'Laravel',\n",
       " 'Linux',\n",
       " 'MacOS',\n",
       " 'MariaDB',\n",
       " 'Matlab',\n",
       " 'Microsoft',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NET',\n",
       " 'NLP',\n",
       " 'NetBeans',\n",
       " 'Netsuite',\n",
       " 'NoSQL',\n",
       " 'Node',\n",
       " 'Notepad',\n",
       " 'NumPy',\n",
       " 'Objective C',\n",
       " 'Oracle',\n",
       " 'PHP',\n",
       " 'PHPStorm',\n",
       " 'PMP',\n",
       " 'Pandas',\n",
       " 'Perl',\n",
       " 'Photoshop',\n",
       " 'Pi',\n",
       " 'Pig',\n",
       " 'PostgreSQL',\n",
       " 'PowerPoint',\n",
       " 'PowerShell',\n",
       " 'Project Management',\n",
       " 'Puppet',\n",
       " 'PyCharm',\n",
       " 'PyTorch',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Rails',\n",
       " 'Raspberry',\n",
       " 'React',\n",
       " 'Ruby',\n",
       " 'RubyMine',\n",
       " 'SAP',\n",
       " 'SAS',\n",
       " 'SPSS',\n",
       " 'SQL',\n",
       " 'SQLite',\n",
       " 'Salesforce',\n",
       " 'Scala',\n",
       " 'Scikit-learn',\n",
       " 'Scrum',\n",
       " 'Shell',\n",
       " 'Spark',\n",
       " 'Spring',\n",
       " 'Sublime',\n",
       " 'Swift',\n",
       " 'Tableau',\n",
       " 'TensorFlow',\n",
       " 'TextMate',\n",
       " 'Torch',\n",
       " 'Unity',\n",
       " 'Unreal Engine',\n",
       " 'Visual Studio',\n",
       " 'Vue',\n",
       " 'Watson',\n",
       " 'WebAssembly',\n",
       " 'Windows',\n",
       " 'WordPress',\n",
       " 'XGBoost',\n",
       " 'XML',\n",
       " 'Xamarin',\n",
       " 'Xcode',\n",
       " 'Zend',\n",
       " 'iOS',\n",
       " 'jQuery',\n",
       " 'mapreduce',\n",
       " 'postgresql',\n",
       " 'sklearn']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.189599Z",
     "start_time": "2020-01-02T04:34:24.187693Z"
    }
   },
   "outputs": [],
   "source": [
    "# option = 'Data Scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.192778Z",
     "start_time": "2020-01-02T04:34:24.191088Z"
    }
   },
   "outputs": [],
   "source": [
    "# dtitle = data[data['title'].astype(str).str.contains(option)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.195993Z",
     "start_time": "2020-01-02T04:34:24.194167Z"
    }
   },
   "outputs": [],
   "source": [
    "# text = dtitle.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.200882Z",
     "start_time": "2020-01-02T04:34:24.197494Z"
    }
   },
   "outputs": [],
   "source": [
    "text = data[['title','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:24.210000Z",
     "start_time": "2020-01-02T04:34:24.202233Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   Data Scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      As a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      Be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     Summary       Esurance is looking for a ...  \n",
       "1      [     Position Description    Data Scientist i...  \n",
       "2      [  Interpret and apply data analyses and expla...  \n",
       "3      [     Position Description      Understands an...  \n",
       "4      [       Silicon Valley Bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     Description    The Senior Data Scientist...  \n",
       "18449  [     Description    The Senior Data Scientist...  \n",
       "18450  [   Data Scientists develop and apply methods ...  \n",
       "18451  [    What you’ll be doing...      As a data sc...  \n",
       "18452  [    What you’ll be doing...      Be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.152791Z",
     "start_time": "2020-01-02T04:34:24.211374Z"
    }
   },
   "outputs": [],
   "source": [
    "# desc_cleaned = []\n",
    "for word in text.description:\n",
    "    cleaned = pd.Series(clean(word))\n",
    "    text.description.append(cleaned)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.163341Z",
     "start_time": "2020-01-02T04:34:36.154826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   Data Scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      As a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      Be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     Summary       Esurance is looking for a ...  \n",
       "1      [     Position Description    Data Scientist i...  \n",
       "2      [  Interpret and apply data analyses and expla...  \n",
       "3      [     Position Description      Understands an...  \n",
       "4      [       Silicon Valley Bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     Description    The Senior Data Scientist...  \n",
       "18449  [     Description    The Senior Data Scientist...  \n",
       "18450  [   Data Scientists develop and apply methods ...  \n",
       "18451  [    What you’ll be doing...      As a data sc...  \n",
       "18452  [    What you’ll be doing...      Be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.167139Z",
     "start_time": "2020-01-02T04:34:36.164755Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.170949Z",
     "start_time": "2020-01-02T04:34:36.168712Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tech_count(text):\n",
    "#     tech_skills = []\n",
    "#     List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = [x.lower() for x in text_clean]\n",
    "\n",
    "#     for item in List2:\n",
    "#         if item in List1:\n",
    "#             tech_skills.append(item)\n",
    "#         else:\n",
    "#             None \n",
    "#     return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.362121Z",
     "start_time": "2020-01-02T04:34:36.172917Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text['description'] = [x.lower() for x in text['description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.374374Z",
     "start_time": "2020-01-02T04:34:36.364322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   data scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      as a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     summary       esurance is looking for a ...  \n",
       "1      [     position description    data scientist i...  \n",
       "2      [  interpret and apply data analyses and expla...  \n",
       "3      [     position description      understands an...  \n",
       "4      [       silicon valley bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     description    the senior data scientist...  \n",
       "18449  [     description    the senior data scientist...  \n",
       "18450  [   data scientists develop and apply methods ...  \n",
       "18451  [    what you’ll be doing...      as a data sc...  \n",
       "18452  [    what you’ll be doing...      be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.378108Z",
     "start_time": "2020-01-02T04:34:36.376044Z"
    }
   },
   "outputs": [],
   "source": [
    "# List3 = []\n",
    "# List2 = text['description']\n",
    "# for item in List2.split():\n",
    "#     List3.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.381379Z",
     "start_time": "2020-01-02T04:34:36.379559Z"
    }
   },
   "outputs": [],
   "source": [
    "# def dfcount(text):\n",
    "#     tech_skills = []\n",
    "#     List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = text['description']\n",
    "\n",
    "#     for item in List2:\n",
    "#         if item in List1:\n",
    "#             tech_skills.append(item)\n",
    "#         else:\n",
    "#             None \n",
    "#     return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.384970Z",
     "start_time": "2020-01-02T04:34:36.383119Z"
    }
   },
   "outputs": [],
   "source": [
    "new_text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.396610Z",
     "start_time": "2020-01-02T04:34:36.386482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   data scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      as a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     summary       esurance is looking for a ...  \n",
       "1      [     position description    data scientist i...  \n",
       "2      [  interpret and apply data analyses and expla...  \n",
       "3      [     position description      understands an...  \n",
       "4      [       silicon valley bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     description    the senior data scientist...  \n",
       "18449  [     description    the senior data scientist...  \n",
       "18450  [   data scientists develop and apply methods ...  \n",
       "18451  [    what you’ll be doing...      as a data sc...  \n",
       "18452  [    what you’ll be doing...      be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:36.402111Z",
     "start_time": "2020-01-02T04:34:36.398644Z"
    }
   },
   "outputs": [],
   "source": [
    "def tech_count(desc):\n",
    "    tech_skills = []\n",
    "    List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = [x.lower() for x in text_clean]\n",
    "\n",
    "#     for item in text['description']:\n",
    "    for x in desc.split():\n",
    "        if x in List1:\n",
    "            tech_skills.append(x)\n",
    "    else:\n",
    "        pass \n",
    "    return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.334715Z",
     "start_time": "2020-01-02T04:34:36.404165Z"
    }
   },
   "outputs": [],
   "source": [
    "tessy = []\n",
    "for sent in new_text['description']:\n",
    "    x = tech_count(sent)\n",
    "    y = str(x)\n",
    "    tessy.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.338970Z",
     "start_time": "2020-01-02T04:34:46.336620Z"
    }
   },
   "outputs": [],
   "source": [
    "ind = len(tessy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.343311Z",
     "start_time": "2020-01-02T04:34:46.340486Z"
    }
   },
   "outputs": [],
   "source": [
    "hmmm = pd.DataFrame(tessy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.356917Z",
     "start_time": "2020-01-02T04:34:46.350437Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "0                     ['python']\n",
       "1                             []\n",
       "2                             []\n",
       "3       ['gcp', 'nosql', 'ruby']\n",
       "4      ['sql', 'julia', 'scala']\n",
       "...                          ...\n",
       "18448                         []\n",
       "18449                      ['r']\n",
       "18450                    ['sql']\n",
       "18451                  ['linux']\n",
       "18452     ['r', 'sql', 'oracle']\n",
       "\n",
       "[18453 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.363710Z",
     "start_time": "2020-01-02T04:34:46.358508Z"
    }
   },
   "outputs": [],
   "source": [
    "hope = pd.concat([new_text, hmmm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.377365Z",
     "start_time": "2020-01-02T04:34:46.365272Z"
    }
   },
   "outputs": [],
   "source": [
    "hope = hope.rename(columns={0:'skills'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.391498Z",
     "start_time": "2020-01-02T04:34:46.378923Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[  about us    on the off chance you've though...</td>\n",
       "      <td>['sql', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist IV, Central Analytics</td>\n",
       "      <td>[     position overview    as a data scientist...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>[     minimum qualifications:     bs/ba degree...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[   company information - alto neuroscience - ...</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[      seen by indeed is a free service that c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     a million people a year die in car colli...</td>\n",
       "      <td>['python', 'jupyter', 'scikit-learn', 'pandas'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist w/ Anomaly detection, d3.js, R ...</td>\n",
       "      <td>[    job summary  data scientist bay area, ca ...</td>\n",
       "      <td>['python', 'r', 'sql', 'spark', 'gcp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[   we are looking for a  data scientist to be...</td>\n",
       "      <td>['python', 'tensorflow', 'hadoop', 'spark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     small business success begins with bette...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Principal Applied and Data Scientist</td>\n",
       "      <td>[    azure production infrastructure engineeri...</td>\n",
       "      <td>['azure', 'azure', 'azure', 'azure', 'azure', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist, WW Operations Finance</td>\n",
       "      <td>[    degree in data science, mathematics, stat...</td>\n",
       "      <td>['python', 'microsoft', 'excel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Senior Data Scientist, WW Operations Finance</td>\n",
       "      <td>[    degree in data science, mathematics, stat...</td>\n",
       "      <td>['python', 'microsoft', 'excel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    graduate degree in statistics, economics,...</td>\n",
       "      <td>['aws']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>[    azure production infrastructure engineeri...</td>\n",
       "      <td>['azure', 'microsoft', 'azure', 'azure', 'azur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist - Demand Forecasting</td>\n",
       "      <td>[    master/phd degree in machine learning, st...</td>\n",
       "      <td>['r', 'python', 'linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sr Data Scientist - Alexa Shopping</td>\n",
       "      <td>[     bachelor or master's degree in highly qu...</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[    csi analytics team in the cloud hardware ...</td>\n",
       "      <td>['microsoft', 'azure', 'azure', 'microsoft', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Siri - Data Scientist, Data Organization</td>\n",
       "      <td>[       summary    posted:  dec 6, 2019    wee...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[        \\n\\n    \\n\\n  \\n\\t  of this role incl...</td>\n",
       "      <td>['python', 'sql', 'python', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    data scientist   downtown seattle  we’re ...</td>\n",
       "      <td>['c++', 'bash', 'linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Scientist / Data Analytics</td>\n",
       "      <td>[   hi,  hope you are doing well.   **this is ...</td>\n",
       "      <td>['sql', 'sql', 'hive', 'sql', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist/Statistician - Growth</td>\n",
       "      <td>[    grade 24: sr growth analyst for ebay paid...</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>[   we are looking for a sr data scientist to ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[    puget sound energy is looking to grow our...</td>\n",
       "      <td>['nlp', 'nlp', 'python', 'tableau', 'aws', 'sap']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Scientist 3 (AP1938)</td>\n",
       "      <td>[   our client is an amazing company in bellev...</td>\n",
       "      <td>['sql', 'r', 'python', 'r', 'microsoft']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>title</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[   about ancestry:  when you join ancestry, y...</td>\n",
       "      <td>['nlp', 'nlp', 'python', 'r', 'java', 'spark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Scientist / Economist</td>\n",
       "      <td>[    looking for a company that inspires passi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lead Data Scientist - Modeling</td>\n",
       "      <td>[   disney streaming services (dss) is creatin...</td>\n",
       "      <td>['python', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  data scientist - start up environment     t...</td>\n",
       "      <td>['sql', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>[    paypal’s global data sciences team is res...</td>\n",
       "      <td>['nlp', 'sql', 'sas', 'nlp', 'scala', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>[    *if you are interested in the position pl...</td>\n",
       "      <td>['microsoft', 'ibm', 'sql', 'nosql', 'spss']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data Scientist - Lab Operations</td>\n",
       "      <td>[  23andme is seeking a talented and driven da...</td>\n",
       "      <td>['sql', 'oracle', 'r', 'git', 'java', 'html', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    with more than 165 million active users g...</td>\n",
       "      <td>['sql', 'tableau', 'hadoop', 'hadoop', 'tableau']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[   our mission:   as the world’s number 1 job...</td>\n",
       "      <td>['spark', 'mongodb', 'c++']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Data Scientist I-III, Spatial Single-Cell RNA ...</td>\n",
       "      <td>[     overview        cures start here.  at fr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Senior Data Scientist II</td>\n",
       "      <td>[   if you have a deep passion for data and se...</td>\n",
       "      <td>['spark', 'hadoop', 'javascript', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Lead Data Scientist - Experimentation</td>\n",
       "      <td>[     develop sampling and allocation methodol...</td>\n",
       "      <td>['python', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>[     about gap inc.    our past is full of ic...</td>\n",
       "      <td>['spark', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>[   if you are interested in the position plea...</td>\n",
       "      <td>['microsoft', 'ibm', 'sql', 'nosql', 'spss']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     who we are:    freedom financial network...</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[    master’s degree or foreign equivalent in ...</td>\n",
       "      <td>['sql', 'aws', 'aws', 'aws', 'aws', 'aws']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>[    conversica is the leader in conversationa...</td>\n",
       "      <td>['tensorflow', 'nosql', 'dynamodb', 'scrum']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Senior Database Engineer</td>\n",
       "      <td>[         about   out-of-pocket healthcare cos...</td>\n",
       "      <td>['react', 'sql', 'sql']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                      Data Scientist   \n",
       "1                                      DATA SCIENTIST   \n",
       "2                                      Data Scientist   \n",
       "3                     Staff Data Scientist (GEC11903)   \n",
       "4                                  Sr. Data Scientist   \n",
       "5                               Senior Data Scientist   \n",
       "6           Lead Data Scientist IV, Central Analytics   \n",
       "7                                    Data Scientist 1   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11  Data Scientist w/ Anomaly detection, d3.js, R ...   \n",
       "12                                     Data Scientist   \n",
       "13                              Senior Data Scientist   \n",
       "14               Principal Applied and Data Scientist   \n",
       "15              Data Scientist, WW Operations Finance   \n",
       "16       Senior Data Scientist, WW Operations Finance   \n",
       "17                                     Data Scientist   \n",
       "18                                  Data Scientist II   \n",
       "19                Data Scientist - Demand Forecasting   \n",
       "20                 Sr Data Scientist - Alexa Shopping   \n",
       "21                              Senior Data Scientist   \n",
       "22           Siri - Data Scientist, Data Organization   \n",
       "23                                     Data Scientist   \n",
       "24                                     Data Scientist   \n",
       "25                    Data Scientist / Data Analytics   \n",
       "26               Data Scientist/Statistician - Growth   \n",
       "27           Data Scientist/Machine Learning Engineer   \n",
       "28                              Senior Data Scientist   \n",
       "29                          Data Scientist 3 (AP1938)   \n",
       "30                                              title   \n",
       "31                                     Data Scientist   \n",
       "32                         Data Scientist / Economist   \n",
       "33                     Lead Data Scientist - Modeling   \n",
       "34                                     Data Scientist   \n",
       "35                                Lead Data Scientist   \n",
       "36                                Lead Data Scientist   \n",
       "37                    Data Scientist - Lab Operations   \n",
       "38                                     Data Scientist   \n",
       "39                              Senior Data Scientist   \n",
       "40  Data Scientist I-III, Spatial Single-Cell RNA ...   \n",
       "41                           Senior Data Scientist II   \n",
       "42              Lead Data Scientist - Experimentation   \n",
       "43                           Associate Data Scientist   \n",
       "44                                Lead Data Scientist   \n",
       "45                                     DATA SCIENTIST   \n",
       "46                              Senior Data Scientist   \n",
       "47                              Senior Data Scientist   \n",
       "48                                Lead Data Scientist   \n",
       "49                           Senior Database Engineer   \n",
       "\n",
       "                                          description  \\\n",
       "0   [     summary       esurance is looking for a ...   \n",
       "1   [     position description    data scientist i...   \n",
       "2   [  interpret and apply data analyses and expla...   \n",
       "3   [     position description      understands an...   \n",
       "4   [       silicon valley bank is the market lead...   \n",
       "5   [  about us    on the off chance you've though...   \n",
       "6   [     position overview    as a data scientist...   \n",
       "7   [     minimum qualifications:     bs/ba degree...   \n",
       "8   [   company information - alto neuroscience - ...   \n",
       "9   [      seen by indeed is a free service that c...   \n",
       "10  [     a million people a year die in car colli...   \n",
       "11  [    job summary  data scientist bay area, ca ...   \n",
       "12  [   we are looking for a  data scientist to be...   \n",
       "13  [     small business success begins with bette...   \n",
       "14  [    azure production infrastructure engineeri...   \n",
       "15  [    degree in data science, mathematics, stat...   \n",
       "16  [    degree in data science, mathematics, stat...   \n",
       "17  [    graduate degree in statistics, economics,...   \n",
       "18  [    azure production infrastructure engineeri...   \n",
       "19  [    master/phd degree in machine learning, st...   \n",
       "20  [     bachelor or master's degree in highly qu...   \n",
       "21  [    csi analytics team in the cloud hardware ...   \n",
       "22  [       summary    posted:  dec 6, 2019    wee...   \n",
       "23  [        \\n\\n    \\n\\n  \\n\\t  of this role incl...   \n",
       "24  [    data scientist   downtown seattle  we’re ...   \n",
       "25  [   hi,  hope you are doing well.   **this is ...   \n",
       "26  [    grade 24: sr growth analyst for ebay paid...   \n",
       "27  [   we are looking for a sr data scientist to ...   \n",
       "28  [    puget sound energy is looking to grow our...   \n",
       "29  [   our client is an amazing company in bellev...   \n",
       "30                                        description   \n",
       "31  [   about ancestry:  when you join ancestry, y...   \n",
       "32  [    looking for a company that inspires passi...   \n",
       "33  [   disney streaming services (dss) is creatin...   \n",
       "34  [  data scientist - start up environment     t...   \n",
       "35  [    paypal’s global data sciences team is res...   \n",
       "36  [    *if you are interested in the position pl...   \n",
       "37  [  23andme is seeking a talented and driven da...   \n",
       "38  [    with more than 165 million active users g...   \n",
       "39  [   our mission:   as the world’s number 1 job...   \n",
       "40  [     overview        cures start here.  at fr...   \n",
       "41  [   if you have a deep passion for data and se...   \n",
       "42  [     develop sampling and allocation methodol...   \n",
       "43  [     about gap inc.    our past is full of ic...   \n",
       "44  [   if you are interested in the position plea...   \n",
       "45  [     position description    data scientist i...   \n",
       "46  [     who we are:    freedom financial network...   \n",
       "47  [    master’s degree or foreign equivalent in ...   \n",
       "48  [    conversica is the leader in conversationa...   \n",
       "49  [         about   out-of-pocket healthcare cos...   \n",
       "\n",
       "                                               skills  \n",
       "0                                          ['python']  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                            ['gcp', 'nosql', 'ruby']  \n",
       "4                           ['sql', 'julia', 'scala']  \n",
       "5                                   ['sql', 'python']  \n",
       "6                                                  []  \n",
       "7                                                  []  \n",
       "8                                          ['python']  \n",
       "9                                                  []  \n",
       "10  ['python', 'jupyter', 'scikit-learn', 'pandas'...  \n",
       "11             ['python', 'r', 'sql', 'spark', 'gcp']  \n",
       "12        ['python', 'tensorflow', 'hadoop', 'spark']  \n",
       "13                                                 []  \n",
       "14  ['azure', 'azure', 'azure', 'azure', 'azure', ...  \n",
       "15                   ['python', 'microsoft', 'excel']  \n",
       "16                   ['python', 'microsoft', 'excel']  \n",
       "17                                            ['aws']  \n",
       "18  ['azure', 'microsoft', 'azure', 'azure', 'azur...  \n",
       "19                           ['r', 'python', 'linux']  \n",
       "20                                            ['sql']  \n",
       "21  ['microsoft', 'azure', 'azure', 'microsoft', '...  \n",
       "22                                                 []  \n",
       "23                 ['python', 'sql', 'python', 'sql']  \n",
       "24                           ['c++', 'bash', 'linux']  \n",
       "25            ['sql', 'sql', 'hive', 'sql', 'python']  \n",
       "26                                            ['sql']  \n",
       "27                                                 []  \n",
       "28  ['nlp', 'nlp', 'python', 'tableau', 'aws', 'sap']  \n",
       "29           ['sql', 'r', 'python', 'r', 'microsoft']  \n",
       "30                                                 []  \n",
       "31     ['nlp', 'nlp', 'python', 'r', 'java', 'spark']  \n",
       "32                                                 []  \n",
       "33                               ['python', 'python']  \n",
       "34                                  ['sql', 'python']  \n",
       "35       ['nlp', 'sql', 'sas', 'nlp', 'scala', 'sql']  \n",
       "36       ['microsoft', 'ibm', 'sql', 'nosql', 'spss']  \n",
       "37  ['sql', 'oracle', 'r', 'git', 'java', 'html', ...  \n",
       "38  ['sql', 'tableau', 'hadoop', 'hadoop', 'tableau']  \n",
       "39                        ['spark', 'mongodb', 'c++']  \n",
       "40                                                 []  \n",
       "41           ['spark', 'hadoop', 'javascript', 'sql']  \n",
       "42                               ['python', 'python']  \n",
       "43                                   ['spark', 'sql']  \n",
       "44       ['microsoft', 'ibm', 'sql', 'nosql', 'spss']  \n",
       "45                           ['gcp', 'nosql', 'ruby']  \n",
       "46                                         ['python']  \n",
       "47         ['sql', 'aws', 'aws', 'aws', 'aws', 'aws']  \n",
       "48       ['tensorflow', 'nosql', 'dynamodb', 'scrum']  \n",
       "49                            ['react', 'sql', 'sql']  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.397983Z",
     "start_time": "2020-01-02T04:34:46.393658Z"
    }
   },
   "outputs": [],
   "source": [
    "hope2 = hope[['title','skills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.411513Z",
     "start_time": "2020-01-02T04:34:46.400378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                          skills  \n",
       "0                     ['python']  \n",
       "1                             []  \n",
       "2                             []  \n",
       "3       ['gcp', 'nosql', 'ruby']  \n",
       "4      ['sql', 'julia', 'scala']  \n",
       "...                          ...  \n",
       "18448                         []  \n",
       "18449                      ['r']  \n",
       "18450                    ['sql']  \n",
       "18451                  ['linux']  \n",
       "18452     ['r', 'sql', 'oracle']  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.416852Z",
     "start_time": "2020-01-02T04:34:46.414149Z"
    }
   },
   "outputs": [],
   "source": [
    "# tech_list = tech_count(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.425873Z",
     "start_time": "2020-01-02T04:34:46.419280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unique_data = []\n",
    "# for i in range(len(data)):\n",
    "#     if data['description'][i] not in unique_data:\n",
    "#         unique_data.append(data['description'][i])\n",
    "#         if i % 5000 == 0:\n",
    "#             print('{0}'.format(i)+' lines have been processed')\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = text.lower() #convert all the chracters into small letters\n",
    "#     text = re.sub(r\"i'm\", \"i am\", text)\n",
    "#     text = re.sub(r\"he's\", \"he is\", text)\n",
    "#     text = re.sub(r\"she's\", \"she is\", text)\n",
    "#     text = re.sub(r\"that's\", \"that is\", text)\n",
    "#     text = re.sub(r\"what's\", \"what is\", text)\n",
    "#     text = re.sub(r\"where's\", \"where is\", text)\n",
    "#     text = re.sub(r\"how's\", \"how is\", text)\n",
    "#     text = re.sub(r\"\\'ve\", \"have\", text)\n",
    "#     text = re.sub(r\"\\'ll\", \"will\", text)\n",
    "#     text = re.sub(r\"\\'re\", \"are\", text)\n",
    "#     text = re.sub(r\"\\'d\", \"would\", text)\n",
    "#     text = re.sub(r\"n't\", \"not\", text)\n",
    "#     text = re.sub(r\"won't\", \"will not\", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot\", text)\n",
    "#     text = re.sub(r\"[-()\\\"#/@;:<>{}'+=|.!?,]\", \"\", text)\n",
    "#     text = text.replace(\"[\", \"\")\n",
    "#     text = text.replace(\"]\", \"\")\n",
    "#     return text\n",
    "\n",
    "# unique_data_str = []\n",
    "# for i in range(len(unique_data)):\n",
    "#     if type(unique_data[i]) is str:\n",
    "#         unique_data_str.append(unique_data[i])\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "# # Cleaning the data\n",
    "# clean_data = []\n",
    "# for text in unique_data_str:\n",
    "#     a = re.sub(r'[^a-zA-z ]+', '', text).strip()\n",
    "#     if len(a)>0:\n",
    "#         clean_data.append(clean_text(a))\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "# # Removing the lines which are to short or to long\n",
    "# short_data = []\n",
    "# for line in clean_data:\n",
    "#     if 2 <= len(line.split()):\n",
    "#         short_data.append(line)\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "# # Counting the appearnce of each word in the corpus also calculates the number of unique words also\n",
    "# word2count = {}\n",
    "# total_words = 0\n",
    "# for text in clean_data:\n",
    "#     for word in text.split():\n",
    "#         if word not in word2count:\n",
    "#             word2count[word] = 1\n",
    "#         else:\n",
    "#             word2count[word] += 1\n",
    "#         total_words += 1\n",
    "        \n",
    "# # creating a list that will only contain the words that appear more than 15 times\n",
    "# word10 = []\n",
    "# threshold = 10\n",
    "# for word, count in word2count.items():\n",
    "#     if count >= threshold:\n",
    "#         if len(word) > 1:\n",
    "#             word10.append(word)\n",
    "            \n",
    "# # Removing the words from each string which appear less than 15 times\n",
    "# data10 = []\n",
    "# for line in short_data:\n",
    "#     str1=''\n",
    "#     for word in line.split():\n",
    "#         if word in word10:\n",
    "#             str1 = \" \".join((str1, word))\n",
    "#     data10.append(str1)\n",
    "\n",
    "# # Removing the lines which are to short or to long after removing the unnecssary words.     \n",
    "# short_data_consize = []\n",
    "# for line in data10:\n",
    "#     if 3 <= len(line.split()):\n",
    "#         short_data_consize.append(line)\n",
    "#     else:\n",
    "#         None\n",
    "        \n",
    "# clean_unique_data = []\n",
    "# for i in range(len(short_data_consize)):\n",
    "#     if short_data_consize[i] not in clean_unique_data:\n",
    "#         clean_unique_data.append(short_data_consize[i])\n",
    "#     else:\n",
    "#         None\n",
    "        \n",
    "# # # Total number of words in corpus after removing the words which appears less than 15 times and further cleaning\n",
    "# total_words_d10 = 0\n",
    "# for line in data10:\n",
    "#     for word in line.split():\n",
    "#         total_words_d10 += 1 \n",
    "# # # \"\"\" Initially we had 437579 lines in our data after cleaning and preprocessing the data\n",
    "# #     now our complete data will have 126003 lines, that means we removed 71.20% data which was useless\"\"\"   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.432364Z",
     "start_time": "2020-01-02T04:34:46.428303Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = hope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.437896Z",
     "start_time": "2020-01-02T04:34:46.434864Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english') + list(string.punctuation)\n",
    "# stop += [\"''\", '\"\"', '...', '``','--','and','a','an','of']\n",
    "\n",
    "# new_data = []\n",
    "# for word in str(data).split():\n",
    "#     if word not in stop:\n",
    "#         new_data.append(word)\n",
    "        \n",
    "# # data = data.map(word_tokenize).values\n",
    "# # tokens = str(data).split()\n",
    "# # stopwords_removed = [token for token in tokens if token not in stop]\n",
    "# # stopwords_removed = [x for x in data if x not in stop]\n",
    "# # data = data.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.446153Z",
     "start_time": "2020-01-02T04:34:46.440297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18453"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.459603Z",
     "start_time": "2020-01-02T04:34:46.449265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                          skills  \n",
       "0                     ['python']  \n",
       "1                             []  \n",
       "2                             []  \n",
       "3       ['gcp', 'nosql', 'ruby']  \n",
       "4      ['sql', 'julia', 'scala']  \n",
       "...                          ...  \n",
       "18448                         []  \n",
       "18449                      ['r']  \n",
       "18450                    ['sql']  \n",
       "18451                  ['linux']  \n",
       "18452     ['r', 'sql', 'oracle']  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.464436Z",
     "start_time": "2020-01-02T04:34:46.461768Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean_again = []\n",
    "# for text in new_data:\n",
    "#     a = re.sub(r'[^a-zA-z ]+', '', text).strip()\n",
    "#     if len(a)>0:\n",
    "#         clean_again.append(clean_text(a))\n",
    "#     else:\n",
    "#         pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:34:46.468797Z",
     "start_time": "2020-01-02T04:34:46.466506Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(clean_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:35:25.868975Z",
     "start_time": "2020-01-02T04:35:25.865749Z"
    }
   },
   "outputs": [],
   "source": [
    "data = new_data['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:35:26.559931Z",
     "start_time": "2020-01-02T04:35:26.556949Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = clean_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:35:27.009700Z",
     "start_time": "2020-01-02T04:35:27.007489Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = str(data).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:36:51.511142Z",
     "start_time": "2020-01-02T04:36:51.485602Z"
    }
   },
   "outputs": [],
   "source": [
    "data = clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:36:52.370993Z",
     "start_time": "2020-01-02T04:36:52.228825Z"
    }
   },
   "outputs": [],
   "source": [
    "train_len = 3+1\n",
    "text_sequences = []\n",
    "for i in range(train_len,len(data)):\n",
    "    seq = data[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "\n",
    "sequences = {}\n",
    "count = 1\n",
    "for i in range(len(data)):\n",
    "    if data[i] not in sequences:\n",
    "        sequences[data[i]] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:36:54.378749Z",
     "start_time": "2020-01-02T04:36:54.328278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['python', 'gcp', 'nosql', 'ruby'],\n",
       " ['gcp', 'nosql', 'ruby', 'sql'],\n",
       " ['nosql', 'ruby', 'sql', 'julia'],\n",
       " ['ruby', 'sql', 'julia', 'scala'],\n",
       " ['sql', 'julia', 'scala', 'sql'],\n",
       " ['julia', 'scala', 'sql', 'python'],\n",
       " ['scala', 'sql', 'python', 'python'],\n",
       " ['sql', 'python', 'python', 'python'],\n",
       " ['python', 'python', 'python', 'jupyter'],\n",
       " ['python', 'python', 'jupyter', 'scikit'],\n",
       " ['python', 'jupyter', 'scikit', 'learn'],\n",
       " ['jupyter', 'scikit', 'learn', 'pandas'],\n",
       " ['scikit', 'learn', 'pandas', 'numpy'],\n",
       " ['learn', 'pandas', 'numpy', 'pandas'],\n",
       " ['pandas', 'numpy', 'pandas', 'numpy'],\n",
       " ['numpy', 'pandas', 'numpy', 'sas'],\n",
       " ['pandas', 'numpy', 'sas', 'python'],\n",
       " ['numpy', 'sas', 'python', 'r'],\n",
       " ['sas', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'spark'],\n",
       " ['r', 'sql', 'spark', 'gcp'],\n",
       " ['sql', 'spark', 'gcp', 'python'],\n",
       " ['spark', 'gcp', 'python', 'tensorflow'],\n",
       " ['gcp', 'python', 'tensorflow', 'hadoop'],\n",
       " ['python', 'tensorflow', 'hadoop', 'spark'],\n",
       " ['tensorflow', 'hadoop', 'spark', 'azure'],\n",
       " ['hadoop', 'spark', 'azure', 'azure'],\n",
       " ['spark', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'microsoft'],\n",
       " ['azure', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'azure'],\n",
       " ['microsoft', 'microsoft', 'azure', 'azure'],\n",
       " ['microsoft', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'microsoft'],\n",
       " ['azure', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'python'],\n",
       " ['microsoft', 'microsoft', 'python', 'microsoft'],\n",
       " ['microsoft', 'python', 'microsoft', 'excel'],\n",
       " ['python', 'microsoft', 'excel', 'python'],\n",
       " ['microsoft', 'excel', 'python', 'microsoft'],\n",
       " ['excel', 'python', 'microsoft', 'excel'],\n",
       " ['python', 'microsoft', 'excel', 'aws'],\n",
       " ['microsoft', 'excel', 'aws', 'azure'],\n",
       " ['excel', 'aws', 'azure', 'microsoft'],\n",
       " ['aws', 'azure', 'microsoft', 'azure'],\n",
       " ['azure', 'microsoft', 'azure', 'azure'],\n",
       " ['microsoft', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'microsoft'],\n",
       " ['azure', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'r'],\n",
       " ['microsoft', 'microsoft', 'r', 'python'],\n",
       " ['microsoft', 'r', 'python', 'linux'],\n",
       " ['r', 'python', 'linux', 'sql'],\n",
       " ['python', 'linux', 'sql', 'microsoft'],\n",
       " ['linux', 'sql', 'microsoft', 'azure'],\n",
       " ['sql', 'microsoft', 'azure', 'azure'],\n",
       " ['microsoft', 'azure', 'azure', 'microsoft'],\n",
       " ['azure', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'azure'],\n",
       " ['microsoft', 'microsoft', 'azure', 'microsoft'],\n",
       " ['microsoft', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'azure'],\n",
       " ['microsoft', 'microsoft', 'azure', 'azure'],\n",
       " ['microsoft', 'azure', 'azure', 'microsoft'],\n",
       " ['azure', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'python'],\n",
       " ['microsoft', 'microsoft', 'python', 'sql'],\n",
       " ['microsoft', 'python', 'sql', 'python'],\n",
       " ['python', 'sql', 'python', 'sql'],\n",
       " ['sql', 'python', 'sql', 'c'],\n",
       " ['python', 'sql', 'c', 'bash'],\n",
       " ['sql', 'c', 'bash', 'linux'],\n",
       " ['c', 'bash', 'linux', 'sql'],\n",
       " ['bash', 'linux', 'sql', 'sql'],\n",
       " ['linux', 'sql', 'sql', 'hive'],\n",
       " ['sql', 'sql', 'hive', 'sql'],\n",
       " ['sql', 'hive', 'sql', 'python'],\n",
       " ['hive', 'sql', 'python', 'sql'],\n",
       " ['sql', 'python', 'sql', 'nlp'],\n",
       " ['python', 'sql', 'nlp', 'nlp'],\n",
       " ['sql', 'nlp', 'nlp', 'python'],\n",
       " ['nlp', 'nlp', 'python', 'tableau'],\n",
       " ['nlp', 'python', 'tableau', 'aws'],\n",
       " ['python', 'tableau', 'aws', 'sap'],\n",
       " ['tableau', 'aws', 'sap', 'sql'],\n",
       " ['aws', 'sap', 'sql', 'r'],\n",
       " ['sap', 'sql', 'r', 'python'],\n",
       " ['sql', 'r', 'python', 'r'],\n",
       " ['r', 'python', 'r', 'microsoft'],\n",
       " ['python', 'r', 'microsoft', 'nlp'],\n",
       " ['r', 'microsoft', 'nlp', 'nlp'],\n",
       " ['microsoft', 'nlp', 'nlp', 'python'],\n",
       " ['nlp', 'nlp', 'python', 'r'],\n",
       " ['nlp', 'python', 'r', 'java'],\n",
       " ['python', 'r', 'java', 'spark'],\n",
       " ['r', 'java', 'spark', 'python'],\n",
       " ['java', 'spark', 'python', 'python'],\n",
       " ['spark', 'python', 'python', 'sql'],\n",
       " ['python', 'python', 'sql', 'python'],\n",
       " ['python', 'sql', 'python', 'nlp'],\n",
       " ['sql', 'python', 'nlp', 'sql'],\n",
       " ['python', 'nlp', 'sql', 'sas'],\n",
       " ['nlp', 'sql', 'sas', 'nlp'],\n",
       " ['sql', 'sas', 'nlp', 'scala'],\n",
       " ['sas', 'nlp', 'scala', 'sql'],\n",
       " ['nlp', 'scala', 'sql', 'microsoft'],\n",
       " ['scala', 'sql', 'microsoft', 'ibm'],\n",
       " ['sql', 'microsoft', 'ibm', 'sql'],\n",
       " ['microsoft', 'ibm', 'sql', 'nosql'],\n",
       " ['ibm', 'sql', 'nosql', 'spss'],\n",
       " ['sql', 'nosql', 'spss', 'sql'],\n",
       " ['nosql', 'spss', 'sql', 'oracle'],\n",
       " ['spss', 'sql', 'oracle', 'r'],\n",
       " ['sql', 'oracle', 'r', 'git'],\n",
       " ['oracle', 'r', 'git', 'java'],\n",
       " ['r', 'git', 'java', 'html'],\n",
       " ['git', 'java', 'html', 'django'],\n",
       " ['java', 'html', 'django', 'sql'],\n",
       " ['html', 'django', 'sql', 'tableau'],\n",
       " ['django', 'sql', 'tableau', 'hadoop'],\n",
       " ['sql', 'tableau', 'hadoop', 'hadoop'],\n",
       " ['tableau', 'hadoop', 'hadoop', 'tableau'],\n",
       " ['hadoop', 'hadoop', 'tableau', 'spark'],\n",
       " ['hadoop', 'tableau', 'spark', 'mongodb'],\n",
       " ['tableau', 'spark', 'mongodb', 'c'],\n",
       " ['spark', 'mongodb', 'c', 'spark'],\n",
       " ['mongodb', 'c', 'spark', 'hadoop'],\n",
       " ['c', 'spark', 'hadoop', 'javascript'],\n",
       " ['spark', 'hadoop', 'javascript', 'sql'],\n",
       " ['hadoop', 'javascript', 'sql', 'python'],\n",
       " ['javascript', 'sql', 'python', 'python'],\n",
       " ['sql', 'python', 'python', 'spark'],\n",
       " ['python', 'python', 'spark', 'sql'],\n",
       " ['python', 'spark', 'sql', 'microsoft'],\n",
       " ['spark', 'sql', 'microsoft', 'ibm'],\n",
       " ['sql', 'microsoft', 'ibm', 'sql'],\n",
       " ['microsoft', 'ibm', 'sql', 'nosql'],\n",
       " ['ibm', 'sql', 'nosql', 'spss'],\n",
       " ['sql', 'nosql', 'spss', 'gcp'],\n",
       " ['nosql', 'spss', 'gcp', 'nosql'],\n",
       " ['spss', 'gcp', 'nosql', 'ruby'],\n",
       " ['gcp', 'nosql', 'ruby', 'python'],\n",
       " ['nosql', 'ruby', 'python', 'sql'],\n",
       " ['ruby', 'python', 'sql', 'aws'],\n",
       " ['python', 'sql', 'aws', 'aws'],\n",
       " ['sql', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'tensorflow'],\n",
       " ['aws', 'aws', 'tensorflow', 'nosql'],\n",
       " ['aws', 'tensorflow', 'nosql', 'dynamodb'],\n",
       " ['tensorflow', 'nosql', 'dynamodb', 'scrum'],\n",
       " ['nosql', 'dynamodb', 'scrum', 'react'],\n",
       " ['dynamodb', 'scrum', 'react', 'sql'],\n",
       " ['scrum', 'react', 'sql', 'sql'],\n",
       " ['react', 'sql', 'sql', 'java'],\n",
       " ['sql', 'sql', 'java', 'spring'],\n",
       " ['sql', 'java', 'spring', 'sql'],\n",
       " ['java', 'spring', 'sql', 'mysql'],\n",
       " ['spring', 'sql', 'mysql', 'python'],\n",
       " ['sql', 'mysql', 'python', 'linux'],\n",
       " ['mysql', 'python', 'linux', 'java'],\n",
       " ['python', 'linux', 'java', 'javascript'],\n",
       " ['linux', 'java', 'javascript', 'css'],\n",
       " ['java', 'javascript', 'css', 'java'],\n",
       " ['javascript', 'css', 'java', 'spring'],\n",
       " ['css', 'java', 'spring', 'java'],\n",
       " ['java', 'spring', 'java', 'sql'],\n",
       " ['spring', 'java', 'sql', 'sql'],\n",
       " ['java', 'sql', 'sql', 'ruby'],\n",
       " ['sql', 'sql', 'ruby', 'rails'],\n",
       " ['sql', 'ruby', 'rails', 'hadoop'],\n",
       " ['ruby', 'rails', 'hadoop', 'mysql'],\n",
       " ['rails', 'hadoop', 'mysql', 'mysql'],\n",
       " ['hadoop', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'mysql'],\n",
       " ['mysql', 'mysql', 'mysql', 'chef'],\n",
       " ['mysql', 'mysql', 'chef', 'ruby'],\n",
       " ['mysql', 'chef', 'ruby', 'mysql'],\n",
       " ['chef', 'ruby', 'mysql', 'sql'],\n",
       " ['ruby', 'mysql', 'sql', 'oracle'],\n",
       " ['mysql', 'sql', 'oracle', 'oracle'],\n",
       " ['sql', 'oracle', 'oracle', 'oracle'],\n",
       " ['oracle', 'oracle', 'oracle', 'oracle'],\n",
       " ['oracle', 'oracle', 'oracle', 'oracle'],\n",
       " ['oracle', 'oracle', 'oracle', 'postgresql'],\n",
       " ['oracle', 'oracle', 'postgresql', 'postgresql'],\n",
       " ['oracle', 'postgresql', 'postgresql', 'sql'],\n",
       " ['postgresql', 'postgresql', 'sql', 'bash'],\n",
       " ['postgresql', 'sql', 'bash', 'nosql'],\n",
       " ['sql', 'bash', 'nosql', 'gcp'],\n",
       " ['bash', 'nosql', 'gcp', 'kubernetes'],\n",
       " ['nosql', 'gcp', 'kubernetes', 'kubernetes'],\n",
       " ['gcp', 'kubernetes', 'kubernetes', 'sql'],\n",
       " ['kubernetes', 'kubernetes', 'sql', 'linux'],\n",
       " ['kubernetes', 'sql', 'linux', 'bash'],\n",
       " ['sql', 'linux', 'bash', 'python'],\n",
       " ['linux', 'bash', 'python', 'aws'],\n",
       " ['bash', 'python', 'aws', 'aws'],\n",
       " ['python', 'aws', 'aws', 'sql'],\n",
       " ['aws', 'aws', 'sql', 'postgresql'],\n",
       " ['aws', 'sql', 'postgresql', 'mysql'],\n",
       " ['sql', 'postgresql', 'mysql', 'postgresql'],\n",
       " ['postgresql', 'mysql', 'postgresql', 'sql'],\n",
       " ['mysql', 'postgresql', 'sql', 'postgresql'],\n",
       " ['postgresql', 'sql', 'postgresql', 'aws'],\n",
       " ['sql', 'postgresql', 'aws', 'sql'],\n",
       " ['postgresql', 'aws', 'sql', 'scrum'],\n",
       " ['aws', 'sql', 'scrum', 'aws'],\n",
       " ['sql', 'scrum', 'aws', 'aws'],\n",
       " ['scrum', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'linux'],\n",
       " ['aws', 'aws', 'linux', 'windows'],\n",
       " ['aws', 'linux', 'windows', 'shell'],\n",
       " ['linux', 'windows', 'shell', 'aws'],\n",
       " ['windows', 'shell', 'aws', 'sql'],\n",
       " ['shell', 'aws', 'sql', 'sql'],\n",
       " ['aws', 'sql', 'sql', 'mysql'],\n",
       " ['sql', 'sql', 'mysql', 'postgresql'],\n",
       " ['sql', 'mysql', 'postgresql', 'mysql'],\n",
       " ['mysql', 'postgresql', 'mysql', 'postgresql'],\n",
       " ['postgresql', 'mysql', 'postgresql', 'linux'],\n",
       " ['mysql', 'postgresql', 'linux', 'postgresql'],\n",
       " ['postgresql', 'linux', 'postgresql', 'python'],\n",
       " ['linux', 'postgresql', 'python', 'aws'],\n",
       " ['postgresql', 'python', 'aws', 'aws'],\n",
       " ['python', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'sql'],\n",
       " ['aws', 'aws', 'sql', 'mysql'],\n",
       " ['aws', 'sql', 'mysql', 'sql'],\n",
       " ['sql', 'mysql', 'sql', 'sql'],\n",
       " ['mysql', 'sql', 'sql', 'aws'],\n",
       " ['sql', 'sql', 'aws', 'docker'],\n",
       " ['sql', 'aws', 'docker', 'sql'],\n",
       " ['aws', 'docker', 'sql', 'python'],\n",
       " ['docker', 'sql', 'python', 'kubernetes'],\n",
       " ['sql', 'python', 'kubernetes', 'sql'],\n",
       " ['python', 'kubernetes', 'sql', 'gcp'],\n",
       " ['kubernetes', 'sql', 'gcp', 'sql'],\n",
       " ['sql', 'gcp', 'sql', 'sql'],\n",
       " ['gcp', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'aws'],\n",
       " ['sql', 'sql', 'aws', 'ruby'],\n",
       " ['sql', 'aws', 'ruby', 'aws'],\n",
       " ['aws', 'ruby', 'aws', 'aws'],\n",
       " ['ruby', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'aws'],\n",
       " ['aws', 'aws', 'aws', 'java'],\n",
       " ['aws', 'aws', 'java', 'sql'],\n",
       " ['aws', 'java', 'sql', 'sql'],\n",
       " ['java', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'r'],\n",
       " ['sql', 'sql', 'r', 'python'],\n",
       " ['sql', 'r', 'python', 'mysql'],\n",
       " ['r', 'python', 'mysql', 'ruby'],\n",
       " ['python', 'mysql', 'ruby', 'hadoop'],\n",
       " ['mysql', 'ruby', 'hadoop', 'aws'],\n",
       " ['ruby', 'hadoop', 'aws', 'mysql'],\n",
       " ['hadoop', 'aws', 'mysql', 'java'],\n",
       " ['aws', 'mysql', 'java', 'nosql'],\n",
       " ['mysql', 'java', 'nosql', 'aws'],\n",
       " ['java', 'nosql', 'aws', 'sql'],\n",
       " ['nosql', 'aws', 'sql', 'nosql'],\n",
       " ['aws', 'sql', 'nosql', 'aws'],\n",
       " ['sql', 'nosql', 'aws', 'sql'],\n",
       " ['nosql', 'aws', 'sql', 'nosql'],\n",
       " ['aws', 'sql', 'nosql', 'sql'],\n",
       " ['sql', 'nosql', 'sql', 'aws'],\n",
       " ['nosql', 'sql', 'aws', 'aws'],\n",
       " ['sql', 'aws', 'aws', 'java'],\n",
       " ['aws', 'aws', 'java', 'ansible'],\n",
       " ['aws', 'java', 'ansible', 'bash'],\n",
       " ['java', 'ansible', 'bash', 'sql'],\n",
       " ['ansible', 'bash', 'sql', 'sql'],\n",
       " ['bash', 'sql', 'sql', 'microsoft'],\n",
       " ['sql', 'sql', 'microsoft', 'sql'],\n",
       " ['sql', 'microsoft', 'sql', 'sql'],\n",
       " ['microsoft', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'azure'],\n",
       " ['sql', 'sql', 'azure', 'sql'],\n",
       " ['sql', 'azure', 'sql', 'sql'],\n",
       " ['azure', 'sql', 'sql', 'azure'],\n",
       " ['sql', 'sql', 'azure', 'sql'],\n",
       " ['sql', 'azure', 'sql', 'sql'],\n",
       " ['azure', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'mysql'],\n",
       " ['sql', 'sql', 'mysql', 'sql'],\n",
       " ['sql', 'mysql', 'sql', 'mysql'],\n",
       " ['mysql', 'sql', 'mysql', 'nosql'],\n",
       " ['sql', 'mysql', 'nosql', 'python'],\n",
       " ['mysql', 'nosql', 'python', 'puppet'],\n",
       " ['nosql', 'python', 'puppet', 'css'],\n",
       " ['python', 'puppet', 'css', 'javascript'],\n",
       " ['puppet', 'css', 'javascript', 'angular'],\n",
       " ['css', 'javascript', 'angular', 'react'],\n",
       " ['javascript', 'angular', 'react', 'oracle'],\n",
       " ['angular', 'react', 'oracle', 'sql'],\n",
       " ['react', 'oracle', 'sql', 'java'],\n",
       " ['oracle', 'sql', 'java', 'java'],\n",
       " ['sql', 'java', 'java', 'java'],\n",
       " ['java', 'java', 'java', 'hadoop'],\n",
       " ['java', 'java', 'hadoop', 'apache'],\n",
       " ['java', 'hadoop', 'apache', 'apache'],\n",
       " ['hadoop', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'spark'],\n",
       " ['apache', 'apache', 'spark', 'apache'],\n",
       " ['apache', 'spark', 'apache', 'apache'],\n",
       " ['spark', 'apache', 'apache', 'java'],\n",
       " ['apache', 'apache', 'java', 'hadoop'],\n",
       " ['apache', 'java', 'hadoop', 'apache'],\n",
       " ['java', 'hadoop', 'apache', 'apache'],\n",
       " ['hadoop', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'spark'],\n",
       " ['apache', 'apache', 'spark', 'apache'],\n",
       " ['apache', 'spark', 'apache', 'angular'],\n",
       " ['spark', 'apache', 'angular', 'nosql'],\n",
       " ['apache', 'angular', 'nosql', 'mongodb'],\n",
       " ['angular', 'nosql', 'mongodb', 'cassandra'],\n",
       " ['nosql', 'mongodb', 'cassandra', 'java'],\n",
       " ['mongodb', 'cassandra', 'java', 'hadoop'],\n",
       " ['cassandra', 'java', 'hadoop', 'apache'],\n",
       " ['java', 'hadoop', 'apache', 'apache'],\n",
       " ['hadoop', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'spark'],\n",
       " ['apache', 'apache', 'spark', 'apache'],\n",
       " ['apache', 'spark', 'apache', 'sql'],\n",
       " ['spark', 'apache', 'sql', 'apache'],\n",
       " ['apache', 'sql', 'apache', 'java'],\n",
       " ['sql', 'apache', 'java', 'nosql'],\n",
       " ['apache', 'java', 'nosql', 'mongodb'],\n",
       " ['java', 'nosql', 'mongodb', 'cassandra'],\n",
       " ['nosql', 'mongodb', 'cassandra', 'react'],\n",
       " ['mongodb', 'cassandra', 'react', 'javascript'],\n",
       " ['cassandra', 'react', 'javascript', 'vue'],\n",
       " ['react', 'javascript', 'vue', 'react'],\n",
       " ['javascript', 'vue', 'react', 'ruby'],\n",
       " ['vue', 'react', 'ruby', 'sql'],\n",
       " ['react', 'ruby', 'sql', 'mysql'],\n",
       " ['ruby', 'sql', 'mysql', 'javascript'],\n",
       " ['sql', 'mysql', 'javascript', 'react'],\n",
       " ['mysql', 'javascript', 'react', 'docker'],\n",
       " ['javascript', 'react', 'docker', 'javascript'],\n",
       " ['react', 'docker', 'javascript', 'javascript'],\n",
       " ['docker', 'javascript', 'javascript', 'javascript'],\n",
       " ['javascript', 'javascript', 'javascript', 'angular'],\n",
       " ['javascript', 'javascript', 'angular', 'windows'],\n",
       " ['javascript', 'angular', 'windows', 'react'],\n",
       " ['angular', 'windows', 'react', 'hadoop'],\n",
       " ['windows', 'react', 'hadoop', 'linux'],\n",
       " ['react', 'hadoop', 'linux', 'c'],\n",
       " ['hadoop', 'linux', 'c', 'git'],\n",
       " ['linux', 'c', 'git', 'angular'],\n",
       " ['c', 'git', 'angular', 'java'],\n",
       " ['git', 'angular', 'java', 'spring'],\n",
       " ['angular', 'java', 'spring', 'javascript'],\n",
       " ['java', 'spring', 'javascript', 'sql'],\n",
       " ['spring', 'javascript', 'sql', 'css'],\n",
       " ['javascript', 'sql', 'css', 'javascript'],\n",
       " ['sql', 'css', 'javascript', 'html'],\n",
       " ['css', 'javascript', 'html', 'photoshop'],\n",
       " ['javascript', 'html', 'photoshop', 'sql'],\n",
       " ['html', 'photoshop', 'sql', 'databricks'],\n",
       " ['photoshop', 'sql', 'databricks', 'databricks'],\n",
       " ['sql', 'databricks', 'databricks', 'databricks'],\n",
       " ['databricks', 'databricks', 'databricks', 'databricks'],\n",
       " ['databricks', 'databricks', 'databricks', 'wordpress'],\n",
       " ['databricks', 'databricks', 'wordpress', 'wordpress'],\n",
       " ['databricks', 'wordpress', 'wordpress', 'javascript'],\n",
       " ['wordpress', 'wordpress', 'javascript', 'git'],\n",
       " ['wordpress', 'javascript', 'git', 'databricks'],\n",
       " ['javascript', 'git', 'databricks', 'apache'],\n",
       " ['git', 'databricks', 'apache', 'databricks'],\n",
       " ['databricks', 'apache', 'databricks', 'databricks'],\n",
       " ['apache', 'databricks', 'databricks', 'nlp'],\n",
       " ['databricks', 'databricks', 'nlp', 'nlp'],\n",
       " ['databricks', 'nlp', 'nlp', 'css'],\n",
       " ['nlp', 'nlp', 'css', 'javascript'],\n",
       " ['nlp', 'css', 'javascript', 'oracle'],\n",
       " ['css', 'javascript', 'oracle', 'css'],\n",
       " ['javascript', 'oracle', 'css', 'javascript'],\n",
       " ['oracle', 'css', 'javascript', 'scala'],\n",
       " ['css', 'javascript', 'scala', 'java'],\n",
       " ['javascript', 'scala', 'java', 'java'],\n",
       " ['scala', 'java', 'java', 'java'],\n",
       " ['java', 'java', 'java', 'hadoop'],\n",
       " ['java', 'java', 'hadoop', 'apache'],\n",
       " ['java', 'hadoop', 'apache', 'apache'],\n",
       " ['hadoop', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'apache'],\n",
       " ['apache', 'apache', 'apache', 'spark'],\n",
       " ['apache', 'apache', 'spark', 'apache'],\n",
       " ['apache', 'spark', 'apache', 'wordpress'],\n",
       " ['spark', 'apache', 'wordpress', 'javascript'],\n",
       " ['apache', 'wordpress', 'javascript', 'ajax'],\n",
       " ['wordpress', 'javascript', 'ajax', 'wordpress'],\n",
       " ['javascript', 'ajax', 'wordpress', 'php'],\n",
       " ['ajax', 'wordpress', 'php', 'photoshop'],\n",
       " ['wordpress', 'php', 'photoshop', 'html'],\n",
       " ['php', 'photoshop', 'html', 'asp'],\n",
       " ['photoshop', 'html', 'asp', 'asp'],\n",
       " ['html', 'asp', 'asp', 'net'],\n",
       " ['asp', 'asp', 'net', 'sql'],\n",
       " ['asp', 'net', 'sql', 'nosql'],\n",
       " ['net', 'sql', 'nosql', 'html'],\n",
       " ['sql', 'nosql', 'html', 'azure'],\n",
       " ['nosql', 'html', 'azure', 'javascript'],\n",
       " ['html', 'azure', 'javascript', 'javascript'],\n",
       " ['azure', 'javascript', 'javascript', 'angular'],\n",
       " ['javascript', 'javascript', 'angular', 'html'],\n",
       " ['javascript', 'angular', 'html', 'css'],\n",
       " ['angular', 'html', 'css', 'jquery'],\n",
       " ['html', 'css', 'jquery', 'python'],\n",
       " ['css', 'jquery', 'python', 'php'],\n",
       " ['jquery', 'python', 'php', 'c'],\n",
       " ['python', 'php', 'c', 'javascript'],\n",
       " ['php', 'c', 'javascript', 'jquery'],\n",
       " ['c', 'javascript', 'jquery', 'java'],\n",
       " ['javascript', 'jquery', 'java', 'angular'],\n",
       " ['jquery', 'java', 'angular', 'angular'],\n",
       " ['java', 'angular', 'angular', 'javascript'],\n",
       " ['angular', 'angular', 'javascript', 'sql'],\n",
       " ['angular', 'javascript', 'sql', 'c'],\n",
       " ['javascript', 'sql', 'c', 'microsoft'],\n",
       " ['sql', 'c', 'microsoft', 'sql'],\n",
       " ['c', 'microsoft', 'sql', 'asp'],\n",
       " ['microsoft', 'sql', 'asp', 'net'],\n",
       " ['sql', 'asp', 'net', 'microsoft'],\n",
       " ['asp', 'net', 'microsoft', 'sql'],\n",
       " ['net', 'microsoft', 'sql', 'angular'],\n",
       " ['microsoft', 'sql', 'angular', 'c'],\n",
       " ['sql', 'angular', 'c', 'c'],\n",
       " ['angular', 'c', 'c', 'linux'],\n",
       " ['c', 'c', 'linux', 'c'],\n",
       " ['c', 'linux', 'c', 'linux'],\n",
       " ['linux', 'c', 'linux', 'linux'],\n",
       " ['c', 'linux', 'linux', 'c'],\n",
       " ['linux', 'linux', 'c', 'java'],\n",
       " ['linux', 'c', 'java', 'linux'],\n",
       " ['c', 'java', 'linux', 'salesforce'],\n",
       " ['java', 'linux', 'salesforce', 'c'],\n",
       " ['linux', 'salesforce', 'c', 'aws'],\n",
       " ['salesforce', 'c', 'aws', 'mysql'],\n",
       " ['c', 'aws', 'mysql', 'c'],\n",
       " ['aws', 'mysql', 'c', 'java'],\n",
       " ['mysql', 'c', 'java', 'elixir'],\n",
       " ['c', 'java', 'elixir', 'aws'],\n",
       " ['java', 'elixir', 'aws', 'linux'],\n",
       " ['elixir', 'aws', 'linux', 'ruby'],\n",
       " ['aws', 'linux', 'ruby', 'python'],\n",
       " ['linux', 'ruby', 'python', 'tensorflow'],\n",
       " ['ruby', 'python', 'tensorflow', 'javascript'],\n",
       " ['python', 'tensorflow', 'javascript', 'javascript'],\n",
       " ['tensorflow', 'javascript', 'javascript', 'git'],\n",
       " ['javascript', 'javascript', 'git', 'docker'],\n",
       " ['javascript', 'git', 'docker', 'kubernetes'],\n",
       " ['git', 'docker', 'kubernetes', 'java'],\n",
       " ['docker', 'kubernetes', 'java', 'javascript'],\n",
       " ['kubernetes', 'java', 'javascript', 'linux'],\n",
       " ['java', 'javascript', 'linux', 'java'],\n",
       " ['javascript', 'linux', 'java', 'nlp'],\n",
       " ['linux', 'java', 'nlp', 'nlp'],\n",
       " ['java', 'nlp', 'nlp', 'ruby'],\n",
       " ['nlp', 'nlp', 'ruby', 'hadoop'],\n",
       " ['nlp', 'ruby', 'hadoop', 'ruby'],\n",
       " ['ruby', 'hadoop', 'ruby', 'rails'],\n",
       " ['hadoop', 'ruby', 'rails', 'css'],\n",
       " ['ruby', 'rails', 'css', 'python'],\n",
       " ['rails', 'css', 'python', 'bash'],\n",
       " ['css', 'python', 'bash', 'ruby'],\n",
       " ['python', 'bash', 'ruby', 'azure'],\n",
       " ['bash', 'ruby', 'azure', 'azure'],\n",
       " ['ruby', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'c'],\n",
       " ['azure', 'azure', 'c', 'c'],\n",
       " ['azure', 'c', 'c', 'c'],\n",
       " ['c', 'c', 'c', 'microsoft'],\n",
       " ['c', 'c', 'microsoft', 'microsoft'],\n",
       " ['c', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'azure'],\n",
       " ['microsoft', 'microsoft', 'azure', 'azure'],\n",
       " ['microsoft', 'azure', 'azure', 'java'],\n",
       " ['azure', 'azure', 'java', 'python'],\n",
       " ['azure', 'java', 'python', 'python'],\n",
       " ['java', 'python', 'python', 'linux'],\n",
       " ['python', 'python', 'linux', 'aws'],\n",
       " ['python', 'linux', 'aws', 'oracle'],\n",
       " ['linux', 'aws', 'oracle', 'oracle'],\n",
       " ['aws', 'oracle', 'oracle', 'oracle'],\n",
       " ['oracle', 'oracle', 'oracle', 'nosql'],\n",
       " ['oracle', 'oracle', 'nosql', 'oracle'],\n",
       " ['oracle', 'nosql', 'oracle', 'oracle'],\n",
       " ['nosql', 'oracle', 'oracle', 'ruby'],\n",
       " ['oracle', 'oracle', 'ruby', 'python'],\n",
       " ['oracle', 'ruby', 'python', 'tensorflow'],\n",
       " ['ruby', 'python', 'tensorflow', 'ios'],\n",
       " ['python', 'tensorflow', 'ios', 'ios'],\n",
       " ['tensorflow', 'ios', 'ios', 'swift'],\n",
       " ['ios', 'ios', 'swift', 'c'],\n",
       " ['ios', 'swift', 'c', 'ios'],\n",
       " ['swift', 'c', 'ios', 'swift'],\n",
       " ['c', 'ios', 'swift', 'ios'],\n",
       " ['ios', 'swift', 'ios', 'scrum'],\n",
       " ['swift', 'ios', 'scrum', 'python'],\n",
       " ['ios', 'scrum', 'python', 'scala'],\n",
       " ['scrum', 'python', 'scala', 'c'],\n",
       " ['python', 'scala', 'c', 'linux'],\n",
       " ['scala', 'c', 'linux', 'linux'],\n",
       " ['c', 'linux', 'linux', 'git'],\n",
       " ['linux', 'linux', 'git', 'shell'],\n",
       " ['linux', 'git', 'shell', 'python'],\n",
       " ['git', 'shell', 'python', 'docker'],\n",
       " ['shell', 'python', 'docker', 'microsoft'],\n",
       " ['python', 'docker', 'microsoft', 'microsoft'],\n",
       " ['docker', 'microsoft', 'microsoft', 'git'],\n",
       " ['microsoft', 'microsoft', 'git', 'shell'],\n",
       " ['microsoft', 'git', 'shell', 'python'],\n",
       " ['git', 'shell', 'python', 'php'],\n",
       " ['shell', 'python', 'php', 'mongodb'],\n",
       " ['python', 'php', 'mongodb', 'docker'],\n",
       " ['php', 'mongodb', 'docker', 'aws'],\n",
       " ['mongodb', 'docker', 'aws', 'javascript'],\n",
       " ['docker', 'aws', 'javascript', 'ios'],\n",
       " ['aws', 'javascript', 'ios', 'android'],\n",
       " ['javascript', 'ios', 'android', 'ios'],\n",
       " ['ios', 'android', 'ios', 'android'],\n",
       " ['android', 'ios', 'android', 'ios'],\n",
       " ['ios', 'android', 'ios', 'android'],\n",
       " ['android', 'ios', 'android', 'c'],\n",
       " ['ios', 'android', 'c', 'ios'],\n",
       " ['android', 'c', 'ios', 'android'],\n",
       " ['c', 'ios', 'android', 'c'],\n",
       " ['ios', 'android', 'c', 'python'],\n",
       " ['android', 'c', 'python', 'django'],\n",
       " ['c', 'python', 'django', 'javascript'],\n",
       " ['python', 'django', 'javascript', 'aws'],\n",
       " ['django', 'javascript', 'aws', 'linux'],\n",
       " ['javascript', 'aws', 'linux', 'ruby'],\n",
       " ['aws', 'linux', 'ruby', 'python'],\n",
       " ['linux', 'ruby', 'python', 'git'],\n",
       " ['ruby', 'python', 'git', 'gcp'],\n",
       " ['python', 'git', 'gcp', 'aws'],\n",
       " ['git', 'gcp', 'aws', 'python'],\n",
       " ['gcp', 'aws', 'python', 'mysql'],\n",
       " ['aws', 'python', 'mysql', 'rails'],\n",
       " ['python', 'mysql', 'rails', 'ruby'],\n",
       " ['mysql', 'rails', 'ruby', 'git'],\n",
       " ['rails', 'ruby', 'git', 'aws'],\n",
       " ['ruby', 'git', 'aws', 'ruby'],\n",
       " ['git', 'aws', 'ruby', 'rails'],\n",
       " ['aws', 'ruby', 'rails', 'ruby'],\n",
       " ['ruby', 'rails', 'ruby', 'sql'],\n",
       " ['rails', 'ruby', 'sql', 'nosql'],\n",
       " ['ruby', 'sql', 'nosql', 'scrum'],\n",
       " ['sql', 'nosql', 'scrum', 'git'],\n",
       " ['nosql', 'scrum', 'git', 'azure'],\n",
       " ['scrum', 'git', 'azure', 'azure'],\n",
       " ['git', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'azure'],\n",
       " ['azure', 'azure', 'azure', 'react'],\n",
       " ['azure', 'azure', 'react', 'azure'],\n",
       " ['azure', 'react', 'azure', 'microsoft'],\n",
       " ['react', 'azure', 'microsoft', 'microsoft'],\n",
       " ['azure', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'microsoft'],\n",
       " ['microsoft', 'microsoft', 'microsoft', 'spark'],\n",
       " ['microsoft', 'microsoft', 'spark', 'r'],\n",
       " ['microsoft', 'spark', 'r', 'python'],\n",
       " ['spark', 'r', 'python', 'tableau'],\n",
       " ['r', 'python', 'tableau', 'python'],\n",
       " ['python', 'tableau', 'python', 'sql'],\n",
       " ['tableau', 'python', 'sql', 'ibm'],\n",
       " ['python', 'sql', 'ibm', 'sql'],\n",
       " ['sql', 'ibm', 'sql', 'sql'],\n",
       " ['ibm', 'sql', 'sql', 'ibm'],\n",
       " ['sql', 'sql', 'ibm', 'ibm'],\n",
       " ['sql', 'ibm', 'ibm', 'r'],\n",
       " ['ibm', 'ibm', 'r', 'python'],\n",
       " ['ibm', 'r', 'python', 'r'],\n",
       " ['r', 'python', 'r', 'python'],\n",
       " ['python', 'r', 'python', 'sql'],\n",
       " ['r', 'python', 'sql', 'python'],\n",
       " ['python', 'sql', 'python', 'r'],\n",
       " ['sql', 'python', 'r', 'python'],\n",
       " ['python', 'r', 'python', 'ibm'],\n",
       " ['r', 'python', 'ibm', 'sql'],\n",
       " ['python', 'ibm', 'sql', 'python'],\n",
       " ['ibm', 'sql', 'python', 'python'],\n",
       " ['sql', 'python', 'python', 'aws'],\n",
       " ['python', 'python', 'aws', 'r'],\n",
       " ['python', 'aws', 'r', 'nosql'],\n",
       " ['aws', 'r', 'nosql', 'r'],\n",
       " ['r', 'nosql', 'r', 'linux'],\n",
       " ['nosql', 'r', 'linux', 'r'],\n",
       " ['r', 'linux', 'r', 'sql'],\n",
       " ['linux', 'r', 'sql', 'oracle'],\n",
       " ['r', 'sql', 'oracle', 'java'],\n",
       " ['sql', 'oracle', 'java', 'html'],\n",
       " ['oracle', 'java', 'html', 'scala'],\n",
       " ['java', 'html', 'scala', 'spark'],\n",
       " ['html', 'scala', 'spark', 'c'],\n",
       " ['scala', 'spark', 'c', 'r'],\n",
       " ['spark', 'c', 'r', 'r'],\n",
       " ['c', 'r', 'r', 'python'],\n",
       " ['r', 'r', 'python', 'java'],\n",
       " ['r', 'python', 'java', 'r'],\n",
       " ['python', 'java', 'r', 'python'],\n",
       " ['java', 'r', 'python', 'numpy'],\n",
       " ['r', 'python', 'numpy', 'scikit'],\n",
       " ['python', 'numpy', 'scikit', 'learn'],\n",
       " ['numpy', 'scikit', 'learn', 'microsoft'],\n",
       " ['scikit', 'learn', 'microsoft', 'microsoft'],\n",
       " ['learn', 'microsoft', 'microsoft', 'sql'],\n",
       " ['microsoft', 'microsoft', 'sql', 'sql'],\n",
       " ['microsoft', 'sql', 'sql', 'tableau'],\n",
       " ['sql', 'sql', 'tableau', 'tableau'],\n",
       " ['sql', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'oracle'],\n",
       " ['tableau', 'tableau', 'oracle', 'tableau'],\n",
       " ['tableau', 'oracle', 'tableau', 'tableau'],\n",
       " ['oracle', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'sql'],\n",
       " ['tableau', 'tableau', 'sql', 'tableau'],\n",
       " ['tableau', 'sql', 'tableau', 'tableau'],\n",
       " ['sql', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'oracle'],\n",
       " ['tableau', 'tableau', 'oracle', 'tableau'],\n",
       " ['tableau', 'oracle', 'tableau', 'tableau'],\n",
       " ['oracle', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'tableau'],\n",
       " ['tableau', 'tableau', 'tableau', 'sql'],\n",
       " ['tableau', 'tableau', 'sql', 'tableau'],\n",
       " ['tableau', 'sql', 'tableau', 'python'],\n",
       " ['sql', 'tableau', 'python', 'excel'],\n",
       " ['tableau', 'python', 'excel', 'c'],\n",
       " ['python', 'excel', 'c', 'c'],\n",
       " ['excel', 'c', 'c', 'sql'],\n",
       " ['c', 'c', 'sql', 'nosql'],\n",
       " ['c', 'sql', 'nosql', 'hbase'],\n",
       " ['sql', 'nosql', 'hbase', 'aws'],\n",
       " ['nosql', 'hbase', 'aws', 'r'],\n",
       " ['hbase', 'aws', 'r', 'sql'],\n",
       " ['aws', 'r', 'sql', 'python'],\n",
       " ['r', 'sql', 'python', 'r'],\n",
       " ['sql', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'r'],\n",
       " ['r', 'sql', 'r', 'd'],\n",
       " ['sql', 'r', 'd', 'python'],\n",
       " ['r', 'd', 'python', 'r'],\n",
       " ['d', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'sql'],\n",
       " ['r', 'sql', 'sql', 'python'],\n",
       " ['sql', 'sql', 'python', 'aws'],\n",
       " ['sql', 'python', 'aws', 'sas'],\n",
       " ['python', 'aws', 'sas', 'python'],\n",
       " ['aws', 'sas', 'python', 'r'],\n",
       " ['sas', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'sql'],\n",
       " ['r', 'sql', 'sql', 'hadoop'],\n",
       " ['sql', 'sql', 'hadoop', 'r'],\n",
       " ['sql', 'hadoop', 'r', 'python'],\n",
       " ['hadoop', 'r', 'python', 'tableau'],\n",
       " ['r', 'python', 'tableau', 'sql'],\n",
       " ['python', 'tableau', 'sql', 'sas'],\n",
       " ['tableau', 'sql', 'sas', 'python'],\n",
       " ['sql', 'sas', 'python', 'gcp'],\n",
       " ['sas', 'python', 'gcp', 'sql'],\n",
       " ['python', 'gcp', 'sql', 'git'],\n",
       " ['gcp', 'sql', 'git', 'r'],\n",
       " ['sql', 'git', 'r', 'spark'],\n",
       " ['git', 'r', 'spark', 'sql'],\n",
       " ['r', 'spark', 'sql', 'python'],\n",
       " ['spark', 'sql', 'python', 'sas'],\n",
       " ['sql', 'python', 'sas', 'python'],\n",
       " ['python', 'sas', 'python', 'spark'],\n",
       " ['sas', 'python', 'spark', 'python'],\n",
       " ['python', 'spark', 'python', 'spark'],\n",
       " ['spark', 'python', 'spark', 'hive'],\n",
       " ['python', 'spark', 'hive', 'git'],\n",
       " ['spark', 'hive', 'git', 'python'],\n",
       " ['hive', 'git', 'python', 'tensorflow'],\n",
       " ['git', 'python', 'tensorflow', 'hive'],\n",
       " ['python', 'tensorflow', 'hive', 'pig'],\n",
       " ['tensorflow', 'hive', 'pig', 'aws'],\n",
       " ['hive', 'pig', 'aws', 'scala'],\n",
       " ['pig', 'aws', 'scala', 'excel'],\n",
       " ['aws', 'scala', 'excel', 'python'],\n",
       " ['scala', 'excel', 'python', 'java'],\n",
       " ['excel', 'python', 'java', 'linux'],\n",
       " ['python', 'java', 'linux', 'python'],\n",
       " ['java', 'linux', 'python', 'c'],\n",
       " ['linux', 'python', 'c', 'apache'],\n",
       " ['python', 'c', 'apache', 'spark'],\n",
       " ['c', 'apache', 'spark', 'python'],\n",
       " ['apache', 'spark', 'python', 'python'],\n",
       " ['spark', 'python', 'python', 'python'],\n",
       " ['python', 'python', 'python', 'r'],\n",
       " ['python', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'java'],\n",
       " ['r', 'sql', 'java', 'r'],\n",
       " ['sql', 'java', 'r', 'python'],\n",
       " ['java', 'r', 'python', 'microsoft'],\n",
       " ['r', 'python', 'microsoft', 'powerpoint'],\n",
       " ['python', 'microsoft', 'powerpoint', 'sql'],\n",
       " ['microsoft', 'powerpoint', 'sql', 'python'],\n",
       " ['powerpoint', 'sql', 'python', 'sql'],\n",
       " ['sql', 'python', 'sql', 'microsoft'],\n",
       " ['python', 'sql', 'microsoft', 'microsoft'],\n",
       " ['sql', 'microsoft', 'microsoft', 'r'],\n",
       " ['microsoft', 'microsoft', 'r', 'sas'],\n",
       " ['microsoft', 'r', 'sas', 'sql'],\n",
       " ['r', 'sas', 'sql', 'sql'],\n",
       " ['sas', 'sql', 'sql', 'hive'],\n",
       " ['sql', 'sql', 'hive', 'spark'],\n",
       " ['sql', 'hive', 'spark', 'python'],\n",
       " ['hive', 'spark', 'python', 'pi'],\n",
       " ['spark', 'python', 'pi', 'oracle'],\n",
       " ['python', 'pi', 'oracle', 'sql'],\n",
       " ['pi', 'oracle', 'sql', 'r'],\n",
       " ['oracle', 'sql', 'r', 'spark'],\n",
       " ['sql', 'r', 'spark', 'java'],\n",
       " ['r', 'spark', 'java', 'r'],\n",
       " ['spark', 'java', 'r', 'spark'],\n",
       " ['java', 'r', 'spark', 'java'],\n",
       " ['r', 'spark', 'java', 'tableau'],\n",
       " ['spark', 'java', 'tableau', 'r'],\n",
       " ['java', 'tableau', 'r', 'python'],\n",
       " ['tableau', 'r', 'python', 'aws'],\n",
       " ['r', 'python', 'aws', 'python'],\n",
       " ['python', 'aws', 'python', 'tableau'],\n",
       " ['aws', 'python', 'tableau', 'shell'],\n",
       " ['python', 'tableau', 'shell', 'linux'],\n",
       " ['tableau', 'shell', 'linux', 'sql'],\n",
       " ['shell', 'linux', 'sql', 'scala'],\n",
       " ['linux', 'sql', 'scala', 'sas'],\n",
       " ['sql', 'scala', 'sas', 'sql'],\n",
       " ['scala', 'sas', 'sql', 'python'],\n",
       " ['sas', 'sql', 'python', 'hive'],\n",
       " ['sql', 'python', 'hive', 'scala'],\n",
       " ['python', 'hive', 'scala', 'sql'],\n",
       " ['hive', 'scala', 'sql', 'net'],\n",
       " ['scala', 'sql', 'net', 'tensorflow'],\n",
       " ['sql', 'net', 'tensorflow', 'pytorch'],\n",
       " ['net', 'tensorflow', 'pytorch', 'azure'],\n",
       " ['tensorflow', 'pytorch', 'azure', 'microsoft'],\n",
       " ['pytorch', 'azure', 'microsoft', 'python'],\n",
       " ['azure', 'microsoft', 'python', 'r'],\n",
       " ['microsoft', 'python', 'r', 'python'],\n",
       " ['python', 'r', 'python', 'sql'],\n",
       " ['r', 'python', 'sql', 'sql'],\n",
       " ['python', 'sql', 'sql', 'sql'],\n",
       " ['sql', 'sql', 'sql', 'powerpoint'],\n",
       " ['sql', 'sql', 'powerpoint', 'xgboost'],\n",
       " ['sql', 'powerpoint', 'xgboost', 'python'],\n",
       " ['powerpoint', 'xgboost', 'python', 'shell'],\n",
       " ['xgboost', 'python', 'shell', 'shell'],\n",
       " ['python', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'spark'],\n",
       " ['shell', 'shell', 'spark', 'shell'],\n",
       " ['shell', 'spark', 'shell', 'shell'],\n",
       " ['spark', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'shell'],\n",
       " ['shell', 'shell', 'shell', 'python'],\n",
       " ['shell', 'shell', 'python', 'linux'],\n",
       " ['shell', 'python', 'linux', 'python'],\n",
       " ['python', 'linux', 'python', 'r'],\n",
       " ['linux', 'python', 'r', 'spark'],\n",
       " ['python', 'r', 'spark', 'spss'],\n",
       " ['r', 'spark', 'spss', 'spss'],\n",
       " ['spark', 'spss', 'spss', 'hadoop'],\n",
       " ['spss', 'spss', 'hadoop', 'mapreduce'],\n",
       " ['spss', 'hadoop', 'mapreduce', 'sas'],\n",
       " ['hadoop', 'mapreduce', 'sas', 'salesforce'],\n",
       " ['mapreduce', 'sas', 'salesforce', 'scrum'],\n",
       " ['sas', 'salesforce', 'scrum', 'spss'],\n",
       " ['salesforce', 'scrum', 'spss', 'sap'],\n",
       " ['scrum', 'spss', 'sap', 'sql'],\n",
       " ['spss', 'sap', 'sql', 'scrum'],\n",
       " ['sap', 'sql', 'scrum', 'nlp'],\n",
       " ['sql', 'scrum', 'nlp', 'nlp'],\n",
       " ['scrum', 'nlp', 'nlp', 'nlp'],\n",
       " ['nlp', 'nlp', 'nlp', 'sql'],\n",
       " ['nlp', 'nlp', 'sql', 'r'],\n",
       " ['nlp', 'sql', 'r', 'python'],\n",
       " ['sql', 'r', 'python', 'sql'],\n",
       " ['r', 'python', 'sql', 'spss'],\n",
       " ['python', 'sql', 'spss', 'r'],\n",
       " ['sql', 'spss', 'r', 'microsoft'],\n",
       " ['spss', 'r', 'microsoft', 'excel'],\n",
       " ['r', 'microsoft', 'excel', 'hive'],\n",
       " ['microsoft', 'excel', 'hive', 'nlp'],\n",
       " ['excel', 'hive', 'nlp', 'r'],\n",
       " ['hive', 'nlp', 'r', 'python'],\n",
       " ['nlp', 'r', 'python', 'tableau'],\n",
       " ['r', 'python', 'tableau', 'nosql'],\n",
       " ['python', 'tableau', 'nosql', 'hbase'],\n",
       " ['tableau', 'nosql', 'hbase', 'python'],\n",
       " ['nosql', 'hbase', 'python', 'r'],\n",
       " ['hbase', 'python', 'r', 'python'],\n",
       " ['python', 'r', 'python', 'r'],\n",
       " ['r', 'python', 'r', 'python'],\n",
       " ['python', 'r', 'python', 'spss'],\n",
       " ['r', 'python', 'spss', 'tableau'],\n",
       " ['python', 'spss', 'tableau', 'python'],\n",
       " ['spss', 'tableau', 'python', 'sql'],\n",
       " ['tableau', 'python', 'sql', 'sas'],\n",
       " ['python', 'sql', 'sas', 'sas'],\n",
       " ['sql', 'sas', 'sas', 'sas'],\n",
       " ['sas', 'sas', 'sas', 'r'],\n",
       " ['sas', 'sas', 'r', 'python'],\n",
       " ['sas', 'r', 'python', 'aws'],\n",
       " ['r', 'python', 'aws', 'linux'],\n",
       " ['python', 'aws', 'linux', 'hadoop'],\n",
       " ['aws', 'linux', 'hadoop', 'microsoft'],\n",
       " ['linux', 'hadoop', 'microsoft', 'sql'],\n",
       " ['hadoop', 'microsoft', 'sql', 'tableau'],\n",
       " ['microsoft', 'sql', 'tableau', 'aws'],\n",
       " ['sql', 'tableau', 'aws', 'python'],\n",
       " ['tableau', 'aws', 'python', 'r'],\n",
       " ['aws', 'python', 'r', 'net'],\n",
       " ['python', 'r', 'net', 'apache'],\n",
       " ['r', 'net', 'apache', 'spark'],\n",
       " ['net', 'apache', 'spark', 'aws'],\n",
       " ['apache', 'spark', 'aws', 'python'],\n",
       " ['spark', 'aws', 'python', 'r'],\n",
       " ['aws', 'python', 'r', 'jupyter'],\n",
       " ['python', 'r', 'jupyter', 'r'],\n",
       " ['r', 'jupyter', 'r', 'python'],\n",
       " ['jupyter', 'r', 'python', 'r'],\n",
       " ['r', 'python', 'r', 'sas'],\n",
       " ['python', 'r', 'sas', 'r'],\n",
       " ['r', 'sas', 'r', 'jupyter'],\n",
       " ['sas', 'r', 'jupyter', 'sql'],\n",
       " ['r', 'jupyter', 'sql', 'sql'],\n",
       " ['jupyter', 'sql', 'sql', 'microsoft'],\n",
       " ['sql', 'sql', 'microsoft', 'excel'],\n",
       " ['sql', 'microsoft', 'excel', 'powerpoint'],\n",
       " ['microsoft', 'excel', 'powerpoint', 'matlab'],\n",
       " ['excel', 'powerpoint', 'matlab', 'sql'],\n",
       " ['powerpoint', 'matlab', 'sql', 'pig'],\n",
       " ['matlab', 'sql', 'pig', 'microsoft'],\n",
       " ['sql', 'pig', 'microsoft', 'ibm'],\n",
       " ['pig', 'microsoft', 'ibm', 'watson'],\n",
       " ['microsoft', 'ibm', 'watson', 'microsoft'],\n",
       " ['ibm', 'watson', 'microsoft', 'aws'],\n",
       " ['watson', 'microsoft', 'aws', 'ibm'],\n",
       " ['microsoft', 'aws', 'ibm', 'sql'],\n",
       " ['aws', 'ibm', 'sql', 'python'],\n",
       " ['ibm', 'sql', 'python', 'r'],\n",
       " ['sql', 'python', 'r', 'sas'],\n",
       " ['python', 'r', 'sas', 'sql'],\n",
       " ['r', 'sas', 'sql', 'microsoft'],\n",
       " ['sas', 'sql', 'microsoft', 'azure'],\n",
       " ['sql', 'microsoft', 'azure', 'microsoft'],\n",
       " ['microsoft', 'azure', 'microsoft', 'aws'],\n",
       " ['azure', 'microsoft', 'aws', 'ibm'],\n",
       " ['microsoft', 'aws', 'ibm', 'sql'],\n",
       " ['aws', 'ibm', 'sql', 'java'],\n",
       " ['ibm', 'sql', 'java', 'c'],\n",
       " ['sql', 'java', 'c', 'r'],\n",
       " ['java', 'c', 'r', 'windows'],\n",
       " ['c', 'r', 'windows', 'r'],\n",
       " ['r', 'windows', 'r', 'excel'],\n",
       " ['windows', 'r', 'excel', 'salesforce'],\n",
       " ['r', 'excel', 'salesforce', 'sas'],\n",
       " ['excel', 'salesforce', 'sas', 'sas'],\n",
       " ['salesforce', 'sas', 'sas', 'sql'],\n",
       " ['sas', 'sas', 'sql', 'microsoft'],\n",
       " ['sas', 'sql', 'microsoft', 'powerpoint'],\n",
       " ['sql', 'microsoft', 'powerpoint', 'sas'],\n",
       " ['microsoft', 'powerpoint', 'sas', 'sas'],\n",
       " ['powerpoint', 'sas', 'sas', 'sas'],\n",
       " ['sas', 'sas', 'sas', 'sas'],\n",
       " ['sas', 'sas', 'sas', 'sas'],\n",
       " ['sas', 'sas', 'sas', 'sas'],\n",
       " ['sas', 'sas', 'sas', 'sql'],\n",
       " ['sas', 'sas', 'sql', 'r'],\n",
       " ['sas', 'sql', 'r', 'python'],\n",
       " ['sql', 'r', 'python', 'sas'],\n",
       " ['r', 'python', 'sas', 'python'],\n",
       " ['python', 'sas', 'python', 'sql'],\n",
       " ['sas', 'python', 'sql', 'nosql'],\n",
       " ['python', 'sql', 'nosql', 'r'],\n",
       " ['sql', 'nosql', 'r', 'hadoop'],\n",
       " ['nosql', 'r', 'hadoop', 'sql'],\n",
       " ['r', 'hadoop', 'sql', 'nlp'],\n",
       " ['hadoop', 'sql', 'nlp', 'nlp'],\n",
       " ['sql', 'nlp', 'nlp', 'nlp'],\n",
       " ['nlp', 'nlp', 'nlp', 'nlp'],\n",
       " ['nlp', 'nlp', 'nlp', 'sql'],\n",
       " ['nlp', 'nlp', 'sql', 'python'],\n",
       " ['nlp', 'sql', 'python', 'r'],\n",
       " ['sql', 'python', 'r', 'sql'],\n",
       " ['python', 'r', 'sql', 'jupyter'],\n",
       " ['r', 'sql', 'jupyter', 'sas'],\n",
       " ['sql', 'jupyter', 'sas', 'c'],\n",
       " ['jupyter', 'sas', 'c', 'java'],\n",
       " ['sas', 'c', 'java', 'ibm'],\n",
       " ['c', 'java', 'ibm', 'r'],\n",
       " ['java', 'ibm', 'r', 'excel'],\n",
       " ['ibm', 'r', 'excel', 'tableau'],\n",
       " ['r', 'excel', 'tableau', 'salesforce'],\n",
       " ['excel', 'tableau', 'salesforce', 'sap'],\n",
       " ['tableau', 'salesforce', 'sap', 'linux'],\n",
       " ['salesforce', 'sap', 'linux', 'tableau'],\n",
       " ['sap', 'linux', 'tableau', 'sql'],\n",
       " ['linux', 'tableau', 'sql', 'mongodb'],\n",
       " ['tableau', 'sql', 'mongodb', 'git'],\n",
       " ['sql', 'mongodb', 'git', 'r'],\n",
       " ['mongodb', 'git', 'r', 'nosql'],\n",
       " ['git', 'r', 'nosql', 'sql'],\n",
       " ['r', 'nosql', 'sql', 'sql'],\n",
       " ['nosql', 'sql', 'sql', 'tableau'],\n",
       " ['sql', 'sql', 'tableau', 'excel'],\n",
       " ['sql', 'tableau', 'excel', 'sas'],\n",
       " ['tableau', 'excel', 'sas', 'c'],\n",
       " ['excel', 'sas', 'c', 'sap'],\n",
       " ['sas', 'c', 'sap', 'r'],\n",
       " ['c', 'sap', 'r', 'python'],\n",
       " ['sap', 'r', 'python', 'nlp'],\n",
       " ['r', 'python', 'nlp', 'tableau'],\n",
       " ['python', 'nlp', 'tableau', 'microsoft'],\n",
       " ['nlp', 'tableau', 'microsoft', 'tensorflow'],\n",
       " ['tableau', 'microsoft', 'tensorflow', 'keras'],\n",
       " ['microsoft', 'tensorflow', 'keras', 'c'],\n",
       " ['tensorflow', 'keras', 'c', 'java'],\n",
       " ['keras', 'c', 'java', 'r'],\n",
       " ['c', 'java', 'r', 'keras'],\n",
       " ['java', 'r', 'keras', 'pytorch'],\n",
       " ['r', 'keras', 'pytorch', 'scikit'],\n",
       " ['keras', 'pytorch', 'scikit', 'learn'],\n",
       " ['pytorch', 'scikit', 'learn', 'r'],\n",
       " ['scikit', 'learn', 'r', 'sql'],\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:05.393315Z",
     "start_time": "2020-01-02T04:37:05.390072Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills = hope2[\"skills\"] #Our raw text complaints\n",
    "\n",
    "# tokenizer = Tokenizer() #Initialize a tokenizer.\n",
    "\n",
    "# tokenizer.fit_on_texts(skills) #Fit it to the complaints\n",
    "\n",
    "# sequences = tokenizer.texts_to_sequences(skills) #Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:13.179090Z",
     "start_time": "2020-01-02T04:37:12.911036Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english') + list(string.punctuation)\n",
    "# stop += [\"''\", '\"\"', '...', '``','--']\n",
    "# data = data.apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences) \n",
    "\n",
    "#Collecting some information   \n",
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
    "for i in range(len(sequences)):\n",
    "    n_sequences[i] = sequences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:14.505379Z",
     "start_time": "2020-01-02T04:37:14.501072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:16.278140Z",
     "start_time": "2020-01-02T04:37:16.275040Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs = n_sequences[:,:-1]\n",
    "train_targets = n_sequences[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:18.260576Z",
     "start_time": "2020-01-02T04:37:18.257222Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_targets = train_targets.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:18.663624Z",
     "start_time": "2020-01-02T04:37:18.659880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54,  1, 99, ..., 11,  5,  1], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:21.869280Z",
     "start_time": "2020-01-02T04:37:21.853800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47108, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_targets = to_categorical(train_targets, num_classes=vocabulary_size+1)\n",
    "seq_len = train_inputs.shape[1]\n",
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:23.996474Z",
     "start_time": "2020-01-02T04:37:23.993344Z"
    }
   },
   "outputs": [],
   "source": [
    "# The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "# It is a flexible layer that can be used in a variety of ways, such as:\n",
    "# It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
    "# It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "# It can be used to load a pre-trained word embedding model, a type of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:24.502452Z",
     "start_time": "2020-01-02T04:37:24.498710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:37:26.349360Z",
     "start_time": "2020-01-02T04:37:26.344387Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    opt_adam = optimizers.adam(lr=0.01)\n",
    "    #You can simply pass 'adam' to optimizer in compile method. Default learning rate 0.001\n",
    "    #But here we are using adam optimzer from optimizer class to change the LR.\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt_adam,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:40:13.125263Z",
     "start_time": "2020-01-02T04:37:42.217730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3, 3)              336       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3, 50)             10800     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 112)               5712      \n",
      "=================================================================\n",
      "Total params: 39,598\n",
      "Trainable params: 39,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "47108/47108 [==============================] - 3s 73us/step - loss: 3.4681 - acc: 0.1622\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.46811, saving model to checkpoint12\n",
      "Epoch 2/50\n",
      "47108/47108 [==============================] - 3s 57us/step - loss: 3.1625 - acc: 0.1987\n",
      "\n",
      "Epoch 00002: loss improved from 3.46811 to 3.16252, saving model to checkpoint12\n",
      "Epoch 3/50\n",
      "47108/47108 [==============================] - 3s 59us/step - loss: 2.9748 - acc: 0.2306\n",
      "\n",
      "Epoch 00003: loss improved from 3.16252 to 2.97478, saving model to checkpoint12\n",
      "Epoch 4/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 2.7826 - acc: 0.2748\n",
      "\n",
      "Epoch 00004: loss improved from 2.97478 to 2.78264, saving model to checkpoint12\n",
      "Epoch 5/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 2.5969 - acc: 0.3230\n",
      "\n",
      "Epoch 00005: loss improved from 2.78264 to 2.59694, saving model to checkpoint12\n",
      "Epoch 6/50\n",
      "47108/47108 [==============================] - 3s 59us/step - loss: 2.4243 - acc: 0.3716\n",
      "\n",
      "Epoch 00006: loss improved from 2.59694 to 2.42425, saving model to checkpoint12\n",
      "Epoch 7/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 2.2869 - acc: 0.4130\n",
      "\n",
      "Epoch 00007: loss improved from 2.42425 to 2.28691, saving model to checkpoint12\n",
      "Epoch 8/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 2.1870 - acc: 0.4360\n",
      "\n",
      "Epoch 00008: loss improved from 2.28691 to 2.18699, saving model to checkpoint12\n",
      "Epoch 9/50\n",
      "47108/47108 [==============================] - 3s 60us/step - loss: 2.0987 - acc: 0.4530\n",
      "\n",
      "Epoch 00009: loss improved from 2.18699 to 2.09867, saving model to checkpoint12\n",
      "Epoch 10/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 2.0380 - acc: 0.4691\n",
      "\n",
      "Epoch 00010: loss improved from 2.09867 to 2.03795, saving model to checkpoint12\n",
      "Epoch 11/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.9771 - acc: 0.4844\n",
      "\n",
      "Epoch 00011: loss improved from 2.03795 to 1.97707, saving model to checkpoint12\n",
      "Epoch 12/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 1.9212 - acc: 0.4973\n",
      "\n",
      "Epoch 00012: loss improved from 1.97707 to 1.92118, saving model to checkpoint12\n",
      "Epoch 13/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.8772 - acc: 0.5062\n",
      "\n",
      "Epoch 00013: loss improved from 1.92118 to 1.87715, saving model to checkpoint12\n",
      "Epoch 14/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.8517 - acc: 0.5094\n",
      "\n",
      "Epoch 00014: loss improved from 1.87715 to 1.85166, saving model to checkpoint12\n",
      "Epoch 15/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.8084 - acc: 0.5207\n",
      "\n",
      "Epoch 00015: loss improved from 1.85166 to 1.80844, saving model to checkpoint12\n",
      "Epoch 16/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 1.7862 - acc: 0.5230\n",
      "\n",
      "Epoch 00016: loss improved from 1.80844 to 1.78619, saving model to checkpoint12\n",
      "Epoch 17/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.7671 - acc: 0.5271\n",
      "\n",
      "Epoch 00017: loss improved from 1.78619 to 1.76710, saving model to checkpoint12\n",
      "Epoch 18/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.7313 - acc: 0.5343\n",
      "\n",
      "Epoch 00018: loss improved from 1.76710 to 1.73134, saving model to checkpoint12\n",
      "Epoch 19/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.7112 - acc: 0.5387\n",
      "\n",
      "Epoch 00019: loss improved from 1.73134 to 1.71120, saving model to checkpoint12\n",
      "Epoch 20/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.6942 - acc: 0.5420\n",
      "\n",
      "Epoch 00020: loss improved from 1.71120 to 1.69418, saving model to checkpoint12\n",
      "Epoch 21/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.6674 - acc: 0.5495\n",
      "\n",
      "Epoch 00021: loss improved from 1.69418 to 1.66742, saving model to checkpoint12\n",
      "Epoch 22/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.6454 - acc: 0.5504\n",
      "\n",
      "Epoch 00022: loss improved from 1.66742 to 1.64543, saving model to checkpoint12\n",
      "Epoch 23/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.6316 - acc: 0.5535\n",
      "\n",
      "Epoch 00023: loss improved from 1.64543 to 1.63163, saving model to checkpoint12\n",
      "Epoch 24/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.6289 - acc: 0.5561\n",
      "\n",
      "Epoch 00024: loss improved from 1.63163 to 1.62889, saving model to checkpoint12\n",
      "Epoch 25/50\n",
      "47108/47108 [==============================] - 3s 70us/step - loss: 1.6135 - acc: 0.5590\n",
      "\n",
      "Epoch 00025: loss improved from 1.62889 to 1.61352, saving model to checkpoint12\n",
      "Epoch 26/50\n",
      "47108/47108 [==============================] - 3s 70us/step - loss: 1.6004 - acc: 0.5614\n",
      "\n",
      "Epoch 00026: loss improved from 1.61352 to 1.60039, saving model to checkpoint12\n",
      "Epoch 27/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.5938 - acc: 0.5625\n",
      "\n",
      "Epoch 00027: loss improved from 1.60039 to 1.59382, saving model to checkpoint12\n",
      "Epoch 28/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5809 - acc: 0.5649\n",
      "\n",
      "Epoch 00028: loss improved from 1.59382 to 1.58086, saving model to checkpoint12\n",
      "Epoch 29/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5703 - acc: 0.5668\n",
      "\n",
      "Epoch 00029: loss improved from 1.58086 to 1.57030, saving model to checkpoint12\n",
      "Epoch 30/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.5564 - acc: 0.5707\n",
      "\n",
      "Epoch 00030: loss improved from 1.57030 to 1.55645, saving model to checkpoint12\n",
      "Epoch 31/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5388 - acc: 0.5748\n",
      "\n",
      "Epoch 00031: loss improved from 1.55645 to 1.53885, saving model to checkpoint12\n",
      "Epoch 32/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5319 - acc: 0.5757\n",
      "\n",
      "Epoch 00032: loss improved from 1.53885 to 1.53188, saving model to checkpoint12\n",
      "Epoch 33/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5290 - acc: 0.5747\n",
      "\n",
      "Epoch 00033: loss improved from 1.53188 to 1.52895, saving model to checkpoint12\n",
      "Epoch 34/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5202 - acc: 0.5777\n",
      "\n",
      "Epoch 00034: loss improved from 1.52895 to 1.52020, saving model to checkpoint12\n",
      "Epoch 35/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5026 - acc: 0.5822\n",
      "\n",
      "Epoch 00035: loss improved from 1.52020 to 1.50257, saving model to checkpoint12\n",
      "Epoch 36/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.5103 - acc: 0.5803\n",
      "\n",
      "Epoch 00036: loss did not improve from 1.50257\n",
      "Epoch 37/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.4955 - acc: 0.5806\n",
      "\n",
      "Epoch 00037: loss improved from 1.50257 to 1.49555, saving model to checkpoint12\n",
      "Epoch 38/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.5118 - acc: 0.5787\n",
      "\n",
      "Epoch 00038: loss did not improve from 1.49555\n",
      "Epoch 39/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.4793 - acc: 0.5861\n",
      "\n",
      "Epoch 00039: loss improved from 1.49555 to 1.47932, saving model to checkpoint12\n",
      "Epoch 40/50\n",
      "47108/47108 [==============================] - 3s 65us/step - loss: 1.5098 - acc: 0.5791\n",
      "\n",
      "Epoch 00040: loss did not improve from 1.47932\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47108/47108 [==============================] - 3s 60us/step - loss: 1.4742 - acc: 0.5869\n",
      "\n",
      "Epoch 00041: loss improved from 1.47932 to 1.47421, saving model to checkpoint12\n",
      "Epoch 42/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.4570 - acc: 0.5910\n",
      "\n",
      "Epoch 00042: loss improved from 1.47421 to 1.45703, saving model to checkpoint12\n",
      "Epoch 43/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 1.4581 - acc: 0.5867\n",
      "\n",
      "Epoch 00043: loss did not improve from 1.45703\n",
      "Epoch 44/50\n",
      "47108/47108 [==============================] - 3s 63us/step - loss: 1.4460 - acc: 0.5928\n",
      "\n",
      "Epoch 00044: loss improved from 1.45703 to 1.44596, saving model to checkpoint12\n",
      "Epoch 45/50\n",
      "47108/47108 [==============================] - 3s 61us/step - loss: 1.4532 - acc: 0.5884\n",
      "\n",
      "Epoch 00045: loss did not improve from 1.44596\n",
      "Epoch 46/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.4578 - acc: 0.5888\n",
      "\n",
      "Epoch 00046: loss did not improve from 1.44596\n",
      "Epoch 47/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.4465 - acc: 0.5931\n",
      "\n",
      "Epoch 00047: loss did not improve from 1.44596\n",
      "Epoch 48/50\n",
      "47108/47108 [==============================] - 3s 64us/step - loss: 1.4426 - acc: 0.5899\n",
      "\n",
      "Epoch 00048: loss improved from 1.44596 to 1.44260, saving model to checkpoint12\n",
      "Epoch 49/50\n",
      "47108/47108 [==============================] - 3s 66us/step - loss: 1.4528 - acc: 0.5896\n",
      "\n",
      "Epoch 00049: loss did not improve from 1.44260\n",
      "Epoch 50/50\n",
      "47108/47108 [==============================] - 3s 62us/step - loss: 1.4766 - acc: 0.5845\n",
      "\n",
      "Epoch 00050: loss did not improve from 1.44260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d43ea58>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)\n",
    "path = 'checkpoint12'\n",
    "checkpoint = ModelCheckpoint(path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(train_inputs,train_targets,batch_size=128,epochs=50,verbose=1,callbacks=[checkpoint])\n",
    "# pickle.dump(tokenizer,open('tokenizer_Model4','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:44:16.875647Z",
     "start_time": "2020-01-02T04:40:29.419831Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===>Enter --exit to exit from the program\n",
      "Enter string: data scientist\n",
      "         Percentage\n",
      "Tech               \n",
      "python         49.3\n",
      "r              49.1\n",
      "sql             0.3\n",
      "scala           0.2\n",
      "tableau         0.2\n",
      "aws             0.2\n",
      "nlp             0.2\n",
      "spark           0.1\n",
      "linux           0.1\n",
      "sas             0.1\n",
      "Enter string: data analyst\n",
      "         Percentage\n",
      "Tech               \n",
      "python         49.3\n",
      "r              49.1\n",
      "sql             0.3\n",
      "scala           0.2\n",
      "tableau         0.2\n",
      "aws             0.2\n",
      "nlp             0.2\n",
      "spark           0.1\n",
      "linux           0.1\n",
      "sas             0.1\n",
      "Enter string: --exit\n"
     ]
    }
   ],
   "source": [
    "model = load_model('checkpoint12')\n",
    "# tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "seq_len = 3 \n",
    "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' '+pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)\n",
    "\n",
    "print('\\n\\n===>Enter --exit to exit from the program')\n",
    "while True:\n",
    "    seed_text  = input('Enter string: ')\n",
    "    if seed_text.lower() == '--exit':\n",
    "        break\n",
    "    else:\n",
    "        out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=1000)\n",
    "#         print('Output: '+seed_text+' '+out)\n",
    "        out_list = out.split()\n",
    "        out_total = Counter(out_list)\n",
    "        total = sum(out_total.values())\n",
    "        out_length = len(out_total)\n",
    "        out_dict = [(i, out_total[i] / total * 100.0) for i in out_total]\n",
    "        out_result = pd.DataFrame(out_dict, columns=['Tech','Percentage'])\n",
    "        out_result_chart = out_result.sort_values('Percentage', ascending=False).head(10)\n",
    "        output_chart = out_result_chart.set_index('Tech', drop=True)\n",
    "        print(output_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('checkpoint4')\n",
    "# # tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "# seq_len = 3 \n",
    "# def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "#     output_text = []\n",
    "#     input_text = seed_text\n",
    "#     for i in range(num_gen_words):\n",
    "#         encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "#         pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "#         pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "#         pred_word = tokenizer.index_word[pred_word_ind]\n",
    "#         targets = str()\n",
    "#         for word in pred_word:\n",
    "#             if word in search_terms:\n",
    "#                 targets+word\n",
    "                \n",
    "#         input_text += ' '+targets\n",
    "#         output_text.append(targets)\n",
    "#     return ' '.join(output_text)\n",
    "\n",
    "# print('\\n\\n===>Enter --exit to exit from the program')\n",
    "# while True:\n",
    "#     seed_text  = input('Enter string: ')\n",
    "#     if seed_text.lower() == '--exit':\n",
    "#         break\n",
    "#     else:\n",
    "#         out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=5)\n",
    "#         print('Output: '+seed_text+' '+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df.title\n",
    "# data = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_target = set(target)\n",
    "# target_classes = len(total_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_vocabulary = set(word for description in data for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(total_vocabulary)\n",
    "# print(\"There are {} unique tokens in the dataset.\".format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove = {}\n",
    "# with open('glove.6B.50d.txt', 'rb') as f:\n",
    "#     for line in f:\n",
    "#         parts = line.split()\n",
    "#         word = parts[0].decode('utf-8')\n",
    "#         if word in total_vocabulary:\n",
    "#             vector = np.array(parts[1:], dtype=np.float32)\n",
    "#             glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove['java']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class W2vVectorizer(object):\n",
    "    \n",
    "#     def __init__(self, w2v):\n",
    "#         # takes in a dictionary of words and vectors as input\n",
    "#         self.w2v = w2v\n",
    "#         if len(w2v) == 0:\n",
    "#             self.dimensions = 0\n",
    "#         else:\n",
    "#             self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "#     # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "#     # It can't be used in a sklearn Pipeline. \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "            \n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "#                    or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
