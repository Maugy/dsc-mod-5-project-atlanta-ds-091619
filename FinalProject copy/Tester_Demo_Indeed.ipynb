{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.023971Z",
     "start_time": "2020-01-02T15:29:47.831793Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.753243Z",
     "start_time": "2020-01-02T15:29:49.026265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "import WebScrape_Indeed\n",
    "import WebScrape_LinkedIn\n",
    "import streamlit as st \n",
    "import terms \n",
    "import Cities \n",
    "import functions\n",
    "import time\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig\n",
    "\n",
    "import chart_studio.plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "import pydeck as pdk\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)   \n",
    "\n",
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.757703Z",
     "start_time": "2020-01-02T15:29:49.755308Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.765678Z",
     "start_time": "2020-01-02T15:29:49.759818Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.786477Z",
     "start_time": "2020-01-02T15:29:49.768457Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.792957Z",
     "start_time": "2020-01-02T15:29:49.788081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import (make_blobs,\n",
    "                                                make_circles,\n",
    "                                                make_moons)\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('fivethirtyeight')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:49.799595Z",
     "start_time": "2020-01-02T15:29:49.795104Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:50.078076Z",
     "start_time": "2020-01-02T15:29:49.801731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:52.118109Z",
     "start_time": "2020-01-02T15:29:50.079593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:29:52.129957Z",
     "start_time": "2020-01-02T15:29:52.119595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Web Scrape - Indeed\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "import streamlit as st\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "# from google.cloud import bigquery, storage\n",
    "# from google_pandas_load import Loader, LoaderQuickSetup\n",
    "# from google_pandas_load import LoadConfig\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/users/dmauger/Flatiron/FinalProject/WebScraping-676f89d97ac9.json\"\n",
    "\n",
    "# project_id = 'webscraping-261119'\n",
    "# dataset_id = 'Web_Scraping'\n",
    "# bucket_name = 'web_scrape_data'\n",
    "# gs_dir_path = 'https://storage.googleapis.com'\n",
    "# local_dir_path = '/users/dmauger/Flatiron/FinalProject/'\n",
    "# job_config = bigquery.LoadJobConfig()\n",
    "# job_config.autodetect = True\n",
    "# job_config.source_format = bigquery.SourceFormat.CSV\n",
    "# # bq_schema = [bigquery.SchemaField(name='title', field_type='STRING'),\n",
    "# #              bigquery.SchemaField(name='company', field_type='STRING'),\n",
    "# #              bigquery.SchemaField(name='location', field_type='STRING'),\n",
    "# #              bigquery.SchemaField(name='description', field_type='STRING')]\n",
    "\n",
    "# if not os.path.isdir(local_dir_path):\n",
    "#     os.makedirs(local_dir_path)\n",
    "\n",
    "\n",
    "\n",
    "# bq_client = bigquery.Client(\n",
    "#     project=project_id,\n",
    "#     credentials=None)\n",
    "\n",
    "\n",
    "# dataset_ref = bigquery.dataset.DatasetReference(\n",
    "#     project=project_id,\n",
    "#     dataset_id=dataset_id)\n",
    "\n",
    "\n",
    "# gs_client = storage.Client(\n",
    "#     project=project_id,\n",
    "#     credentials=None)\n",
    "\n",
    "# bucket = storage.bucket.Bucket(\n",
    "#     client=gs_client,\n",
    "#     name=bucket_name)\n",
    "\n",
    "# gpl = Loader(\n",
    "#     bq_client=bq_client,\n",
    "#     dataset_ref=dataset_ref,\n",
    "#     bucket=bucket,\n",
    "#     gs_dir_path=gs_dir_path,\n",
    "#     local_dir_path=local_dir_path, compress=False)\n",
    "\n",
    "\n",
    "    \n",
    "data = {'title': [],\n",
    "        'company': [], \n",
    "        'location': [],\n",
    "        'description': [],\n",
    "        'date': [],}\n",
    "\n",
    "# @st.cache(show_spinner=True, allow_output_mutation=True, suppress_st_warning=True)\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    clean = re.sub(cleanr, ' ', str(raw_html))\n",
    "    cleaner = clean.strip()\n",
    "    cleantext = re.sub('\\n', ' ', cleaner)\n",
    "    return cleantext\n",
    "\n",
    "# @st.cache(show_spinner=True, allow_output_mutation=True, suppress_st_warning=True)\n",
    "def export_table(data):\n",
    "    table = pd.DataFrame(data, columns=['title', 'company', 'location', 'description', 'date'])\n",
    "    table.index = table.index + 1\n",
    "    table.to_csv('/users/dmauger/Flatiron/FinalProject/' + 'demo_indeed_webscrape.csv', mode='a', encoding='utf-8', index=False, header=False)\n",
    "    # gpl.load(source='dataframe', destination='bq', data_name='total_data', dataframe=table, write_disposition='WRITE_APPEND', compress=False)\n",
    "    return table\n",
    "    # print('Scraping done. Here are the results:')\n",
    "    # print(table.info())\n",
    "\n",
    "# @st.cache(show_spinner=True, allow_output_mutation=True, suppress_st_warning=True)\n",
    "# def export_storage(table):\n",
    "#     table.to_csv('/users/dmauger/Flatiron/FinalProject/' + 'total_data_date.csv', mode='a', encoding='utf-8', index=False, header=False)\n",
    "#     gpl.load(source='local', destination='gs', data_name='total_data_date.csv', write_disposition='WRITE_APPEND')\n",
    "#     print('Process completed.')\n",
    "\n",
    "# @st.cache(show_spinner=True, allow_output_mutation=True, suppress_st_warning=True)\n",
    "def job_details(job):\n",
    "\n",
    "    r = requests.get(job)\n",
    "    r.encoding = 'utf-8'\n",
    "    sleep(1)\n",
    "\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        title = soup.find('h3', class_='jobsearch-JobInfoHeader-title').text\n",
    "    except:\n",
    "        title = 'NaN'\n",
    "\n",
    "    try:\n",
    "        company = soup.find_all(\n",
    "            'div', class_=\"jobsearch-InlineCompanyRating\")[-1].find_all('div')[0].text\n",
    "    except:\n",
    "        company = 'NaN'\n",
    "\n",
    "    try:\n",
    "        location = soup.find_all(\n",
    "            'div', class_=\"jobsearch-InlineCompanyRating\")[-1].find_all('div')[-1].text\n",
    "    except:\n",
    "        location = 'NaN'\n",
    "\n",
    "    try:\n",
    "        description = soup.find_all(\n",
    "            'div', class_=\"jobsearch-JobComponent-description\")\n",
    "    except:\n",
    "        description = 'NaN'\n",
    "\n",
    "    data['title'].append(title)\n",
    "    data['company'].append(company)\n",
    "    data['location'].append(location)\n",
    "    data['description'].append(cleanhtml(description))\n",
    "    data['date'] = datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# @st.cache(show_spinner=True, allow_output_mutation=True, suppress_st_warning=True)\n",
    "def extract_title(ind_url):\n",
    "\n",
    "    sleep(1)\n",
    "    page = requests.get(ind_url)\n",
    "    bs = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    links = []\n",
    "    for div in bs.find_all('div', class_=\"title\"):\n",
    "        for a in div.find_all('a', href=True):\n",
    "            links.append(urljoin('https://indeed.com', a['href']))\n",
    "\n",
    "    for job in links:\n",
    "        job_details(job)\n",
    "\n",
    "    # next_page_text = bs.find('div', class_=\"pagination\").find_all('a')\n",
    "    # next_page = [link.get('href') for link in next_page_text][-1]\n",
    "\n",
    "    # if '&start=20' not in next_page:\n",
    "    #     next_page_url = (urljoin('https://indeed.com', cleanhtml(next_page)))\n",
    "    #     print(next_page_url)\n",
    "    #     extract_title(next_page_url)\n",
    "    # else:\n",
    "    #     export_table(data)\n",
    "\n",
    "    return export_table(data)\n",
    "\n",
    "# cit = st.text_input('Enter city')\n",
    "# stat = st.text_input('Enter state')\n",
    "# city = str(cit.replace(' ', '+'))\n",
    "# state = str(stat.replace(' ','+'))\n",
    "# location = city+\"%2C+\"+state+\"&radius=50&sort=date\"\n",
    "\n",
    "# search_url = \"https://www.indeed.com/jobs?q=title%3A(%22data+scientist%22+OR+%22data+science%22+OR+%22data+analyst%22)&l=\"+location\n",
    "\n",
    "# extract_title(search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:36:57.506635Z",
     "start_time": "2020-01-02T15:36:57.504126Z"
    }
   },
   "outputs": [],
   "source": [
    "search_url = \"https://www.indeed.com/jobs?q=title%3A(%22machine+learning%22)&l=United+States&sort=date\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:37:31.172998Z",
     "start_time": "2020-01-02T15:36:58.004009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Amiti Consulting Corp</td>\n",
       "      <td>San Ramon, CA</td>\n",
       "      <td>[    Job Summary   Job Title: Data Analyst  *L...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Amiti Consulting Corp</td>\n",
       "      <td>San Ramon, CA</td>\n",
       "      <td>[    Job Summary   Job Title: Data Analyst  *L...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>HCL Americas</td>\n",
       "      <td>King County, WA</td>\n",
       "      <td>[  To develop and deliver codes for the work a...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Lincoln Financial</td>\n",
       "      <td>Philadelphia, PA 19103</td>\n",
       "      <td>[    Alternate Locations: 13378; 14457; 16819;...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>pureIntegration</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>[  pureIntegration is seeking a Junior Data An...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Kobre &amp; Kim LLP</td>\n",
       "      <td>New York, NY 10106</td>\n",
       "      <td>[    Senior Data Analyst    Job Description:  ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Writer/Data Analyst</td>\n",
       "      <td>Blackstone Laboratories</td>\n",
       "      <td>Fort Wayne, IN 46806</td>\n",
       "      <td>[   We are a small, local laboratory, adding m...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Riverstone Solutions, Inc.</td>\n",
       "      <td>Huntsville, AL 35806</td>\n",
       "      <td>[   Riverstone Solutions is seeking a Senior D...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - 17549</td>\n",
       "      <td>Knoxville Utilities Board</td>\n",
       "      <td>Knoxville, TN 37921</td>\n",
       "      <td>[    *To be considered for this job, you must ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>comScore, Inc.</td>\n",
       "      <td>Boston, MA 02116</td>\n",
       "      <td>[   Job Description:   Job Title: Associate Da...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Colonial Savings</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>[    JOB DESCRIPTION     Company:  Colonial Sa...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Catastrophe Data Analyst</td>\n",
       "      <td>IFG Companies</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>[   POSITION SUMMARY / OBJECTIVE  This positio...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jr. Business Data Analyst</td>\n",
       "      <td>WebFX, Inc.</td>\n",
       "      <td>Harrisburg, PA 17102</td>\n",
       "      <td>[  WebFX is looking for qualified candidates t...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mapping and Data Analyst</td>\n",
       "      <td>Mountrail-Williams Electric Cooperative</td>\n",
       "      <td>Williston, ND 58801</td>\n",
       "      <td>[   MAPPING AND DATA ANALYST Mountrail-William...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Riverstone Solutions, Inc.</td>\n",
       "      <td>Huntsville, AL 35806</td>\n",
       "      <td>[   Riverstone Solutions is seeking a Senior D...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sage Management</td>\n",
       "      <td>Ashburn, VA 20147</td>\n",
       "      <td>[   We are looking for a passionate Data Analy...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>National Mortgage Bank</td>\n",
       "      <td>Des Plaines, IL</td>\n",
       "      <td>[   We are a National Bank/Mortgage Lender cur...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Geo-Med, LLC</td>\n",
       "      <td>Lake Mary, FL</td>\n",
       "      <td>[   Geo-Med is a Medical/Surgical supplier foc...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>[    With one application you can be considere...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MRP</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>[   A well funded start-up in the Chinatown ne...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Canopie One Inc</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>[    Job Summary   Job Title:   Data Scientist...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>pureIntegration</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>[  pureIntegration is seeking a Junior Data Sc...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Decode_M</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>[     About Us     Decode_M is a new kind of i...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Social Science Research Solutions (SSRS)</td>\n",
       "      <td>Glen Mills, PA</td>\n",
       "      <td>[      SSRS Data Scientist    SSRS, a leading ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Decode_M</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>[     About Us     Decode_M is a new kind of i...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Associate Director, Data Scientist</td>\n",
       "      <td>OMD</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>[      Associate Director, Data Scientist     ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Cylance, Inc.</td>\n",
       "      <td>Irvine, CA 92618</td>\n",
       "      <td>[       Worker Sub-Type:   Regular      Job De...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[      We’re looking for intelligent, creative...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>SFL Scientific</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>[   SFL Scientific is expanding our data scien...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Trademark Global, LLC</td>\n",
       "      <td>Lorain, OH 44053</td>\n",
       "      <td>[   Trademark Global, LLC (TM) is a private eq...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bossanova Robotics</td>\n",
       "      <td>Pittsburgh, PA 15222</td>\n",
       "      <td>[    Bossa Nova is the leading provider of rea...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>[      As a Data Scientist for the CIA, you wi...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Senior Healthcare Data Scientist</td>\n",
       "      <td>VBCare Network</td>\n",
       "      <td>Phoenix, AZ 85034</td>\n",
       "      <td>[    TITLE: SENIOR HEALTHCARE INFORMATION SCIE...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Big Y Foods, Inc</td>\n",
       "      <td>Springfield, MA 01104</td>\n",
       "      <td>[   Our database Marketing scientist is respon...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>[    With one application you can be considere...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>National Geospatial-Intelligence Agency</td>\n",
       "      <td>Wright-Patterson AFB, OH</td>\n",
       "      <td>[   Data Scientists develop and apply methods ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ORANGE BUICK GMC</td>\n",
       "      <td>Orlando, FL 32808</td>\n",
       "      <td>[     **An assessment is attached to this appl...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>NU Borders</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>[    Strict Requirement:   Candidate must be a...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rust Developer for Data and AI Machine Learnin...</td>\n",
       "      <td>B23 LLC</td>\n",
       "      <td>Tysons, VA 22102</td>\n",
       "      <td>[    B23  is a product-enabled data and softwa...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Canopie One Inc</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>[    Job Summary   Job Title:   Machine Learni...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[    Machine Learning Engineer   Contribute to...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Research Scientist - Machine Learning and Comp...</td>\n",
       "      <td>ObjectVideo Labs, LLC</td>\n",
       "      <td>Tysons, VA 22102</td>\n",
       "      <td>[    Research Scientist - Machine Learning and...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Senior Natural Language AI &amp; Machine Learning ...</td>\n",
       "      <td>care.coach corporation</td>\n",
       "      <td>Millbrae, CA</td>\n",
       "      <td>[    Core Responsibilities :   Coordinate with...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Teaching Assistant - AI &amp; Machine Learning (Te...</td>\n",
       "      <td>Digital Media Academy</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>[    Our Story   Founded on the campus of Stan...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Entry Level Machine Learning Engineer (Freshers)</td>\n",
       "      <td>Core Software Tech</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>[     Job Description    We are looking for fr...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Learn Ventures</td>\n",
       "      <td>Cambridge, MA 02139</td>\n",
       "      <td>[   Learn Ventures seeks a full-time Machine L...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Maps Data and Machine Learning Internship</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Santa Clara Valley, CA 95014</td>\n",
       "      <td>[       Summary    Posted:  Dec 31, 2019    We...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Data Scientist/Machine Learning Expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[    SphereOI helps clients succeed with advan...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sr Computer Vision / Machine Learning Engineer...</td>\n",
       "      <td>LG Electronics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>[      At LG's Future Experiences team we’re c...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Software Engineer, Computer Vision / Machine L...</td>\n",
       "      <td>Leia</td>\n",
       "      <td>Menlo Park, CA 94025</td>\n",
       "      <td>[    What You’ll Do      As a Software Enginee...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Artificial Intelligence and Machine Learning E...</td>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>Cincinnati, OH 45201</td>\n",
       "      <td>[  P&amp;amp;G is the largest consumer packaged go...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Principal Machine Learning Scientist</td>\n",
       "      <td>Best Buy</td>\n",
       "      <td>Richfield, MN 55423</td>\n",
       "      <td>[    Best Buy has the third largest eCommerce ...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sr. Manager Machine Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[   McLean 1 (19050), United States of America...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Vody</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>[   Vody is a venture-backed startup focused o...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Triplebyte</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>[    About Triplebyte  Triplebyte helps compan...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>[       Summary    Posted:  Aug 14, 2019    Ro...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Kimberly-Clark Corporation, LLC</td>\n",
       "      <td>Neenah, WI 54956</td>\n",
       "      <td>[   Machine Learning Engineer     Job Descript...</td>\n",
       "      <td>01-02-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "1                                        Data Analyst   \n",
       "2                                        Data Analyst   \n",
       "3                                 Junior Data Analyst   \n",
       "4                                 Senior Data Analyst   \n",
       "5                                 Junior Data Analyst   \n",
       "6                                 Senior Data Analyst   \n",
       "7                                 Writer/Data Analyst   \n",
       "8                                        Data Analyst   \n",
       "9                                Data Analyst - 17549   \n",
       "10                             Associate Data Analyst   \n",
       "11                                    Data Analyst II   \n",
       "12                           Catastrophe Data Analyst   \n",
       "13                          Jr. Business Data Analyst   \n",
       "14                           Mapping and Data Analyst   \n",
       "15                                       Data Analyst   \n",
       "16                                       Data Analyst   \n",
       "17                                       Data Analyst   \n",
       "18                                Junior Data Analyst   \n",
       "19                                       Data Analyst   \n",
       "20                                     Data Scientist   \n",
       "21                                     Data Scientist   \n",
       "22                              Junior Data Scientist   \n",
       "23                              Junior Data Scientist   \n",
       "24                                     Data Scientist   \n",
       "25                              Senior Data Scientist   \n",
       "26                 Associate Director, Data Scientist   \n",
       "27                              Senior Data Scientist   \n",
       "28                                     Data Scientist   \n",
       "29                              Senior Data Scientist   \n",
       "30                                     Data Scientist   \n",
       "31                                     Data Scientist   \n",
       "32                                     Data Scientist   \n",
       "33                   Senior Healthcare Data Scientist   \n",
       "34                                     Data Scientist   \n",
       "35                                     Data Scientist   \n",
       "36                         Data Scientist - Mid-Level   \n",
       "37                                     Data Scientist   \n",
       "38                              Junior Data Scientist   \n",
       "39  Rust Developer for Data and AI Machine Learnin...   \n",
       "40                          Machine Learning Engineer   \n",
       "41                          Machine Learning Engineer   \n",
       "42  Research Scientist - Machine Learning and Comp...   \n",
       "43  Senior Natural Language AI & Machine Learning ...   \n",
       "44  Teaching Assistant - AI & Machine Learning (Te...   \n",
       "45   Entry Level Machine Learning Engineer (Freshers)   \n",
       "46                          Machine Learning Engineer   \n",
       "47          Maps Data and Machine Learning Internship   \n",
       "48             Data Scientist/Machine Learning Expert   \n",
       "49  Sr Computer Vision / Machine Learning Engineer...   \n",
       "50  Software Engineer, Computer Vision / Machine L...   \n",
       "51  Artificial Intelligence and Machine Learning E...   \n",
       "52               Principal Machine Learning Scientist   \n",
       "53                       Sr. Manager Machine Learning   \n",
       "54                          Machine Learning Engineer   \n",
       "55                          Machine Learning Engineer   \n",
       "56                          Machine Learning Engineer   \n",
       "57                          Machine Learning Engineer   \n",
       "\n",
       "                                     company                      location  \\\n",
       "1                      Amiti Consulting Corp                 San Ramon, CA   \n",
       "2                      Amiti Consulting Corp                 San Ramon, CA   \n",
       "3                               HCL Americas               King County, WA   \n",
       "4                          Lincoln Financial        Philadelphia, PA 19103   \n",
       "5                            pureIntegration              Philadelphia, PA   \n",
       "6                            Kobre & Kim LLP            New York, NY 10106   \n",
       "7                    Blackstone Laboratories          Fort Wayne, IN 46806   \n",
       "8                 Riverstone Solutions, Inc.          Huntsville, AL 35806   \n",
       "9                  Knoxville Utilities Board           Knoxville, TN 37921   \n",
       "10                            comScore, Inc.              Boston, MA 02116   \n",
       "11                          Colonial Savings                Fort Worth, TX   \n",
       "12                             IFG Companies                   Atlanta, GA   \n",
       "13                               WebFX, Inc.          Harrisburg, PA 17102   \n",
       "14   Mountrail-Williams Electric Cooperative           Williston, ND 58801   \n",
       "15                Riverstone Solutions, Inc.          Huntsville, AL 35806   \n",
       "16                           Sage Management             Ashburn, VA 20147   \n",
       "17                    National Mortgage Bank               Des Plaines, IL   \n",
       "18                              Geo-Med, LLC                 Lake Mary, FL   \n",
       "19                            Seen by Indeed                   Atlanta, GA   \n",
       "20                                       MRP                Washington, DC   \n",
       "21                           Canopie One Inc                    Irving, TX   \n",
       "22                           pureIntegration              Philadelphia, PA   \n",
       "23                                  Decode_M                  New York, NY   \n",
       "24  Social Science Research Solutions (SSRS)                Glen Mills, PA   \n",
       "25                                  Decode_M                  New York, NY   \n",
       "26                                       OMD                   Burbank, CA   \n",
       "27                             Cylance, Inc.              Irvine, CA 92618   \n",
       "28                                       NaN                           NaN   \n",
       "29                            SFL Scientific                    Boston, MA   \n",
       "30                     Trademark Global, LLC              Lorain, OH 44053   \n",
       "31                        Bossanova Robotics          Pittsburgh, PA 15222   \n",
       "32               Central Intelligence Agency                Washington, DC   \n",
       "33                            VBCare Network             Phoenix, AZ 85034   \n",
       "34                          Big Y Foods, Inc         Springfield, MA 01104   \n",
       "35                            Seen by Indeed                Washington, DC   \n",
       "36   National Geospatial-Intelligence Agency      Wright-Patterson AFB, OH   \n",
       "37                          ORANGE BUICK GMC             Orlando, FL 32808   \n",
       "38                                NU Borders              Reston, VA 20190   \n",
       "39                                   B23 LLC              Tysons, VA 22102   \n",
       "40                           Canopie One Inc                    Irving, TX   \n",
       "41                                       NaN                           NaN   \n",
       "42                     ObjectVideo Labs, LLC              Tysons, VA 22102   \n",
       "43                    care.coach corporation                  Millbrae, CA   \n",
       "44                     Digital Media Academy                 Palo Alto, CA   \n",
       "45                        Core Software Tech                 Princeton, NJ   \n",
       "46                            Learn Ventures           Cambridge, MA 02139   \n",
       "47                                     Apple  Santa Clara Valley, CA 95014   \n",
       "48                                       NaN                           NaN   \n",
       "49                            LG Electronics               Santa Clara, CA   \n",
       "50                                      Leia          Menlo Park, CA 94025   \n",
       "51                          Procter & Gamble          Cincinnati, OH 45201   \n",
       "52                                  Best Buy           Richfield, MN 55423   \n",
       "53                                       NaN                           NaN   \n",
       "54                                      Vody               Los Angeles, CA   \n",
       "55                                Triplebyte                   Seattle, WA   \n",
       "56                                     Apple                Pittsburgh, PA   \n",
       "57           Kimberly-Clark Corporation, LLC              Neenah, WI 54956   \n",
       "\n",
       "                                          description        date  \n",
       "1   [    Job Summary   Job Title: Data Analyst  *L...  01-02-2020  \n",
       "2   [    Job Summary   Job Title: Data Analyst  *L...  01-02-2020  \n",
       "3   [  To develop and deliver codes for the work a...  01-02-2020  \n",
       "4   [    Alternate Locations: 13378; 14457; 16819;...  01-02-2020  \n",
       "5   [  pureIntegration is seeking a Junior Data An...  01-02-2020  \n",
       "6   [    Senior Data Analyst    Job Description:  ...  01-02-2020  \n",
       "7   [   We are a small, local laboratory, adding m...  01-02-2020  \n",
       "8   [   Riverstone Solutions is seeking a Senior D...  01-02-2020  \n",
       "9   [    *To be considered for this job, you must ...  01-02-2020  \n",
       "10  [   Job Description:   Job Title: Associate Da...  01-02-2020  \n",
       "11  [    JOB DESCRIPTION     Company:  Colonial Sa...  01-02-2020  \n",
       "12  [   POSITION SUMMARY / OBJECTIVE  This positio...  01-02-2020  \n",
       "13  [  WebFX is looking for qualified candidates t...  01-02-2020  \n",
       "14  [   MAPPING AND DATA ANALYST Mountrail-William...  01-02-2020  \n",
       "15  [   Riverstone Solutions is seeking a Senior D...  01-02-2020  \n",
       "16  [   We are looking for a passionate Data Analy...  01-02-2020  \n",
       "17  [   We are a National Bank/Mortgage Lender cur...  01-02-2020  \n",
       "18  [   Geo-Med is a Medical/Surgical supplier foc...  01-02-2020  \n",
       "19  [    With one application you can be considere...  01-02-2020  \n",
       "20  [   A well funded start-up in the Chinatown ne...  01-02-2020  \n",
       "21  [    Job Summary   Job Title:   Data Scientist...  01-02-2020  \n",
       "22  [  pureIntegration is seeking a Junior Data Sc...  01-02-2020  \n",
       "23  [     About Us     Decode_M is a new kind of i...  01-02-2020  \n",
       "24  [      SSRS Data Scientist    SSRS, a leading ...  01-02-2020  \n",
       "25  [     About Us     Decode_M is a new kind of i...  01-02-2020  \n",
       "26  [      Associate Director, Data Scientist     ...  01-02-2020  \n",
       "27  [       Worker Sub-Type:   Regular      Job De...  01-02-2020  \n",
       "28  [      We’re looking for intelligent, creative...  01-02-2020  \n",
       "29  [   SFL Scientific is expanding our data scien...  01-02-2020  \n",
       "30  [   Trademark Global, LLC (TM) is a private eq...  01-02-2020  \n",
       "31  [    Bossa Nova is the leading provider of rea...  01-02-2020  \n",
       "32  [      As a Data Scientist for the CIA, you wi...  01-02-2020  \n",
       "33  [    TITLE: SENIOR HEALTHCARE INFORMATION SCIE...  01-02-2020  \n",
       "34  [   Our database Marketing scientist is respon...  01-02-2020  \n",
       "35  [    With one application you can be considere...  01-02-2020  \n",
       "36  [   Data Scientists develop and apply methods ...  01-02-2020  \n",
       "37  [     **An assessment is attached to this appl...  01-02-2020  \n",
       "38  [    Strict Requirement:   Candidate must be a...  01-02-2020  \n",
       "39  [    B23  is a product-enabled data and softwa...  01-02-2020  \n",
       "40  [    Job Summary   Job Title:   Machine Learni...  01-02-2020  \n",
       "41  [    Machine Learning Engineer   Contribute to...  01-02-2020  \n",
       "42  [    Research Scientist - Machine Learning and...  01-02-2020  \n",
       "43  [    Core Responsibilities :   Coordinate with...  01-02-2020  \n",
       "44  [    Our Story   Founded on the campus of Stan...  01-02-2020  \n",
       "45  [     Job Description    We are looking for fr...  01-02-2020  \n",
       "46  [   Learn Ventures seeks a full-time Machine L...  01-02-2020  \n",
       "47  [       Summary    Posted:  Dec 31, 2019    We...  01-02-2020  \n",
       "48  [    SphereOI helps clients succeed with advan...  01-02-2020  \n",
       "49  [      At LG's Future Experiences team we’re c...  01-02-2020  \n",
       "50  [    What You’ll Do      As a Software Enginee...  01-02-2020  \n",
       "51  [  P&amp;G is the largest consumer packaged go...  01-02-2020  \n",
       "52  [    Best Buy has the third largest eCommerce ...  01-02-2020  \n",
       "53  [   McLean 1 (19050), United States of America...  01-02-2020  \n",
       "54  [   Vody is a venture-backed startup focused o...  01-02-2020  \n",
       "55  [    About Triplebyte  Triplebyte helps compan...  01-02-2020  \n",
       "56  [       Summary    Posted:  Aug 14, 2019    Ro...  01-02-2020  \n",
       "57  [   Machine Learning Engineer     Job Descript...  01-02-2020  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_title(search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:36:40.082667Z",
     "start_time": "2020-01-02T15:36:40.050039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665 entries, 0 to 664\n",
      "Data columns (total 5 columns):\n",
      "title          665 non-null object\n",
      "company        633 non-null object\n",
      "location       633 non-null object\n",
      "description    665 non-null object\n",
      "date           665 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 26.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('demo_indeed_webscrape.csv')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
