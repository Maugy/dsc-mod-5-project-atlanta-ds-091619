{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.268603Z",
     "start_time": "2020-01-02T04:17:42.781736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "import WebScrape_Indeed\n",
    "import WebScrape_LinkedIn\n",
    "import streamlit as st \n",
    "import terms \n",
    "import Cities \n",
    "import functions\n",
    "import time\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig\n",
    "\n",
    "import chart_studio.plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "import pydeck as pdk\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)   \n",
    "\n",
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.274194Z",
     "start_time": "2020-01-02T04:17:45.270730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.282853Z",
     "start_time": "2020-01-02T04:17:45.277402Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.297355Z",
     "start_time": "2020-01-02T04:17:45.286544Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.305293Z",
     "start_time": "2020-01-02T04:17:45.300833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import (make_blobs,\n",
    "                                                make_circles,\n",
    "                                                make_moons)\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('fivethirtyeight')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.311133Z",
     "start_time": "2020-01-02T04:17:45.307265Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:45.538301Z",
     "start_time": "2020-01-02T04:17:45.313298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:46.964947Z",
     "start_time": "2020-01-02T04:17:45.540165Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:46.971536Z",
     "start_time": "2020-01-02T04:17:46.967047Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(raw):\n",
    "#     raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    raw = nltk.regexp_tokenize(raw, pattern)\n",
    "#     raw = str(raw)\n",
    "    return raw\n",
    "\n",
    "def cleanC(raw):\n",
    "#     raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    return raw\n",
    "\n",
    "def C_plus(raw):\n",
    "    Cplus = re.findall(r'(?i)\\bC\\+\\+(?!\\w)', str(raw))\n",
    "    return Cplus\n",
    "\n",
    "def C_sharp(raw):\n",
    "    Csharp = re.findall(r'(?i)\\bC\\#(?!\\w)', str(raw))\n",
    "    return Csharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.233445Z",
     "start_time": "2020-01-02T04:17:46.973311Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco, CA 94105</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kohl's</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Palo Alto, CA 94304</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title              company  \\\n",
       "0                   Data Scientist             Esurance   \n",
       "1                   DATA SCIENTIST              Walmart   \n",
       "2                   Data Scientist               Kohl's   \n",
       "3  Staff Data Scientist (GEC11903)    Walmart eCommerce   \n",
       "4               Sr. Data Scientist  Silicon Valley Bank   \n",
       "\n",
       "                  location                                        description  \\\n",
       "0  San Francisco, CA 94105  [     Summary       Esurance is looking for a ...   \n",
       "1      Sunnyvale, CA 94087  [     Position Description    Data Scientist i...   \n",
       "2       Milpitas, CA 95035  [  Interpret and apply data analyses and expla...   \n",
       "3      Sunnyvale, CA 94087  [     Position Description      Understands an...   \n",
       "4      Palo Alto, CA 94304  [       Silicon Valley Bank is the market lead...   \n",
       "\n",
       "         date  \n",
       "0  12-01-2019  \n",
       "1  12-01-2019  \n",
       "2  12-01-2019  \n",
       "3  12-01-2019  \n",
       "4  12-01-2019  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('total_data_date.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.238096Z",
     "start_time": "2020-01-02T04:17:47.235726Z"
    }
   },
   "outputs": [],
   "source": [
    "search_terms = terms.total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.244349Z",
     "start_time": "2020-01-02T04:17:47.240141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AJAX',\n",
       " 'ASP',\n",
       " 'ASP.NET',\n",
       " 'AWS',\n",
       " 'Acrobat',\n",
       " 'Airflow',\n",
       " 'Alteryx',\n",
       " 'Android',\n",
       " 'Angular',\n",
       " 'Ansible',\n",
       " 'Apache',\n",
       " 'Arduino',\n",
       " 'Atom',\n",
       " 'Azure',\n",
       " 'BSD',\n",
       " 'Bash',\n",
       " 'BigQuery',\n",
       " 'C#',\n",
       " 'C++',\n",
       " 'CSS',\n",
       " 'Caffe',\n",
       " 'Cassandra',\n",
       " 'Chef',\n",
       " 'Couchbase',\n",
       " 'CryEngine',\n",
       " 'D3',\n",
       " 'Databricks',\n",
       " 'Django',\n",
       " 'Docker',\n",
       " 'Drupal',\n",
       " 'DynamoDB',\n",
       " 'Elixir',\n",
       " 'Excel',\n",
       " 'Fastai',\n",
       " 'Firebase',\n",
       " 'Flask',\n",
       " 'GCP',\n",
       " 'Git',\n",
       " 'Google Cloud',\n",
       " 'HTML',\n",
       " 'Hadoop',\n",
       " 'Hbase',\n",
       " 'Hive',\n",
       " 'IBM',\n",
       " 'IPython',\n",
       " 'Illustrator',\n",
       " 'InDesign',\n",
       " 'IntelliJ',\n",
       " 'Java',\n",
       " 'Javascript',\n",
       " 'Julia',\n",
       " 'Jupyter',\n",
       " 'Keras',\n",
       " 'Komodo',\n",
       " 'Kubernetes',\n",
       " 'Laravel',\n",
       " 'Linux',\n",
       " 'MacOS',\n",
       " 'MariaDB',\n",
       " 'Matlab',\n",
       " 'Microsoft',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NET',\n",
       " 'NLP',\n",
       " 'NetBeans',\n",
       " 'Netsuite',\n",
       " 'NoSQL',\n",
       " 'Node',\n",
       " 'Notepad',\n",
       " 'NumPy',\n",
       " 'Objective C',\n",
       " 'Oracle',\n",
       " 'PHP',\n",
       " 'PHPStorm',\n",
       " 'PMP',\n",
       " 'Pandas',\n",
       " 'Perl',\n",
       " 'Photoshop',\n",
       " 'Pi',\n",
       " 'Pig',\n",
       " 'PostgreSQL',\n",
       " 'PowerPoint',\n",
       " 'PowerShell',\n",
       " 'Project Management',\n",
       " 'Puppet',\n",
       " 'PyCharm',\n",
       " 'PyTorch',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Rails',\n",
       " 'Raspberry',\n",
       " 'React',\n",
       " 'Ruby',\n",
       " 'RubyMine',\n",
       " 'SAP',\n",
       " 'SAS',\n",
       " 'SPSS',\n",
       " 'SQL',\n",
       " 'SQLite',\n",
       " 'Salesforce',\n",
       " 'Scala',\n",
       " 'Scikit-learn',\n",
       " 'Scrum',\n",
       " 'Shell',\n",
       " 'Spark',\n",
       " 'Spring',\n",
       " 'Sublime',\n",
       " 'Swift',\n",
       " 'Tableau',\n",
       " 'TensorFlow',\n",
       " 'TextMate',\n",
       " 'Torch',\n",
       " 'Unity',\n",
       " 'Unreal Engine',\n",
       " 'Visual Studio',\n",
       " 'Vue',\n",
       " 'Watson',\n",
       " 'WebAssembly',\n",
       " 'Windows',\n",
       " 'WordPress',\n",
       " 'XGBoost',\n",
       " 'XML',\n",
       " 'Xamarin',\n",
       " 'Xcode',\n",
       " 'Zend',\n",
       " 'iOS',\n",
       " 'jQuery',\n",
       " 'mapreduce',\n",
       " 'postgresql',\n",
       " 'sklearn']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.248334Z",
     "start_time": "2020-01-02T04:17:47.246171Z"
    }
   },
   "outputs": [],
   "source": [
    "# option = 'Data Scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.252244Z",
     "start_time": "2020-01-02T04:17:47.250336Z"
    }
   },
   "outputs": [],
   "source": [
    "# dtitle = data[data['title'].astype(str).str.contains(option)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.255812Z",
     "start_time": "2020-01-02T04:17:47.253780Z"
    }
   },
   "outputs": [],
   "source": [
    "# text = dtitle.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.260319Z",
     "start_time": "2020-01-02T04:17:47.257146Z"
    }
   },
   "outputs": [],
   "source": [
    "text = data[['title','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:47.269521Z",
     "start_time": "2020-01-02T04:17:47.261799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   Data Scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      As a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      Be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     Summary       Esurance is looking for a ...  \n",
       "1      [     Position Description    Data Scientist i...  \n",
       "2      [  Interpret and apply data analyses and expla...  \n",
       "3      [     Position Description      Understands an...  \n",
       "4      [       Silicon Valley Bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     Description    The Senior Data Scientist...  \n",
       "18449  [     Description    The Senior Data Scientist...  \n",
       "18450  [   Data Scientists develop and apply methods ...  \n",
       "18451  [    What you’ll be doing...      As a data sc...  \n",
       "18452  [    What you’ll be doing...      Be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.340906Z",
     "start_time": "2020-01-02T04:17:47.271361Z"
    }
   },
   "outputs": [],
   "source": [
    "# desc_cleaned = []\n",
    "for word in text.description:\n",
    "    cleaned = pd.Series(clean(word))\n",
    "    text.description.append(cleaned)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.350242Z",
     "start_time": "2020-01-02T04:17:59.342768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     Description    The Senior Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   Data Scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      As a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    What you’ll be doing...      Be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     Summary       Esurance is looking for a ...  \n",
       "1      [     Position Description    Data Scientist i...  \n",
       "2      [  Interpret and apply data analyses and expla...  \n",
       "3      [     Position Description      Understands an...  \n",
       "4      [       Silicon Valley Bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     Description    The Senior Data Scientist...  \n",
       "18449  [     Description    The Senior Data Scientist...  \n",
       "18450  [   Data Scientists develop and apply methods ...  \n",
       "18451  [    What you’ll be doing...      As a data sc...  \n",
       "18452  [    What you’ll be doing...      Be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.354415Z",
     "start_time": "2020-01-02T04:17:59.351907Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.358355Z",
     "start_time": "2020-01-02T04:17:59.356052Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tech_count(text):\n",
    "#     tech_skills = []\n",
    "#     List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = [x.lower() for x in text_clean]\n",
    "\n",
    "#     for item in List2:\n",
    "#         if item in List1:\n",
    "#             tech_skills.append(item)\n",
    "#         else:\n",
    "#             None \n",
    "#     return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.544365Z",
     "start_time": "2020-01-02T04:17:59.360155Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text['description'] = [x.lower() for x in text['description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.552862Z",
     "start_time": "2020-01-02T04:17:59.546047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   data scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      as a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     summary       esurance is looking for a ...  \n",
       "1      [     position description    data scientist i...  \n",
       "2      [  interpret and apply data analyses and expla...  \n",
       "3      [     position description      understands an...  \n",
       "4      [       silicon valley bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     description    the senior data scientist...  \n",
       "18449  [     description    the senior data scientist...  \n",
       "18450  [   data scientists develop and apply methods ...  \n",
       "18451  [    what you’ll be doing...      as a data sc...  \n",
       "18452  [    what you’ll be doing...      be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.556983Z",
     "start_time": "2020-01-02T04:17:59.554722Z"
    }
   },
   "outputs": [],
   "source": [
    "# List3 = []\n",
    "# List2 = text['description']\n",
    "# for item in List2.split():\n",
    "#     List3.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.561011Z",
     "start_time": "2020-01-02T04:17:59.558816Z"
    }
   },
   "outputs": [],
   "source": [
    "# def dfcount(text):\n",
    "#     tech_skills = []\n",
    "#     List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = text['description']\n",
    "\n",
    "#     for item in List2:\n",
    "#         if item in List1:\n",
    "#             tech_skills.append(item)\n",
    "#         else:\n",
    "#             None \n",
    "#     return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.565523Z",
     "start_time": "2020-01-02T04:17:59.563238Z"
    }
   },
   "outputs": [],
   "source": [
    "new_text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.575869Z",
     "start_time": "2020-01-02T04:17:59.567033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   data scientists develop and apply methods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      as a data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      be a part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \n",
       "0      [     summary       esurance is looking for a ...  \n",
       "1      [     position description    data scientist i...  \n",
       "2      [  interpret and apply data analyses and expla...  \n",
       "3      [     position description      understands an...  \n",
       "4      [       silicon valley bank is the market lead...  \n",
       "...                                                  ...  \n",
       "18448  [     description    the senior data scientist...  \n",
       "18449  [     description    the senior data scientist...  \n",
       "18450  [   data scientists develop and apply methods ...  \n",
       "18451  [    what you’ll be doing...      as a data sc...  \n",
       "18452  [    what you’ll be doing...      be a part of...  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:17:59.580451Z",
     "start_time": "2020-01-02T04:17:59.577659Z"
    }
   },
   "outputs": [],
   "source": [
    "def tech_count(desc):\n",
    "    tech_skills = []\n",
    "    List1 = [x.lower() for x in search_terms]\n",
    "#     List2 = [x.lower() for x in text_clean]\n",
    "\n",
    "#     for item in text['description']:\n",
    "    for x in desc.split():\n",
    "        if x in List1:\n",
    "            tech_skills.append(x)\n",
    "    else:\n",
    "        pass \n",
    "    return tech_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.762601Z",
     "start_time": "2020-01-02T04:17:59.581851Z"
    }
   },
   "outputs": [],
   "source": [
    "tessy = []\n",
    "for sent in new_text['description']:\n",
    "    x = tech_count(sent)\n",
    "    y = str(x)\n",
    "    tessy.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.766802Z",
     "start_time": "2020-01-02T04:18:08.764870Z"
    }
   },
   "outputs": [],
   "source": [
    "ind = len(tessy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.781444Z",
     "start_time": "2020-01-02T04:18:08.777197Z"
    }
   },
   "outputs": [],
   "source": [
    "hmmm = pd.DataFrame(tessy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.791382Z",
     "start_time": "2020-01-02T04:18:08.783956Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "0                     ['python']\n",
       "1                             []\n",
       "2                             []\n",
       "3       ['gcp', 'nosql', 'ruby']\n",
       "4      ['sql', 'julia', 'scala']\n",
       "...                          ...\n",
       "18448                         []\n",
       "18449                      ['r']\n",
       "18450                    ['sql']\n",
       "18451                  ['linux']\n",
       "18452     ['r', 'sql', 'oracle']\n",
       "\n",
       "[18453 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.798347Z",
     "start_time": "2020-01-02T04:18:08.793210Z"
    }
   },
   "outputs": [],
   "source": [
    "hope = pd.concat([new_text, hmmm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.814224Z",
     "start_time": "2020-01-02T04:18:08.800727Z"
    }
   },
   "outputs": [],
   "source": [
    "hope = hope.rename(columns={0:'skills'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.823935Z",
     "start_time": "2020-01-02T04:18:08.816017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[     summary       esurance is looking for a ...</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[     position description    data scientist i...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[  interpret and apply data analyses and expla...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>[     position description      understands an...</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>[       silicon valley bank is the market lead...</td>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>[     description    the senior data scientist...</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>[   data scientists develop and apply methods ...</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      as a data sc...</td>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[    what you’ll be doing...      be a part of...</td>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                                             description  \\\n",
       "0      [     summary       esurance is looking for a ...   \n",
       "1      [     position description    data scientist i...   \n",
       "2      [  interpret and apply data analyses and expla...   \n",
       "3      [     position description      understands an...   \n",
       "4      [       silicon valley bank is the market lead...   \n",
       "...                                                  ...   \n",
       "18448  [     description    the senior data scientist...   \n",
       "18449  [     description    the senior data scientist...   \n",
       "18450  [   data scientists develop and apply methods ...   \n",
       "18451  [    what you’ll be doing...      as a data sc...   \n",
       "18452  [    what you’ll be doing...      be a part of...   \n",
       "\n",
       "                          skills  \n",
       "0                     ['python']  \n",
       "1                             []  \n",
       "2                             []  \n",
       "3       ['gcp', 'nosql', 'ruby']  \n",
       "4      ['sql', 'julia', 'scala']  \n",
       "...                          ...  \n",
       "18448                         []  \n",
       "18449                      ['r']  \n",
       "18450                    ['sql']  \n",
       "18451                  ['linux']  \n",
       "18452     ['r', 'sql', 'oracle']  \n",
       "\n",
       "[18453 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.828440Z",
     "start_time": "2020-01-02T04:18:08.825419Z"
    }
   },
   "outputs": [],
   "source": [
    "hope2 = hope[['title','skills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.837230Z",
     "start_time": "2020-01-02T04:18:08.829901Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>['gcp', 'nosql', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>['sql', 'julia', 'scala']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>Senior Data Scientist - Consumer Analytics (Ir...</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>Data Scientist - Mid-Level</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>['linux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['r', 'sql', 'oracle']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                         Data Scientist   \n",
       "1                                         DATA SCIENTIST   \n",
       "2                                         Data Scientist   \n",
       "3                        Staff Data Scientist (GEC11903)   \n",
       "4                                     Sr. Data Scientist   \n",
       "...                                                  ...   \n",
       "18448                              Senior Data Scientist   \n",
       "18449  Senior Data Scientist - Consumer Analytics (Ir...   \n",
       "18450                         Data Scientist - Mid-Level   \n",
       "18451                           Principal Data Scientist   \n",
       "18452                                     Data Scientist   \n",
       "\n",
       "                          skills  \n",
       "0                     ['python']  \n",
       "1                             []  \n",
       "2                             []  \n",
       "3       ['gcp', 'nosql', 'ruby']  \n",
       "4      ['sql', 'julia', 'scala']  \n",
       "...                          ...  \n",
       "18448                         []  \n",
       "18449                      ['r']  \n",
       "18450                    ['sql']  \n",
       "18451                  ['linux']  \n",
       "18452     ['r', 'sql', 'oracle']  \n",
       "\n",
       "[18453 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:08.841384Z",
     "start_time": "2020-01-02T04:18:08.839364Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.421486Z",
     "start_time": "2020-01-02T04:18:08.843657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences type: <class 'list'>\n",
      "one_hot_results type: <class 'numpy.ndarray'>\n",
      "Vocab size 114\n",
      "Found 114 unique tokens.\n",
      "Dimensions of our coded results: (18453, 115)\n"
     ]
    }
   ],
   "source": [
    "skills = hope2[\"skills\"] #Our raw text complaints\n",
    "\n",
    "tokenizer = Tokenizer() #Initialize a tokenizer.\n",
    "\n",
    "tokenizer.fit_on_texts(skills) #Fit it to the complaints\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(skills) #Generate sequences\n",
    "print('sequences type:', type(sequences))\n",
    "\n",
    "one_hot_results= tokenizer.texts_to_matrix(skills, mode='binary') #Similar to sequences, but returns a numpy array\n",
    "print('one_hot_results type:', type(one_hot_results))\n",
    "\n",
    "word_index = tokenizer.word_index #Useful if we wish to decode (more explanation below)\n",
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "print('Vocab size', vocabulary_size)\n",
    "print('Found %s unique tokens.' % len(word_index)) #Tokens are the number of unique words across the corpus\n",
    "\n",
    "\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) #Our coded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.426766Z",
     "start_time": "2020-01-02T04:18:09.424719Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.431590Z",
     "start_time": "2020-01-02T04:18:09.428210Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original complaint text:\n",
      "['r', 'python', 'linux']\n",
      "\n",
      "\n",
      "\n",
      "Decoded review from Tokenizer:\n",
      "'r' 'python' 'linux'\n"
     ]
    }
   ],
   "source": [
    "comment_idx_to_preview = 19\n",
    "print('Original complaint text:')\n",
    "print(skills[comment_idx_to_preview])\n",
    "print('\\n\\n')\n",
    "\n",
    "#The reverse_index cell block above must be complete in order for this cell block to successively execute.\n",
    "decoded_review = ' '.join([reverse_index.get(i) for i in sequences[comment_idx_to_preview]])\n",
    "print('Decoded review from Tokenizer:')\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.435432Z",
     "start_time": "2020-01-02T04:18:09.433373Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.439481Z",
     "start_time": "2020-01-02T04:18:09.436910Z"
    }
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed(123)\n",
    "# test_index = random.sample(range(1,20), 10)\n",
    "\n",
    "# test = one_hot_results[test_index]\n",
    "# train = np.delete(one_hot_results, test_index, 0)\n",
    "\n",
    "\n",
    "# label_test = product_onehot[test_index]\n",
    "# label_train = np.delete(product_onehot, test_index, 0)\n",
    "\n",
    "# print(\"Test label shape:\", np.shape(label_test))\n",
    "# print(\"Train label shape:\", np.shape(label_train))\n",
    "# print(\"Test shape:\", np.shape(test))\n",
    "# print(\"Train shape:\", np.shape(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.442767Z",
     "start_time": "2020-01-02T04:18:09.440819Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_len = 3+1\n",
    "# text_sequences = []\n",
    "# for i in range(train_len,len(data)):\n",
    "#     seq = data[i-train_len:i]\n",
    "#     text_sequences.append(seq)\n",
    "\n",
    "# sequences = {}\n",
    "# count = 1\n",
    "# for i in range(len(data)):\n",
    "#     if data[i] not in sequences:\n",
    "#         sequences[data[i]] = count\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.446537Z",
     "start_time": "2020-01-02T04:18:09.444196Z"
    }
   },
   "outputs": [],
   "source": [
    "train_len = 3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.450501Z",
     "start_time": "2020-01-02T04:18:09.448087Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(text_sequences)\n",
    "\n",
    "# sequences = tokenizer.texts_to_sequences(text_sequences) \n",
    "\n",
    "# #Collecting some information   \n",
    "# vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "# n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
    "# for i in range(len(sequences)):\n",
    "#     n_sequences[i] = sequences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.456635Z",
     "start_time": "2020-01-02T04:18:09.452569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.460488Z",
     "start_time": "2020-01-02T04:18:09.458358Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs = one_hot_results\n",
    "# train_targets = n_sequences[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.464987Z",
     "start_time": "2020-01-02T04:18:09.462676Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_targets = train_targets.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.473637Z",
     "start_time": "2020-01-02T04:18:09.466951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Data Scientist\n",
       "1                                           DATA SCIENTIST\n",
       "2                                           Data Scientist\n",
       "3                          Staff Data Scientist (GEC11903)\n",
       "4                                       Sr. Data Scientist\n",
       "                               ...                        \n",
       "18448                                Senior Data Scientist\n",
       "18449    Senior Data Scientist - Consumer Analytics (Ir...\n",
       "18450                           Data Scientist - Mid-Level\n",
       "18451                             Principal Data Scientist\n",
       "18452                                       Data Scientist\n",
       "Name: title, Length: 18453, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope3 = hope2['title'].astype(str)\n",
    "hope3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.515721Z",
     "start_time": "2020-01-02T04:18:09.475713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['(203) Server-Side Software Engineer', '(Contract) Material Property Database Engineer', '(VOIP) Network Engineer, VSP Vision Care', '***Data Engineer I***', '.NET Developer', '.NET Software Developer', '.NET Software Engineer', '.NET Web Developer', '.Net / Web Developer', '.Net Applications Software Engineer', '.Net Software Engineer', '.Net Technical Consultant', '.Net Web Developer', '160 - Security Operations Center - SOC Analyst I', '2020 - Associate Software Engineer - Intern Conversion', '2020 - Software Engineer Intern - Think Tank Team', '2020 Associates Program', '2020 Summer Residency', '3M HIS Data Engineer', 'ACD/Sr. Art Director', 'AI Engineering - Machine Learning Engineer', 'APaaS Product Implementation Advisor', 'ATAK Software Developer', 'AWS & Azure Cloud Engineer / Microsoft SQL Engineer', 'AWS & Azure Cloud Engineer/Microsoft SQL Engineer', 'AWS SQL Data Engineer', 'Academic Affairs: Stitcher/Draper', 'Account Coordinator', 'Account Executive', 'Account Group Supervisor / VP', 'Account Manager', 'Account Security Investigator', 'Account/Project Manager', 'Accountant', 'Accounting Associate', 'Accounting Supervisor', 'Accounts Payable Specialist', 'Activation Manager: Incubator Brands', 'Activities Director', 'Activities Therapist', 'Activity Center Assistant Leader-Before/After/Summer Out of School Time', 'Activity Director', 'Administrative Assistant', 'Advance Data Analyst/ GIS Specialist', 'Advanced Practice Nurse', 'Advertising Sales Representative', 'Aerospace and/or Software Engineer', 'Affirmative Action Data Analyst', 'Agile Software Engineer', 'Agile Software Engineer, Intermediate', 'AmeriCorps Ambassador', 'Analyst', 'Analyst Intern - Data Science & Solutions', 'Analyst, Business', 'Analyst, Cloud Data Engineer', 'Analyst, Data', 'Analyst, Data Analytics', 'Analyst, Data Products', 'Analyst, Data Science', 'Analyst, Data Solutions', 'Analyst, Data and Analytics', 'Analyst, Digital Analytics', 'Analyst, Measurement', 'Analyst, Operations', 'Analyst, Renewable Programs', 'Analyst, eBusiness', 'Analytics Engineer', 'Analytics Specialist', 'Analytics, Data Scientist', 'Analytics, Machine Learning Data Engineer', 'Android Developer', 'Android Software Engineer for Soldier-Worn Apps', 'Angular Web Developer', 'App/Web Developer', 'Application Developer', 'Application Developer - MI7250573', 'Application Develpopment Lead', 'Application Security Engineer', 'Application Security Engineer (Security Consulting)', 'Application Software Engineer', 'Application Software Engineer (ETL)', 'Application Web Developer, FX Connect, AVP', 'Application server administrator', 'Applied Data Scientist- Arlington, VA', 'Applied Research Data Science Intern', 'Architect', 'Architect Software Engineer', 'Armed Security Officer', 'Armed Security Officer.', 'Aroma & Household Product Testing Panelist', 'Artificial Intelligence and Machine Learning Engineer', 'Asset Management Data Analyst (Contract to Perm)', 'Assistant Bursar', 'Assistant Construction Project Manager', 'Assistant General Manager, Operations', 'Assistant Manager - Eyeglasses', 'Assistant Manager, Search Marketing', 'Assistant Professor - Graphic Design', 'Assistant Professor Graphic Design', 'Assistant Project Manager', 'Assistant Publicist - William Morrow', 'Assistant Technical Designer', 'Associate', 'Associate Account Manager', 'Associate Corporate SP&A - Product Development', 'Associate Data Analyst', 'Associate Data Engineer', 'Associate Data Scientist', 'Associate Data Scientist ( 6 Month Contact)', 'Associate Database Engineer', 'Associate Digital Developer', 'Associate Director of Sourcing', 'Associate Director, Cell Therapy Robotics Data Automation and Machine Learning', 'Associate Director, Digital Marketing - Waltham, MA', 'Associate General Counsel – Environmental Matters', 'Associate Info Security Assess', 'Associate Java Software Engineer', 'Associate Media Planner', 'Associate Principal Data Scientist', 'Associate Product Manager', 'Associate Project Coordinator', 'Associate Project Manager', 'Associate Software Engineer', 'Associate Software Engineer, Sage50', 'Associate Web Developer', 'Associate – Financial Crimes Compliance', 'Associate, Carbon Markets', 'Associate, Data Engineer', 'Associate, International Trade', 'Associate, Partnership Development for Dine for No Kid Hungry', 'Associate, Software Engineer', 'Associate, Software Engineer (NERD)', 'Associate, Software Engineer, Trading Systems', 'Associate, Web Developer', 'Associate, Wikibuy Software Engineer', 'Athletic Trainer', 'Atmospheric Data Scientist - Air Quality', 'Audio Software Engineer - Contractor', 'Audio Systems Engineer', 'Auditor/Examiner 1', 'Automation Tester', 'Autonomous Driving Compute Systems Engineer', 'Azure Data Engineer', 'Azure Infrastructure Consultant', 'BGOV Associate Data Scientist', 'BI Business / Data Analyst', 'BI Data Analyst', 'BI Data Analyst II', 'BI Engineer', 'BI and Data Analyst', 'BIG DATA ENGINEER / HADOOP DEVELOPER', 'BIM Modeler', 'BRAND OPERATIONS COORDINATOR', 'Back End Web Developer', 'Backend Engineer', 'Backend Software Engineer (Elixir)', 'Backend Web Developer', 'Bagger', 'Benefit Specialist', 'Big Data Analyst', 'Big Data Analyst job opening in #Alpharetta, Georgia #hiring', 'Big Data Developer', 'Big Data Developer/Data Engineer (3 STA)', 'Big Data Engineer', 'Big Data Engineer - Enterprise Solutions Engineer II (Data Engineering and Analytics) – (Position Closes 12/31/2019 at 5:00pm)', 'Big Data Engineer/Hadoop Developer', 'Big Data Software Engineer 2', 'Big Data Web Developer', 'Big Data/Data Analyst', 'BigCommerce and WordPress Developer', 'Bilingual Customer Service Representative', 'Bilingual Office Assistant', 'Bill of Material Data Analyst – Excel', 'Billing Specialist', 'Biological Science Info Spec - Data Scientist', 'Bolingbrook,IL- Network Engineer', 'Bookkeeper', 'Bootcamp Instructor', 'Branch Manager', 'Brand Assistant - Entry Level / Full Time', 'Brand Manager -Portland', 'Brand Marketing Associate', 'Brand Specialist - CALVIN KLEIN (Dallas, TX)', 'Building Engineer', 'Business Analyst', 'Business Analyst - Must be local to San Francisco, CA', 'Business Analyst II', 'Business Analyst Supply Chain', 'Business Analyst, Marketing', 'Business Analyst, Outreach Operations', 'Business Analyst, Partnership Marketing', 'Business Analyst/Data Analyst', 'Business Data Analyst', 'Business Data Analyst (must work', 'Business Data Analyst Consultant', 'Business Data Scientist II', 'Business Development Manager', 'Business IT Manager', 'Business Intelligence Analyst', 'Business Intelligence Analyst - Senior Associate', 'Business Intelligence Data Engineer I', 'Business Operations & Strategy Analyst', 'Business Strategy & Data Analyst', 'Business System Analyst', 'Business Systems Analyst', 'Business Transformation Junior Position', 'Business-Readiness Project Manager', 'Business/Data Analyst', 'Buyer', 'Buyer, NY', 'C# .Net Developer', 'C# ASP.NET MVC Developer / Software Engineer', 'C# Intermediate - Senior Level Software Engineer', 'C++ Software Developer', 'C++ Software Engineer', 'C++/Qt Software Engineer', 'CBRN Sample Analyst', 'CCB-Risk-Card Portfolio Machine Learning Data Scientist –Associate', 'CCIP Intern- Data Scientist Anly Intern', 'CIB - Data Scientist Associate', 'CIB - Economic Research - Macroeconomic Data Scientist - Associate/VP', 'CIB Machine Learning Center of Excellence - Applied AI/ML Associate', 'CIB Machine Learning Center of Excellence - Applied AI/ML Director', 'CIB data+design - Data Scientist - VP', 'CONTRACT - Data Engineer', 'CONTRACT - Data Scientist (NTD)', 'CONTRACT - Web Developer', 'COO', 'CREFMarketing.com - Web Developer', 'CRM Marketing Coordinator (bareMinerals)', 'CSR, PR & Event Representative *NEW HIRE*', 'Call Center Operator', 'Callidus Data Analyst', 'Career Transition Coach', 'Catastrophe Data Analyst', 'Category Analyst, Sourcing', 'Category Manager', 'Category Strategy Manager', 'Cerner Revenue Cycle Project Manager', 'Certified Medical Assistant', 'Chief Data Scientist', 'Chief Engineer-Commercial', 'Chief Executive Officer', 'Chief Learning Officer', 'Chief Security Officer', 'Chief of Security', 'Chief of Security and Parking', 'Chief of Staff', 'Circulator', 'Cisco Network Engineer', 'Civil Engineer', 'Client Advocate (Wednesday-Sunday 7-3:30 pm)', 'Client Engagement Partner', 'Client Partner-Fulltime', 'Client Relations Associate', 'Client Relationship Consultant - Multiple locations', 'Client Service Manager - Stitcher', 'Client Service Specialist', 'Client Services Partner', 'Clinical Data Analyst', 'Clinical Data Analyst - Baptist Metro Square', 'Clinical Data Analyst Surgical Services', 'Clinical Data Scientist', 'Clinical Education Specialist', 'Clinical Project Lead (Remote)', 'Clinical Research Associate', \"Clinical Research Manager (Women's Health : Postpartum Hemorrhage)\", 'Cloud Data Engineer', 'Cloud Security Engineer', 'Cloud Software Engineer - Video - multiple locations', 'Club Success Specialist', 'Combustion Systems Engineer', 'Commercial Banking - Reference Data Analyst - WLS', 'Commercial Property Accountant - 19-07319', 'Commodities Quantitative Structurer', 'Communication Network Engineer, Mid (Government)', 'Communications Assistant', 'Communications Assoc, Corp Strategy & Engagement', 'Communications Associate', 'Communications Lead', 'Communications Network Engineer', 'Communications Project Manager', 'Community Impact Coordinator', 'Community Liaison', 'Community Relations Specialist', 'Community Support Specialist - Farmington, MO (Children and Family Services', 'Compensation Manager', 'Completions Consultant', 'Compliance Software Engineer', 'Computational Biologist/Data Scientist', 'Computer Project Manager', 'Computer Systems Engineer', 'Computer Vision Software Engineer', 'Configuration Manager (JSF/ACURL)', 'Construction Engineer', 'Construction Project Manager', 'Consultant, IT Data & Analytics - Data Analyst', 'Content Creator', 'Content Marketing Strategist', 'Content Producer', 'Content Specialist', 'Content Strategist', 'Content Strategy Researcher', 'Continuous Improvement Leader', 'Continuous Improvement Specialist', 'Contract & Data Analyst', 'Contract Advisor', 'Contract Data Analyst', 'Contract Price/Cost Analyst', 'Contract Software Engineer MongoDB/Javascript/Meteor', 'Contracts Counsel', 'Controller', 'Coordinator of Donor Engagement', 'Coordinator, International Vendor Compliance', 'Coordinator-DME', 'Copy Editor', 'CoreMedia Software Engineer', 'Corporate Controller', 'Corporate Recruiter', 'Corporate Recruiter (entry level)', 'Corporate Sales Trainer-Entry Level', 'Corporate Senior Accountant', 'Cost Estimator', 'Costing Engineer', 'Crane Hoist Technician', 'Credit Analyst', 'Crime Analyst', 'Curator/Associate/Assistant Curator', 'Curriculum & Instruction Manager', 'Customer Data Analyst', 'Customer Experience Analyst (Data Scientist)', 'Customer Relations Analyst', 'Customer Relations Coordinator', 'Customer Relations Specialist', 'Customer Service Account Representative', 'Customer Service Center Manager - Buffalo Site Location Lead', 'Customer Service Representative', 'Customer Success Data Analyst', 'Customer Success Manager', 'Customer Success Manager (Enterprise/Strategic)', 'Customer Success Project Manager', 'Customer Support Specialist', 'Cyber Analyst', 'Cyber Defense Consultant (Remote)', 'Cyber Infrastructure Engineer', 'Cyber Intel Analyst: Mid Level (Secret Clearance Required)', 'Cyber Intelligence Data Scientist', 'Cyber Policy and Strategy Subject Matter Expert', 'Cyber Security Analyst', 'Cyber Security Analyst (Assessment and Authorization)', 'Cyber Security Auditor', 'Cyber Security Engineer', 'Cyber Security Engineer 3 or 4', 'Cyber Security Intern', 'Cyber Security Manager', 'Cyber Security Policy Analyst', 'Cyber Security Specialist', 'Cyber Security officer - SSBI Clearance W/Security +', 'Cyber Software Engineer - Source Code Review', 'Cyber Software Engineering Lead *$10K sign on eligible*', 'Cyber Underwriter', 'DATA ANALYST', 'DATA ANALYST INTERN', 'DATA SCIENTIST', 'DATA SCIENTIST I', 'DATA SCIENTIST MANAGER', 'DATABASE ENGINEER, DATA ANALYST', 'DB2 UDB Database Administrator', 'DBA/ Data Analyst', 'DC Office: Cyber Security Consultant', 'DCAM Digital Product Owner - Business', 'Data Administrator', 'Data Analyst', 'Data Analyst #102792', 'Data Analyst (2320)', 'Data Analyst (Data Governance)', 'Data Analyst (Digital Experience)', 'Data Analyst (Fulltime', 'Data Analyst (MDM)', 'Data Analyst (Medical Systems)', 'Data Analyst (OpCity)', 'Data Analyst (TX)', 'Data Analyst - Analytics Team', 'Data Analyst - Associate', 'Data Analyst - Entry Level', 'Data Analyst - Investigative Analytics - Experienced Associate', 'Data Analyst - Marketing', 'Data Analyst - Medicare Business Analytics', 'Data Analyst - Mid_ANG', 'Data Analyst - Pharmacy', 'Data Analyst - Research Department', 'Data Analyst / Business System Analyst', 'Data Analyst / Data Scientist', 'Data Analyst / RFP Specialist', 'Data Analyst / Report Development - Marietta, GA', 'Data Analyst / Scientist', 'Data Analyst / Sr. Data Analyst', 'Data Analyst 19-072', 'Data Analyst 2', 'Data Analyst EDM', 'Data Analyst II', 'Data Analyst III', 'Data Analyst III (SQL, Excel, Healthcare)', 'Data Analyst with Dynamic 365', 'Data Analyst with SQL (w/ BFS exp)', 'Data Analyst with sql', 'Data Analyst – Data Science/Big Data', 'Data Analyst – People Data Solutions', 'Data Analyst – Statistical Modeling', 'Data Analyst – University Graduate', 'Data Analyst(Medical Device)', 'Data Analyst(local to WA)', 'Data Analyst, BI & Portfolio Analytics', 'Data Analyst, Data Science', 'Data Analyst, Digital Experience', 'Data Analyst, Enterprise Portfolio', 'Data Analyst, Jr. (Navy)', 'Data Analyst, Operations', 'Data Analyst, Operations Analysis & Performance (OAP)', 'Data Analyst, People Analytics', 'Data Analyst, Revenue Compliance', 'Data Analyst- Bilingual Spanish, Alexa Automotive', 'Data Analyst- Logistics', 'Data Analyst-Patient Access and Service Center', 'Data Analyst-People Operations', 'Data Analyst-Video Games', 'Data Analyst/ Scientist', 'Data Analyst/Associate', 'Data Analyst/Data Scientist', 'Data Analyst/Developer', 'Data Analyst/Engineer', 'Data Analyst/MS Analyst Specialist', 'Data Analyst/Reporting Specialist', 'Data Analyst/Scientist III', 'Data Analytics Analyst', 'Data Analytics Business Analyst', 'Data Analytics Engineer', 'Data Analytics:Project Business Analyst Intern -Fall 2020, Orlando, FL', 'Data Architect', 'Data Center Engineer', 'Data Center Network Engineer', 'Data Center Network Engineer - ITS4', 'Data Defect Analyst', 'Data Director', 'Data Engineer', 'Data Engineer (AWS)', 'Data Engineer (Contract)', 'Data Engineer (Data Feed - Cloud)', 'Data Engineer (Data Quality)', 'Data Engineer (Hadoop Spark)', 'Data Engineer (Hadoop)', 'Data Engineer (Master Data Management Team)', 'Data Engineer (Remote)', 'Data Engineer (SF)', 'Data Engineer (Top Secret Clearance with FS poly)', 'Data Engineer (W2 Only, No C2C)', 'Data Engineer - 19-07267', 'Data Engineer - AWS', 'Data Engineer - AWS Experience.', 'Data Engineer - Canada', 'Data Engineer - Card Technology', 'Data Engineer - Data Analyst', 'Data Engineer - Data Lake', 'Data Engineer - Entry Level', 'Data Engineer - Fintech', 'Data Engineer - Health Data Engineering', 'Data Engineer - Linux', 'Data Engineer - WWOps Connections', 'Data Engineer / Data Scientist', 'Data Engineer / Digital Media / Sports', 'Data Engineer / Modeler - NO H1B / NO CC', 'Data Engineer 1', 'Data Engineer 2', 'Data Engineer : 19-05385', 'Data Engineer BI & Reporting', 'Data Engineer Consultant', 'Data Engineer I', 'Data Engineer II', 'Data Engineer II FT', 'Data Engineer III', 'Data Engineer III - C#,SQL (AV1966)', 'Data Engineer Intern', 'Data Engineer Intern - Summer 2020', 'Data Engineer Senior/Expert', 'Data Engineer with Python', 'Data Engineer | Hadoop, Pig, Hive, Spark, and MapReduce', 'Data Engineer – Enterprise Data Warehouse', 'Data Engineer – PL /SQL ETL', 'Data Engineer – Predictive Model Implementations', 'Data Engineer, Amazon GO', 'Data Engineer, Business Intelligence & Analytics', 'Data Engineer, Human Loop – AI', 'Data Engineer, Products', 'Data Engineer- Configuration', 'Data Engineer- Frozen Viper', 'Data Engineer- Req 102', 'Data Engineer/Scientist', 'Data Engineer/Software Developer - Data Pipeline', 'Data Engineer:  up to $300,000', 'Data Engineers', 'Data Entry Clerk', 'Data Feature Engineer', 'Data Govenance/ Analyst', 'Data Governance Analyst', 'Data Governance Analyst Intership', 'Data Integration Developer-112729', 'Data Integration Engineer', 'Data Integrator/Data Engineer (NC-19-0005)', 'Data Model Analyst', 'Data Network Engineer', 'Data Operations & Reporting Analyst', 'Data Operations Analyst', 'Data Ops Analyst', 'Data Path Engineer', 'Data Privacy Analyst', 'Data Privacy Analyst Intern (2020)', 'Data Quality Analyst', 'Data Quality Analyst- e-commerce tech company', 'Data Reporting Analyst', 'Data Science', 'Data Science Engineer', 'Data Science Leader - Applied Machine Learning', 'Data Science Manager', 'Data Science Platform - Software Engineer', 'Data Scientist', 'Data Scientist (Analytic Consultant 4)', 'Data Scientist (Contract)', 'Data Scientist (IL)', 'Data Scientist (Intelligence)', 'Data Scientist (Labs)', 'Data Scientist (Mid Level)', 'Data Scientist (Part-time)', 'Data Scientist (PhD Statistics ONLY)', 'Data Scientist (Python Developer) - Workforce Analytics', 'Data Scientist (Python/Remote)', 'Data Scientist (Remote)', 'Data Scientist (Spark)', 'Data Scientist (TS/SCI required)', 'Data Scientist (TX)', 'Data Scientist (Telework Available in the DC Metro area)', 'Data Scientist - Algorithms', 'Data Scientist - Analytics, People Analytics', 'Data Scientist - Analytics, Trust', 'Data Scientist - Applied Machine Learning', 'Data Scientist - Applied Machine Learning and Advertising Modeling', 'Data Scientist - Behavioral Health', 'Data Scientist - Data Analyst Manager', 'Data Scientist - Data Analytic Consultant', 'Data Scientist - Deloitte (Remote, Freelance/Contract)', 'Data Scientist - Demand Forecasting', 'Data Scientist - Disney+', 'Data Scientist - Economic Data', 'Data Scientist - Experimentation & Platform', 'Data Scientist - Financial Technology Start Up!', 'Data Scientist - Forecasting', 'Data Scientist - Global Optimization', 'Data Scientist - Healthcare', 'Data Scientist - Houston, TX', 'Data Scientist - Industrial IoT (local candidates only, please)', 'Data Scientist - Inference', 'Data Scientist - Insurance', 'Data Scientist - IoT (Chicago)', 'Data Scientist - Lab Operations', 'Data Scientist - Machine Learning', 'Data Scientist - Marketing Analytics Consultant', 'Data Scientist - Mid-Level', 'Data Scientist - New Grad 2020', 'Data Scientist - People Analytics', 'Data Scientist - Personalization', 'Data Scientist - Pre Sales', 'Data Scientist - Product Operations', 'Data Scientist - REMOTE', 'Data Scientist - Southern Cascades Finance', 'Data Scientist - Venn Engineering', 'Data Scientist - W2 Only', 'Data Scientist -Cognitive/Machine Learning Professional 2-2', 'Data Scientist / AI Engineer', 'Data Scientist / Data Analyst Manager', 'Data Scientist / Data Analytics', 'Data Scientist / Economist', 'Data Scientist / Engineer', 'Data Scientist / Quantitative Analyst', 'Data Scientist / Research Scientist', 'Data Scientist / Solution Architect', 'Data Scientist 1', 'Data Scientist 3 (AP1938)', 'Data Scientist @ SpectraMedix, NJ', 'Data Scientist Analyst', 'Data Scientist Causal & Predict analytic', 'Data Scientist I', 'Data Scientist I (Marketing)', 'Data Scientist I - III', 'Data Scientist I-III, Spatial Single-Cell RNA Sequencing', 'Data Scientist II', 'Data Scientist II - Machine Learning', 'Data Scientist II FT', 'Data Scientist III', 'Data Scientist III – IVR Journey & Experience Analytics', 'Data Scientist IV', 'Data Scientist IV - IVR Predictive Experience Analytics', 'Data Scientist Intern', 'Data Scientist Intern for Enterprise Analytics', 'Data Scientist Junior', 'Data Scientist Leader', 'Data Scientist Researcher', 'Data Scientist Senior', 'Data Scientist Sr', 'Data Scientist in Santa Clara, CA (corp-corp can also apply)', 'Data Scientist w/ Anomaly detection, d3.js, R and Machine Learning', 'Data Scientist – Data & Metrics', 'Data Scientist – ESPN+', 'Data Scientist – Pricing Optimization', 'Data Scientist – Statistical Modeling', 'Data Scientist, AMP Commerce/ Payments/ Subscription Analytics', 'Data Scientist, Analytics', 'Data Scientist, Analytics (University Grad)', 'Data Scientist, Analytics -San Francisco', 'Data Scientist, Data & Analytics (D&A)', 'Data Scientist, Data Analytics & AI', 'Data Scientist, EMR - Pharma Solutions', 'Data Scientist, Energy Platform', 'Data Scientist, Forecasting', 'Data Scientist, Global Supply Chain', 'Data Scientist, ISC', 'Data Scientist, Internal Benchmarking', 'Data Scientist, Machine Learning - Game Matchmaking', 'Data Scientist, Machine Learning Engineer', 'Data Scientist, Marketing', 'Data Scientist, Mid', 'Data Scientist, Office of Data Science', 'Data Scientist, Operations Research', 'Data Scientist, WW Operations Finance', 'Data Scientist, Zillow Offers ML Team', 'Data Scientist- Advanced Analytics (Tech, Media & Telecom)', 'Data Scientist- Intermediate- 69599', 'Data Scientist- Media Analytics', 'Data Scientist- Remote (US based)', 'Data Scientist--Future Opportunity', 'Data Scientist-Fraud', 'Data Scientist-Machine Learning Engineer', 'Data Scientist/ Leadership Role', 'Data Scientist/ Machine Learning Engineer', 'Data Scientist/Architect', 'Data Scientist/Data Science Instructor', 'Data Scientist/Engineer', 'Data Scientist/Machine Learning Engineer', 'Data Scientist/Machine Learning Expert', 'Data Scientist/Statistician (Statistical Modeling)', 'Data Scientist/Statistician - Growth', 'Data Scientist/Visualization Master', 'Data Scientist: 100K+ per annum / equity', 'Data Scientist: Deep Learning & NLP', 'Data Security Administrator', 'Data Software Engineer', 'Data Specialist/Data Analyst', 'Data Storage Engineer', 'Data Visualization Engineer', 'Data Warehouse Analyst', 'Data Warehouse Engineer', 'Data Warehouse Specialist', 'Data analyst', 'Data analyst/Reporting analyst', 'Data and Analytics Analyst', 'Data and Analytics Associate', 'Data science Tagging and Analytics Engineer', 'Data scientist', 'Data scientist with python, C++ and data mining', 'Data/Database Architect', 'DataBase Engineer', 'Database Admin', 'Database Admin / Architect', 'Database Admin Dec Sup I', 'Database Admin Sr', 'Database Administrator', 'Database Administrator (Microsoft)', 'Database Administrator/Sales Administrator', 'Database Analyst', 'Database Architect', 'Database Architect # JN -122019-50866', 'Database Architect (4 years exp.)', 'Database Architect (DBA)', 'Database Architect Job#2747', 'Database Architect Onlife (Brentwood, Tenn)', 'Database Architect Technical Specialist', 'Database Architect/Administrator', 'Database Architect/Database Developer', 'Database Architect/Engineer', 'Database Developer', 'Database Developer / Engineer', 'Database Developer/Administrator (SQL Server)', 'Database Engineer', 'Database Engineer (Clearance Required)', 'Database Engineer (MySQL)', 'Database Engineer (NoSQL)', 'Database Engineer (Postgres 10.0 or later), Apple Media Products', 'Database Engineer - 19271', 'Database Engineer - Ads', 'Database Engineer - Oracle', 'Database Engineer - Platform', 'Database Engineer - PostgreSQL', 'Database Engineer - Reliability', 'Database Engineer 3', 'Database Engineer I', 'Database Engineer II', 'Database Engineer II - Oracle & Postgres', 'Database Engineer III', 'Database Engineer, Google Cloud Platform', 'Database Engineer, Infrastructure Automation', 'Database Engineer, Ops Engineering', 'Database Engineer, SQL Server, Cloud', 'Database Engineer: Oracle and/or Mongo - Cleared Position!', 'Database Platform Engineer', 'Decision Scientist', 'Decision Scientist - Data & Media', 'Decision Scientist - Product', 'Deep Learning Data Scientist', 'Deep Learning Scientist', 'Deep Learning Scientist - Autonomous Vehicles', 'Deliver with Uber Eats', 'Dentist', 'Denver, CO Office Agent', 'Design Intern', 'Designer (MCAD)', 'DevOps Engineer (Database Engineering)', 'DevOps Security Engineer', 'DevOps Software Engineer', 'DevOps Systems Administrator', 'Developer Application Services', 'Development Coordinator -New Jersey', 'Diesel Remediation Controller', 'Digital - Lead Database Architect - Data Lake', 'Digital Analytics Engineer', 'Digital Communications Product Manager (603)', 'Digital Copy Writer', 'Digital Data Analyst', 'Digital Graphic Designer', 'Digital Marketing Specialist', 'Digital Media Planner', 'Digital News Operations Trainer', 'Digital Project Manager', 'Digital Strategist + Web Developer', 'Director', 'Director - Asset/Liability Management', 'Director Information Security', 'Director Of Business Development', 'Director Of Continuous Improvement', 'Director Of Development', 'Director Of Field Marketing', 'Director Of Marketing', 'Director Of Operations', 'Director Security', 'Director Software Engineering', 'Director for Community Education and Personal Enrichment', 'Director of Customer Success', 'Director of Cyber Intelligence Unit', 'Director of Cyber Security', 'Director of Information & Cyber Security', 'Director of Machine Learning and AI (Computer Vision)', 'Director of Marketing', 'Director of Platform Security', 'Director of Quality Management (Jedi)', 'Director of Quality and Regulatory', 'Director of Security', 'Director of Strategic Communications & Marketing', 'Director, HRBP', 'Director, Lean and Continuous Improvement', 'Director, Medical Monitoring & Consulting', 'Director, Search Engine Marketing', 'Director, Security', 'Display Core Software Engineer', 'Distribution Center Equipment Technician', 'District Manager- No Holiday Hours!', 'District Manager-Wilmington NC', 'Document Proofreader', 'Drupal Developer', 'Drupal Web Developer', 'E-COMMERCE SPECIALIST / DATA ANALYST', 'E-Commerce Data Analyst', 'E-Commerce: Full Stack Software Engineer III', 'EA Data Analyst - Ion', 'ECM/Java Developer', 'EHS Co-ordinator', 'EHS Manager', 'ERSEA Training Coordinator (Head Start - South Los Angeles)', 'ETL Data Analyst', 'ETL Test Lead', 'Ecommerce Data Analyst', 'Editor', 'Editor, Fine Cooking Magazine', 'Editorial Content Strategist', 'Editorial Intern, New York Magazine', 'Electrical Controls Specialist', 'Electrical Test Technician', 'Electronic Services Librarian', 'Electronic Warfare Business Development - International Location', 'Electronic Warfare Data Scientist', 'Eligibility Clerical Assistant (Seattle, WA)', 'Embedded Software Engineer', 'Embedded Software Engineer (Entry-Level)', 'Embedded Software Engineer (Flight Mission/Space/Electronics/Robotics)', 'Embedded Software Engineer - Electrical Systems', 'Embedded Software Engineer - Principle', 'Embedded Software Engineer, 2+ Years, Robotics/Exoskeletons', 'Energy & Data Analytics Engineer', 'Eng 4, Machine Learning', 'Engineer V, Networks', 'Engineer – Network Monitoring', 'Engineer, Data', 'Engineer, Data Analytics', 'Engineer, Machine Learning', 'Engineering Manager - Machine Learning', 'Engineering, Database', 'Enterprise Account Executive', 'Enterprise Analytics Data Scientist', 'Enterprise Data Architect', 'Enterprise Sales Engineer (Mobile Security, Cloud, VPN)', 'Entry Level - Management Training', 'Entry Level / Associate Business Data Analyst', 'Entry Level Business Analyst / Data Analyst', 'Entry Level Data Analyst', 'Entry Level Data Analyst/ MS BI Developer', 'Entry Level Data Scientist', 'Entry Level Human Resource Specialist', 'Entry Level IT Contractor Role- Business Analyst /Data Analyst', 'Entry Level Management Training', 'Entry Level Software Engineer', 'Entry Level Web Developer', 'Entry-Level Administrative Opportunities', 'Epic Healthy Planet Analyst', 'Event + Sales Producer', 'Event Assistant- Entry Level Marketing', 'Event Coordinator', 'Event Coordinator \\\\ Entry Level', 'Event Marketing Manager', 'Event and Communications Coordinator', 'Events Assistant - Part Time', 'Events Coordinator', 'Excel Specialist (Data Analyst)', 'Exec Director-Pharmacy Service', 'Executive Assistant', 'Executive Assistant To The Chairman', 'Executive Financial Recruiter', 'Executive Recruiter', 'Executive Sous Chef', 'Executive/Personal Assistant to CEO', 'Experienced Web Developer', 'Experienced eCommerce Web Developer - C#, MVC and nopCommerce', 'External Private Markets Quantitative Data Analyst or Senior Analyst', 'FAST Software Engineer', 'FC Network Data Scientist', 'FULL STACK Application WEB Developer', 'FULL STACK WEB DEVELOPER', 'Facilities Office Coordinator', 'Facility Security Officer', 'Facility Security Officer (FSO)', 'February 13th, 2020 RN New Grad Event', 'Fed Pre-Sales Network Systems Engineer', 'Federal Data Scientist', 'Field Application Data Scientist - Junior', 'Field Marketing Manager', 'Fiesta Bowl Event Staff and Security', 'FinTech Data Scientist', 'Financial Advisor', 'Financial Analyst', 'Financial Controller, Staffing Company', 'Financial Data Analyst', 'Financial Data Engineer', 'Financial Planning & Analysis Lead', 'Financial Planning and Analysis Manager', 'Financial Systems/Data Analyst', 'Financial/Data Analyst', 'Fire and security tech', 'Fixed Income Research Analyst', 'Food Science/Contract Manufacturer Manager', 'Forensic Data Analyst - TERM', 'Freelance Web Developer', 'Freelance Web Developer/Designer', 'Front End Developer', 'Front End Developer (5323)', 'Front End Developer (Angular)', 'Front End Engineer - React/Angular', 'Front End Software Engineer in Miami', 'Front End UI/Web Developer', 'Front End Web Developer', 'Front End Web Developer - Marketing Agency', 'Front End Web Developer, NA', 'Front End Web Developer/Designer', 'Front End Web Developer/Designer Intern', 'Front Office Administrator', 'Front end web developer (AV1936', 'Front-End Developer', 'Front-End Developer: Accessibility', 'Front-End Web Developer', 'Front-end Developer', 'Frontend Developer', 'Frontend Software Engineer', 'Frontend Software Engineer (Remote)', 'Frontend Web Developer', 'Frontend Web Developer- Apply now!', 'Frontend Web Developer: up to $200,000 + Equity', 'Full Stack Developer', 'Full Stack Java Developer', 'Full Stack Software Engineer', 'Full Stack Software Engineer (FT)', 'Full Stack Software Engineer (Python / Azure)', 'Full Stack Software Engineer (React)', 'Full Stack Software Engineer - Digital Banking', 'Full Stack Software Engineer / Web Developer', 'Full Stack Web Developer', 'Full Stack Web Developer (Junior)', 'Full Stack Web Developer (Mandarin Required, Full-time/ Part-time)', 'Full Stack Web Developer (Rails/React)', 'Full Stack Web Developer - Entry level', 'Full Stack Web Developer / React Developer / Full stack Developer', 'Full Stack/JavaScript Software Engineer', 'Full stack web developer', 'Full time Java software engineer', 'Full-Stack Software Engineer, Machine Learning', 'Full-Stack Web Developer', 'Full-Stack Web Developer for Scientific Applications', 'Full-Time Security Day Shift in Melbourne, Titusville and Viera areas', 'Fullstack Developer', 'Fullstack Software Engineer - Denver, CO', 'Fundamental Equity Analyst', 'GCP Data Engineer', 'GDOT Project Manager', 'GIS Analyst with Python', 'GIS Data Engineer', 'GIS Developer', 'Gameplay Software Engineer', 'General Manager', 'General Manager - JCB SoCal', 'General Manager - Knoxville, TN', 'Genetic Data Analyst I', 'Genomic Data Scientist', 'Geospatial Analyst', 'Global Data Analyst', 'Global Database Technology Lead', 'Global Head of Cyber Hygiene', 'Global Product Manager -- Software Solutions', 'Global Safety and Security Manager', 'Golang Software Engineer, Backend', 'Govt SAP Security Officer', 'Graphic Design', 'Graphic Design Assistant', 'Graphic Design Intern', 'Graphic Design Intern - Spring 2020', 'Graphic Design Internship', 'Graphic Design Project Manager', 'Graphic Design Specialist', 'Graphic Design Supervisor', 'Graphic Design/ Print Specialist UPS Store Associate', 'Graphic Design/Communications Intern', 'Graphic Designer', 'Graphic Designer (#AM716728)', 'Graphic Designer (CT)', 'Graphic Designer (Corporate)', 'Graphic Designer II', 'Graphic Designer and Web Developer', 'Graphic Designer and Web Developer - HTML CSS JAVASCRIPT PHOTOSHOP', 'Graphic Designer/ Production', 'Graphics Designer/Print Production - 6 Month Contract', 'Greenplum PostgreSQL Database Administrator', 'Ground System Software Engineer', 'HCM Solution Architect', 'HR Administration Data Analyst', 'HR Data Analyst', 'HR Data Scientist', 'HR Manager (Employee Engagement)', 'HR Systems Administrator, SAP (Remote/Work From Home)', 'HRIS Consultant II-LMS', 'Hadoop Data Scientist', 'Hadoop Spark Data Engineer', 'Hardware Engineer - FPGA', 'Head Of Finance', 'Head Of Product Management', 'Head of Business Development', 'Head of Engineering, AI & Machine Learning', 'Head of Engineering, Next Gen Experience', 'Head of Flight Safety', 'Head of Machine Learning', 'Head of Office Operations', 'Head of Product', 'Head of Revenue Marketing', 'Head of Security', 'Head of Software Engineering-Asset Management Firm', 'Head of Systems Engineering & Lead Engineer', 'Health Data Scientist/Engineer', 'Health Scientist Administrator - Center for Quality Improvement and PatientSafety', 'Healthcare Data Analyst', 'Healthcare Data Scientist', 'Healthcare Security Officer', 'Heavy Equipment Mechanic', 'Hedge Fund Analyst', 'HelloSign Security Engineer', 'Help Desk Support Engineer', 'Home Security Customer Support - Lakeland, FL', 'HomeKit Software Engineer', 'Hospital Controller', 'Human Capital Business Analytics – Sr Data Scientist', 'Human Resources (HR) Director', 'Human Resources Administrative Assistant', 'Human Resources Administrator', 'Human Resources Coordinator', 'Human Resources Manager - Part time', 'Human Services Specialist I- Walnut Residence', 'IA/Comms Network Engineer', 'IMS Database Admin.', 'IN-HOUSE/ASSISTANT GC', 'IOS Mobile Application Developer', 'IT - Data Engineer II', 'IT Administrator', 'IT Business Intelligence/Data Analyst II', 'IT Infrastructure Manager', 'IT NETWORK ENGINEER', 'IT Network Engineer', 'IT Project Manager', 'IT SECURITY PROGRAMMER/ANALYST', 'IT SQL Engineer I', 'IT Security / Cyber Security Specialist', 'IT Security Analyst', 'IT Security Analyst I', 'IT Security Architect', 'IT Security Engineer', 'IT Security Manager', 'IT Security Specialist', 'IT Software Asset Manager', 'IT Software Engineer - Data/Database Engineer (NoSQL)', 'IT Specialist/Software Engineer', 'IT Team Lead - Data Engineer', 'IT Technical Associate (Database Architect)', 'IT and Cyber Security', 'ITS Software Engineer', 'Industrial Designer', 'Information Assurance / Cyber Analytics', 'Information Assurance / Security Engineer', 'Information Assurance Security Engineer', 'Information Assurance/Security Intern - Summer 2020', 'Information Security Analyst', 'Information Security Architect', 'Information Security Associate', 'Information Security Engineer', 'Information Security Engineer (Network Security / Checkpoint)', 'Information Security Manager', 'Information Security Specialist', 'Information System Security Professional', 'Information Systems Security Officer', 'Information Technology Security Analyst', 'Information Technology Software Developer', 'Infrastructure Business Analyst', 'Infrastructure Engineer', 'Infrastructure Engineer (New Grad)', 'Infrastructure Project Manager', 'Innovation Consultant', 'Innovation Senior Associate', 'Institutional Data Analyst', 'Instructional Design Specialist', 'Instructional Designer', 'Instructor, Computer Technology - Computer Programming - Occupational Extension - Adjunct -Jamestown', 'Insurance Data Analyst', 'Insurance Data Scientist', 'Insurance Loss Control Consultant - Virtual/Remote from Home Office', 'Integrated Producer/Project Manager', 'Integration Developer', 'Intelligence Analyst', 'Intelligence Data Analyst, Senior', 'Intermediate Data Analyst', 'Intermediate Full Stack Software Engineer (Elixir/ROR)', 'Intern (Masters) - Data Scientist', 'Intern - Software Engineer - Summer 2020', 'Intern Student - Cyber Security', 'Intern, IT Software Engineer (NOA)', 'Intern, Machine Learning', 'Intern, Software Engineer', 'Internship - Data Engineer', 'Internship Opportunities - Medical Center', 'Internship | Experiences', 'Internship: CTO Social - Software Engineer Intern', 'Intervention Specialist - Akron Ohio', 'Inventory Data Specialist', 'Inventory Management Software Engineer - Equities Tech', 'Investment Analyst', 'IoT Data Scientist', 'JDA WM - Software Engineer', 'Java / Web Developer', 'Java Software Engineer', 'Java Web Developer', 'Javascript Developer', 'Javascript Web Developer (SQL, Angular & Spring), USC/GC - T', 'Jr Software Engineer', 'Jr Web Developer', 'Jr. Back End Web Developer', 'Jr. Big Data Engineer', 'Jr. Business Data Analyst', 'Jr. Cisco Network Engineer or CCNA resource', 'Jr. Data Analyst', 'Jr. Data Scientist', 'Jr. Data Scientist (Tableau Big Data)', 'Jr. Data Scientist with AWS exposure', 'Jr. Data Visualization Analyst', 'Jr. Front End Web Developer', 'Jr. Full Stack Software Engineer', 'Jr. Java Developer', 'Jr. Machine Learning Engineers', 'Jr. Network Engineer', 'Jr. Network Engineer Intern', 'Jr. Program Manager', 'Jr. Software Developer', 'Jr. Software Engineer', 'Jr. Systems Engineer', 'Jr. Web Developer', 'Junior Account Executive', 'Junior Brand Designer', 'Junior Customer Data Analyst', 'Junior Cyber Security Analyst', 'Junior Data Analyst', 'Junior Data Analyst (PAU)', 'Junior Data Engineer', 'Junior Data Scientist', 'Junior Devops Engineer', 'Junior Estimator', 'Junior Front-End Web Developer (Temp-to-Hire)', 'Junior Graphic Designer', 'Junior Graphic Illustrator', 'Junior Investment Analyst', 'Junior Network Engineer', 'Junior Network Engineer, Cisco', 'Junior Producer', 'Junior Recruiter', 'Junior Research Analyst', 'Junior Sales and Marketing Representative', 'Junior Software Engineer', 'Junior Statistical Data Analyst', 'Junior Web Designer', 'Junior Web Developer', 'Junior Web/Database Programmer', 'Junior iOS Software Developer', 'Junior/Senior Embedded Software Engineer', 'Juniper SRX Architect/Network Engineer Virginia US Citizen for clearance', 'Key Account Manager', 'Kitchen Manager', 'Korean Speaking Security Systems Engineer', 'LAB TECH ASSISTANT PSC FLOAT', 'LMS Product Owner', 'LaCroix Representative- Sales', 'Lead Android Developer', 'Lead Angular Architect', 'Lead Data Architect', 'Lead Data Engineer', 'Lead Data Engineer, Infrastructure.', 'Lead Data Engineer, Spark', 'Lead Data Scientist', 'Lead Data Scientist - Automation Lab (PwC Labs)', 'Lead Data Scientist - Experimentation', 'Lead Data Scientist - Modeling', 'Lead Data Scientist IV, Central Analytics', 'Lead Data Scientist, Data Analytics & AI', 'Lead Database Engineer', 'Lead Database Engineer - Oracle', 'Lead Desktop & Network Engineer', 'Lead Embedded Software Engineer', 'Lead Front-End Developer', 'Lead Geospatial Data Scientist', 'Lead Machine Learning DevOps Engineer', 'Lead Mbr Engrg Staff/ Software Engineer', 'Lead Network Engineer', 'Lead Principal Software Engineer-DevOps', 'Lead Product Designer', 'Lead Software Developer', 'Lead Software Engineer', 'Lead Software Engineer (JR1009297)', 'Lead Software Engineer - Mobile', 'Lead Software Engineer -Java', 'Lead Software Engineer, Data Engineering', 'Lead UI Software Engineer', 'Lead Video Architect', 'Lead Web Developer', 'Lead, Software Engineer', 'Leader, Cyber Defense – Attack Surface Reduction', 'Learning Data Analyst I-II', 'Learning Systems Data Scientist & Administrator', 'Legal IT Solutions Engineer (SQL Engineer)', 'Librarian, Boulder County Campus', 'Licensed Unarmed Security Guard', 'Linux Software Engineer', 'Linux Systems Engineer', 'Litigation Marketing Maanager', 'Logistics Analyst', 'Logistics Coordinator - Supply Chain', 'Logistics Data Analyst', 'Logistics Dispatcher', 'Longitudinal Data Analyst 9-11', 'Looking for Professional, IT Production Application Support/TSQl Database', 'Luxury Sales Stylist - Mens - Saks Fifth Avenue', \"Luxury Sales Stylist - Women's Contemporary\", 'MANAGEMENT & PROGRAM ANLYST', 'MANAGEMENT AND PROGRAM ANALYST', 'MASTER DATA ANALYST', 'MEAN developer', 'MES IT Product Manager', 'MGR, Security', 'MSBI Azure data Engineer', 'Machine Learning / NLP Data Scientist', 'Machine Learning /Artificial Intelligence - Product Analyst - Columbus, OH', 'Machine Learning Applied Scientist', 'Machine Learning Architect', 'Machine Learning Compiler Engineer', 'Machine Learning Data Scientist', 'Machine Learning Developer', 'Machine Learning Developer - Deep Learning', 'Machine Learning Engineer', 'Machine Learning Engineer (Remote)', 'Machine Learning Engineer - Health ML', 'Machine Learning Engineer - NLP', 'Machine Learning Engineer - Search', 'Machine Learning Engineer Manager', 'Machine Learning Engineer, Ads Retrieval', 'Machine Learning Engineer, Homefeed', 'Machine Learning Engineer, Perception', 'Machine Learning Engineering Lead', 'Machine Learning Evangelist', 'Machine Learning Intern', 'Machine Learning Intern at DIL', 'Machine Learning Quant Researcher', 'Machine Learning Research Engineer', 'Machine Learning Researcher', 'Machine Learning Researcher - Hedge Fund', 'Machine Learning Researcher Intern', 'Machine Learning Researcher, AI Research', 'Machine Learning Scientist', 'Machine Learning Scientist (DNNs, Optimization, Deep Learning)', 'Machine Learning Scientist (Speech)', 'Machine Learning Software Engineer', 'Machine Learning Team Lead', 'Machine Learning Workload Development - Intern', 'Machine Learning and Data Engineer Intern', 'Machine Learning(Senior)', 'Machine Learning, Lead Engineer', 'Machine Learning-Consultant', 'Machine Learning/AI (ideally Deep Learning)', 'Machine Learning/Deep Learning Research Scientist:  up to $250,000 + Equity', 'Machine Learning/Deep Learning Research Scientist: up to $250,000 + Eq', 'Machine Learning/Deep Learning Research Scientist: up to $250,000 + Equity', 'Machine Learning/Predictive Analytics Scientist', 'Mainframe Developer', 'Mainframe Software Engineer', 'Maintenance Mechanic (Second Shift)', 'Major Market Corporate Payment Solution Sales', 'Management & Program Assistant.', 'Management Trainee (Entry Level & Full Time)', 'Manager - Engineering and Maintenance', 'Manager :Marketing Ops and Data Analyst', 'Manager International Security & Safety', 'Manager Supply Chain Excellence', 'Manager of Infrastructure Security', 'Manager of Network Engineers', 'Manager of Security', 'Manager of Security Operations', 'Manager, Competitive Intelligence/Data Scientist', 'Manager, Data Scientist', 'Manager, Digital Marketing', 'Manager, Digital Technologies', 'Manager, Internal Evaluation Program (IEP)', 'Manager, Software Engineer', 'Managing Attorney', 'Manufacturing Engineer - Furniture', 'Manufacturing IT Data Analyst', 'Mapping and Data Analyst', 'Market Activation Specialist', 'Market Data Analyst (Trane Energy Supply)', 'Market Resource Manager', 'Marketer PR Position', 'Marketing / PR', 'Marketing Analytics Consultant-Loyalty Campaigns', 'Marketing Assistant *Spring Opportunities Available *', 'Marketing Communications Manager', 'Marketing Content Manager', 'Marketing Coordinator', 'Marketing Data Analyst', 'Marketing Data Science Analyst / Data Scientist - Omaha', 'Marketing Data Scientist', 'Marketing Manager', 'Marketing Web Developer', 'Marketing and Branding Assistant', 'Master Data Analyst', 'Master Data Engineer - Card Technology', 'Master Electrician - Marshall Islands', 'Master Production Scheduler', 'Master Scheduler', 'Mbr Engrg Staff/ Software Engineer', 'Mechanical Project Engineer', 'Media Coordinator', 'Media Relations Officer', 'Medicaid Reporting and Data Analyst', 'Medical Director', 'Medical Front Desk Receptionist', 'Medical Writer', 'Meetings and Events Specialist', 'Membership & Marketing Coordinator', 'Merchant- Grains and Commodities', 'Mgr 3 Data and Analytics', 'Microservices Software Engineer', 'Microsoft Network Engineer', 'Microsoft Server and Network Engineer', 'Microsoft Specialist / Full Stack Developer', 'Mid-Level Network Engineer', 'Mid-Level Software Engineer', 'Mid-level Software Engineer', 'Mid/Sr. Software Engineer', 'Mitigation Project Manager', 'Mobile Application Software Engineer', 'Mobile Developer', 'Mobile Developers (NO C2C), Unlimited PTO', 'Mobile Engineer (Machine Learning/Computer Vision)', 'Mobile Marketing Supervisor', 'Mobile Software Engineer', 'Mobile and UI/UX Web Developer', 'Mobile/Cloud Software Engineer', 'Modem Platform Software Engineer', 'Mongo Database Engineer', 'Mortgage Insuring Agent', 'Multifamily Asset Manager I', 'MySQL Database Engineer', 'NASA Lunar Rover Robotics Software Engineer - C++ Linux', 'NCG: Software Engineer', 'NCIS Front End Web Developer', 'NLP - Data Scientist II', 'NTCIP Software Engineer', 'National Account Sales Manager', 'National Recruiter', 'Network / Infrastructure & SQL Database Admin / Engineer', 'Network Administrator', 'Network Administrator w/Security Clearance', 'Network Advanced Services Engineer (SDN)', 'Network Avaya Engineer', 'Network Engineer', 'Network Engineer - Indianapolis, IN', 'Network Engineer - Junior', 'Network Engineer - L2 Engineer - MSP', 'Network Engineer - Layer 2 & 3', 'Network Engineer - UCD Design', 'Network Engineer - Westborough, MA - Full time', 'Network Engineer 4 - Managed Enterprise Services', 'Network Engineer I', 'Network Engineer II', 'Network Engineer II - Core & Backbone Optical', 'Network Engineer Level II', 'Network Engineer, LAN', 'Network Pentest Security Engineer, AWS', 'Network Security Engineer', 'Network Systems Engineer', 'Network Technician', 'Network and Virtualization Engineer #0129', 'Network engineer', 'Network/Software/Systems Engineer', 'New Grad, Software Engineer, Perception', 'New Product Operations Manager', 'Night Security Guard', 'OCI Principal Data Scientist', 'OCI Senior Data Scientist', 'OEM Sales Representative', 'OFFICER SECURITY', 'ORACLE Database Engineer (Administrator)', 'OSIsoft PI Software Engineer', 'Occupancy Planning Data Analyst', 'Office & Admin Specialist Int', 'Office & Events Coordinator', 'Office 365 Security Engineer', 'Office Administrator - (Foundation)', 'Office Manager', 'Office Manager (Atlanta, GA)', 'On Premise Specialist', 'Onsite Account Manager', 'Open Interviews', 'Opening General Manager - Hampton Inn Avon', 'Operations Associate, Career Services', 'Operations Coordinator-New Grads!', 'Operations Manager', 'Operations Specialist', 'Operations and Sustainability Coordinator', 'Oracle / PostgreSQL Database Administrator', 'Oracle Database Admin IV', 'Oracle Database Administrator', 'Oracle Database Engineer - PostgreSQL', 'Oracle EBS Security Consultant', 'Oracle ERP Cloud Security Administrator', 'Oracle Web Developer', 'Oracle with Open Database Connectivity (ODBC)', 'Organizational Change Management Consultant', 'Outreach Coordinator #2605', 'Outreach Specialist for Frontline', 'Outside Sales Representative', 'PEGA', 'PHP MySQL Web Developer', 'PHP Web Developer', 'PHP Web Developer (Contractor)', 'PLC/Software Engineer', 'PMP, Financial Projects', 'PR Account Executive', 'PROSPECTNG DATA SCIENTIST - SUPPORTING SALES', 'PSEGLI Senior IT Data Analyst', 'Paralegal', 'Paralegal / Legal Assistant III Supporting the FBI with Security Clearance', 'Part Time Full Stack Software Engineer - Gaming and Esports', 'Patient Access Rep II/ Admitting Rep II', 'Patient Escort', 'Patient Services Coordinator', 'Payroll Coordinator', 'Pediatric RN Registered Nurse HC On Call 5 PM - 8 AM', 'People Analytics Data Engineer', 'Peoplesoft Financial Anayst', 'Personal Assistant', 'Personnel Security Specialist', 'Pharmacy Technician (Web Design or Graphic Design Background a plus)', 'Philanthropic CRM Senior Analyst or CRM Analyst (Renton, WA or Portland, OR)', 'Planner', 'Planner (Development)', 'Planning, Policy and Business Analysis (Cyber Security)', 'Plant Buyer - Fairport', 'Plant Manager', 'Plant Systems Engineer', 'Platform Software Engineer', 'Playlist Coordinator', 'Portfolio Strategist', 'Postal Clerk - Mail Service', 'Postdoc, Geospatial Data Scientist, Director of Business Development', 'PostgreSQL Database Admin', 'Power BI Data Analyst', 'Power Systems Engineer', 'Predictive Analytics Principal - Marketing Analytics - Medicare', 'Press Relations Officer', 'Pricing Analyst', 'Pricing Data Analyst', 'Principal / Sr Principal Hive SQL Engineer', 'Principal Applied and Data Scientist', 'Principal Cybersecurity Data Analyst', 'Principal Data Scientist', 'Principal Data Scientist - Deep Learning', 'Principal Data Scientist, Translational Data Science', 'Principal Data Scientist- Foundational Algorithm CRM Email', 'Principal Database Engineer', 'Principal Machine Learning Computer Vision Lead', 'Principal Machine Learning Engineer', 'Principal Machine Learning Engineer (Python)', 'Principal Network Engineer', 'Principal Network Systems Engineer', 'Principal SQL Engineer', 'Principal Software Engineer', 'Principal System Security Engineer', 'Principle Data Scientist', 'Private Equity Associate (2021)', 'Prncpl Software Engineer', 'Process Analyst', 'Process Engineer', 'Procurement Manager', 'Producer', 'Product Analyst', 'Product Analyst, Performance', 'Product Cyber Security Supervisor', 'Product Data Analyst', 'Product Data Engineer', 'Product Data Scientist', 'Product Design, Project Manager', 'Product Development Engineer', 'Product Development Engineer II', 'Product Educator Creator - Beauty', 'Product Engineering Lab Technician', 'Product Intern, Apple Services Growth', 'Product Manager', 'Product Manager - Anchor', 'Product Manager - Communnications', 'Product Manager - Data Processing Suite', 'Product Manager - Mobile', 'Product Manager - Technical', 'Product Manager – Devices', 'Product Manager, Calibra', 'Product Manager, Consumer', 'Product Manager, Core News', 'Product Manager, Insights and Analytics', 'Product Manager, Instagram', 'Product Manager, Instagram Shopping', 'Product Manager, Release Products', 'Product Manager, Studio (Post Production)', 'Product Manager, Web App', 'Product Manager, WhatsApp Business', 'Product Operations Coordinator', 'Product Owner', 'Product Owner - Healthcare Enrollment & Billing', 'Product Security Specialist', 'Product Specialist', 'Product Strategist', 'Product Supervisor', 'Product Support Engineer', 'Product/ Lifestyle Photographer', 'Product/Marketing Manager - Software', 'Production 2019 - 09', 'Production Coordinator', 'Production Planning Manager', 'Production and Product Development Coordinator', 'Professional Dog Walker', 'Professional-Data Scientist', 'Program Analyst (Data Scientist)', 'Program Assistant - Shelton Campus', 'Program Manager - Heavy Truck', 'Program Manager- Data Analyst', 'Programmer / Software Engineer', 'Programmer/Application Specialist', 'Programmer/Software Development Engineer', 'Programming Analyst', 'Project Admin Assistant', 'Project Assistant', 'Project Controls Analyst', 'Project Coordinator', 'Project Coordinator (Term-Exempt)', 'Project Coordinator, Security Systems', 'Project Data Analyst', 'Project Employee, Social Content', 'Project Engineer', 'Project Manager', 'Project Manager - BOSTON', 'Project Manager - Must be local to San Francisco, CA', 'Project Manager - Product Development', 'Project Manager - Residential Renovations', 'Project Manager / Administrator Laboratory', 'Project Manager Supply Chain', 'Project Manager, Strategic Initiatives', 'Project manager / Data Analyst Specialist - Behavioral Health', 'Project/Program Coordinator', 'Property Manager', 'Psychologist', 'Public Relations - Account Executive - HEALTHCARE', 'Purchasing Agent/Data Analyst', 'Purchasing Coordinator', 'Pyspark/Data Engineer', 'Python Data Engineer', 'Python Developer', 'Python Engineer (Machine Learning)', 'Python Software Engineer', 'QA Data Analyst', 'QA Process Development Consultant', 'QA Tester', 'QNXT Web Developer', 'QST/Security Monitor', 'Qlik Web Developer', 'Quality Assurance', 'Quality Assurance Architect', 'Quality Assurance Mobile', 'Quality Assurance Technical Manager', 'Quality Assurance Test Analyst', 'Quality Control Manager', 'Quality Control Technician', 'Quality Engineer', 'Quality Monitoring Data Analyst', 'Quality Specialist', 'Quantitative Analytics Senior - Data Scientist', 'Quantitative Researcher - Equities', 'Quantitative Researcher - Machine Learning Platform', 'R&D Data Analyst', 'R05 Security Officer (FT/2nd shift)', 'R07 Security Dispatch (FT/2nd shift)', 'REF Web Developer', 'Radiologist Assistant', 'Rate Data Analyst', 'React Web Developer', 'ReactJS web developer', 'Real Estate Asset Management Analyst', 'Real Estate Investment-Sales Associate', 'Receptionist/Security', 'Recruiter', 'Red Team Security Engineer, AWS', 'Regional Marketing Manager', 'Regional Outreach (Business Development) Specialist', 'Regional Portfolio Manager', 'Regional Product Manager', 'Regional Vice President, Sales & Services', 'Registered Nurse', 'Registered Nurse - MICU/CCU - Night Shift', 'Regulatory Compliance Manager (TX)', 'Relationship Manager', 'Remote Inpatient Medical Coder', 'Remote Sr. Software Engineer (No Sponsorship)- Permanent Role', 'Reporting Data Analyst', 'Reporting/Data Analyst', 'Research Analyst', 'Research Analyst (Excel/Client Facing)', 'Research And Development Scientist', 'Research Associate', 'Research Data Analyst', 'Research Data Analyst - COR', 'Research Data Analyst - TX0013937590', 'Research Data Analyst II (2 Positions)', 'Research Data Analyst-Center for Pediatric Clinical Effectiveness', 'Research Informatics Data Scientist', 'Research Intern - Privacy-Preserving Machine Learning', 'Research Intern – Machine Learning & A.I.', 'Research Investigator', 'Research Scientist (Machine Learning Engineer)', 'Research Scientist (Machine Learning/Deep Learning)', 'Reservoir Engineer', 'Residential Security Officer - Concierge - Overnights', 'Residential Security Officer - Concierge - Swing Shift', 'Respiratory Therapist', 'Retail Communications Manager', 'Retail Sales/ Graphic Design', 'Retail Sales: Non-Retail Hours, Uncapped Bonuses!', 'Return to Work Program - Software Engineer - Backend', 'Revenue Manager', 'Risk Data Engineer', 'Robotics Software Engineer', 'Roofing Project Manager', 'Ruby on Rails Developer', 'SAFETY AND SECURITY OFFICER', 'SAP BODS Consultant', 'SAP Data Analyst', 'SAP Data Engineer', 'SAP EWM Functional Consultant', 'SAP Fiori Web Developer', 'SAP Project Manager', 'SAS Analytical Consultant (Data Scientist)', 'SAS Data Scientist', 'SDET to test BOTs (built using RPA)', 'SECURITY INVESTIGATOR', 'SECURITY OFFICER.120.68076', 'SENIOR DATA ANALYST (TABLEAU , AWS EXP.)', 'SENIOR DATA SCIENTIST', 'SENIOR Data Scientist', 'SENIOR SOFTWARE ENGINEER', 'SENIOR SOFTWARE ENGINEER (RUBY)', 'SENIOR WEB DEVELOPER - FREELANCER', 'SOC Analyst', 'SOFTWARE ENGINEER', 'SQL  Database Developer', 'SQL Data Analyst', 'SQL Data Engineer', 'SQL Database Architect', 'SQL Database Engineer', 'SQL Developer', 'SQL Developer - 19-07262', 'SQL Developer, Sr.', 'SQL Developer/EDI Data Analyst', 'SQL ETL Data Engineer', 'SQL Engineer', 'SQL Software Engineer', 'SQL Support Engineer', 'SR NETWORK ENGINEER', 'SSAS SQL Developer', 'SUPV - SECURITY', 'SVP -- Surveillance Data Scientist', 'SVP Corporate Development', 'SWE 2019 - Software Engineer', 'SYSTEMS ENGINEER', 'Safety & Sustainability Data Analyst*', 'Sales Advisor', 'Sales And Marketing Representative', 'Sales And Marketing Specialist', 'Sales Business Development', 'Sales Business Development Manager', 'Sales Data Analyst', 'Sales Data Analyst/Sales Support', 'Sales Development Representative', 'Sales Development Representative (SDR)', 'Sales Manager', 'Sales Manager, East Coast, French speaking, Food industry', 'Sales Operations Manager', 'Sales Planning Manager', 'Sales Representative', 'Sales Training Manager', 'Salesforce Administrator', 'School Security Officer', 'Scientist', 'Scientist - Intelligent Controls', 'Scientist/Sr. Scientist, Antibody Discovery', 'Scrum Master', 'Search Engine Optimization Specialist', 'Security', 'Security - Holland', 'Security - MA12993869', 'Security - Security Guards', 'Security Administrator', 'Security Analyst', 'Security Architect', 'Security Automation Engineer', 'Security Badging Administrator', 'Security Compliance Analyst', 'Security Consultant and Managers Needed', 'Security Data Scientist', 'Security Engineer', 'Security Engineer (Red Team) - CTJ', 'Security Engineer( Tier 3 Firewall)', 'Security Engineer, AWS', 'Security Engineer, Detection and Response', 'Security Guard', 'Security Guard (Unarmed)', 'Security Investigations Analyst', 'Security Investigations Internship - Summer 2020', 'Security Investigator', 'Security Manager', 'Security Manager (Security Clearance Required)', 'Security Manager L1', 'Security Officer', 'Security Officer I - Oklahoma City', 'Security Officers', 'Security Operations Manager', 'Security P/T weekends', 'Security Sergeant - Delta Junction, AK', 'Security Software Product Engineer (I)', 'Security Specalist', 'Security Specialist', 'Security Specialist - Senior (Security Clearance Required)', 'Security Supervisor', 'Security Systems Manager', 'Security Technology Specialist', 'Security Threat Administrator', 'Selling And Service Supervisor - SAKS OFF 5TH', 'Selling Associate - SAKS OFF 5TH', 'Senior .NET Developer', 'Senior .NET Software Developer', 'Senior .NET Software Engineer', 'Senior .Net Azure Developer', 'Senior Account Director', 'Senior Account Executive', 'Senior Accountant', 'Senior Accountant - 19-07170', 'Senior Agile Product Owner', 'Senior Android Engineer', 'Senior Android Software Engineer', 'Senior Application Security Engineer', 'Senior Associate Data Scientist', 'Senior Associate, SQL Engineer', 'Senior Big Data Engineer', 'Senior Business Analytics Database Engineer', 'Senior Business Data Analyst', 'Senior Business Data Science Analyst', 'Senior Business Intelligence Analyst', 'Senior Business Retail Sales Analyst', 'Senior Business Systems Analyst', 'Senior C# Software Engineer', 'Senior C++ Developer', 'Senior Chemist - Formulation', 'Senior Cisco Network Engineer', 'Senior Cisco Network Engineer - Westborough, MA', 'Senior Climatic Database Engineer (Level 3)', 'Senior Cloud Developer', 'Senior Cloud Software Engineer', 'Senior Compliance Specialist', 'Senior Consultant – Data Scientist (Python, VBA, Excel)', 'Senior Cyber Security Engineer', 'Senior Data Analyst', 'Senior Data Analyst (R&D)', 'Senior Data Analyst - Marine Operations', 'Senior Data Analyst, Disney+ Analytics', 'Senior Data Analyst, Research', 'Senior Data Analyst- Product', 'Senior Data Engineer', 'Senior Data Engineer (Big Data Operations)', 'Senior Data Engineer (Data Feed - SQL)', 'Senior Data Engineer (Java/Python/AWS)', 'Senior Data Engineer (NO C2C)', 'Senior Data Engineer (Spark) - REMOTE', 'Senior Data Engineer (XBRL)', 'Senior Data Engineer, OneView', 'Senior Data Scientist', 'Senior Data Scientist (Big Data, Python, Machine Learning)', 'Senior Data Scientist - Big Data', 'Senior Data Scientist - Consumer Analytics (Irving, TX)', 'Senior Data Scientist - Technology', 'Senior Data Scientist II', 'Senior Data Scientist | Deep Learning - NLP', 'Senior Data Scientist – Corporate Training', 'Senior Data Scientist, Analytics & Inference', 'Senior Data Scientist, Business Analytics', 'Senior Data Scientist, Data Analytics & AI', 'Senior Data Scientist, Machine Learning', 'Senior Data Scientist, Product - Resume Search', 'Senior Data Scientist, System Modeling- Framingham/MA', 'Senior Data Scientist, WW Operations Finance', 'Senior Database Administrator', 'Senior Database Architect', 'Senior Database Architect - IT', 'Senior Database Developer', 'Senior Database Engineer', 'Senior Database Engineer (PostgreSQL)', 'Senior Database Engineer - MySQL', 'Senior Design Engineer', 'Senior Developer - Machine Learning Applications', 'Senior Director, Brand and Digital Marketing', 'Senior ETL Developer', 'Senior Engineer / Project Manager', 'Senior Engineer, Software Engineering (Database Engineer)', 'Senior Finance Analyst', 'Senior Front End Developer (REMOTE)', 'Senior Front End Web Developer', 'Senior Front End Web Developer - UI and ReactJS', 'Senior Frontend Engineer', 'Senior Frontend Web Developer', 'Senior Full Stack Web Developer', 'Senior Graphic Designer', 'Senior Health Care Analyst', 'Senior Healthcare Data Analyst-Data Quality and Validation', 'Senior Healthcare Data Scientist', 'Senior Human Resources Generalist', 'Senior IT Auditor', 'Senior IT Security Engineer', 'Senior Insider Threat Analyst', 'Senior Java Web Developer', 'Senior Lab Data Analyst (SAS)', 'Senior Machine Learning Core Engineer', 'Senior Machine Learning Engineer', 'Senior Machine Learning Engineer - SEAL', 'Senior Manager Enterprise Data Scientist', 'Senior Manager Product Strategy', 'Senior Manager, Data Engineer - Card Technology', 'Senior Manager, Digital Product Management (19-37)', 'Senior Manager, Machine Learning', 'Senior Media Buyer', 'Senior Media Planner/Buyer: Finance', 'Senior Mortgage Processor', 'Senior MySQL Database Admin', 'Senior MySQL Database Engineer', 'Senior Network Administrator', 'Senior Network Engineer', 'Senior Network Engineer (Cisco)', 'Senior Network Engineer - Planning & Design', 'Senior Network Engineer SME', 'Senior Network and Security Engineer (Contract)', 'Senior Oracle Database Administrator', 'Senior Oracle Database Administrator / Engineer', 'Senior Oracle PL/SQL Engineer', 'Senior Outreach Coordinator', 'Senior Pre-Sales Engineer', 'Senior Pricing Analyst', 'Senior Principal Software Engineer', 'Senior Product Advisor', 'Senior Product Designer', 'Senior Product Manager', 'Senior Product Manager II', 'Senior Product Manager, Confluent Platform', 'Senior Program Manager', 'Senior Project Leader', 'Senior Project Manager', 'Senior Project Manager with PEGA Implementation', 'Senior Project Manager/ Project Engineer', 'Senior Quality Data Analyst', 'Senior React Front-End Developer', 'Senior Research Data Scientist', 'Senior SQL Database Admin', 'Senior SQL Database Engineer', 'Senior SQL Developer', 'Senior SQL Developer / Architect (PostgreSQL)', 'Senior SQL Programmer', 'Senior Security Analyst', 'Senior Security Engineer', 'Senior Security Systems Engineer', 'Senior Software Developer', 'Senior Software Development Engineer Test', 'Senior Software Engineer', 'Senior Software Engineer (3 openings)', 'Senior Software Engineer (C#/ASP.NET)', 'Senior Software Engineer (Coupang Media Group)', 'Senior Software Engineer (Full Time)', 'Senior Software Engineer (Integration CoE)', 'Senior Software Engineer (Java)', 'Senior Software Engineer (React)', 'Senior Software Engineer (React.JS)', 'Senior Software Engineer - Avalara CertCapture (5933)', 'Senior Software Engineer - Controls - Autonomous Driving', 'Senior Software Engineer - Core Java', 'Senior Software Engineer - Corptax', 'Senior Software Engineer - Demand Side Platform', 'Senior Software Engineer - FHIR', 'Senior Software Engineer - Finance', 'Senior Software Engineer - Localization, Autonomous Driving', 'Senior Software Engineer - Louisville Experience Center', 'Senior Software Engineer - Machine Learning Platform', 'Senior Software Engineer -- Networking', 'Senior Software Engineer – Agile Environment', 'Senior Software Engineer, API Frameworks', 'Senior Software Engineer, Back End', 'Senior Software Engineer, Backend (Streaming Data)', 'Senior Software Engineer, Features', 'Senior Software Engineer, Growth', 'Senior Software Engineer, Software Infrastructure - Autonomous Driving', 'Senior Software Engineer, WoW Classic', 'Senior Software Engineer- Applications', 'Senior Software Engineer- Python', 'Senior Software Engineer- React/Redux, GraphQL', 'Senior Software Engineer: dotnet and node.js', 'Senior Software Support Engineer', 'Senior Systems Database Engineer', 'Senior Systems Engineer', 'Senior Systems Engineer (Web Systems and IIS)', 'Senior Tax Manager', 'Senior Technical Business Analyst', 'Senior Threat Detection Analyst', 'Senior Threat Intelligence Analyst', 'Senior Web Application Developer', 'Senior Web Applications Developer', 'Senior Web Developer', 'Senior Web Developer (Full-Stack)', 'Senior Web Developer\\u200b\\u200b\\u200b (Front -End)', 'Senior iOS Engineer', 'Senior or Principal Software Engineer - Oracle Cloud Infrastructure', 'Server Side Software Engineer (Start Date January 2020)', 'Service Delivery Manager', 'Service Desk Manager', 'Service Technician', 'Services Software Engineer', 'Sharepoint Consultant', 'Shop Development and Construction Coordinator', 'Shopify Front End Web Developer', 'Shopify Plus Web Developer', 'Siri - Data Scientist, Data Organization', 'Siri - Embedded Data Scientist, Data Organization', 'Siri - Machine Learning Manager', 'Siri - Senior Software Engineer, Weather', 'Site Reliability Engineer:  up to $175,000', 'Social & Community Coordinator, DUST', 'Social Media Coordinator', 'Social Media Marketing Strategist', 'Social Media Specialist', 'Social Media Strategist', 'Social Media Strategist (Start-Up Lifestyle Brand)', 'Social Media/Marketing Wizard and Web Developer', 'Software Data Engineer', 'Software Database Engineer 2', 'Software Developer', 'Software Developer - Bloomberg', 'Software Developer Engineer II', 'Software Developer II, Java', 'Software Developer III', 'Software Developer In Test', 'Software Developer/Engineer', 'Software Development Engineer', 'Software Development Engineer - Machine Learning', 'Software Development Engineer II', 'Software Development Engineer in Test', 'Software Development Project Manager', 'Software Engineer', 'Software Engineer $5000 Bonus', 'Software Engineer (.NET core)', 'Software Engineer (.NET)', 'Software Engineer (.Net)', 'Software Engineer (Bethesda, MD or Remote)', 'Software Engineer (C/C++)', 'Software Engineer (Colorado)', 'Software Engineer (Computer Graphics)', 'Software Engineer (Course Exchange)', 'Software Engineer (Entry Level)', 'Software Engineer (Entry level)', 'Software Engineer (Full Stack)', 'Software Engineer (JSF)', 'Software Engineer (Java)', 'Software Engineer (Java/C#, TypeScript, Angular 2)', 'Software Engineer (MEAN Stack)', 'Software Engineer (Machine Learning)', 'Software Engineer (Mid / Senior)', 'Software Engineer (NASA) - Entry Level', 'Software Engineer (OpCity)', 'Software Engineer (PT)', 'Software Engineer (Portland)', 'Software Engineer (Python)', 'Software Engineer (Python, DevOps)', 'Software Engineer (Ref #SC)', 'Software Engineer (Ruby or React)', 'Software Engineer (SPARTA)', 'Software Engineer (Spring 2020 Co-Op)', 'Software Engineer (User Authentication, security, access control)', 'Software Engineer - Apple Health', 'Software Engineer - Apps Programmer/Analyst 3', 'Software Engineer - Backend', 'Software Engineer - Backend (Sync Gaming)', 'Software Engineer - C++', 'Software Engineer - C++,Java', 'Software Engineer - Cloud', 'Software Engineer - Cloud and Microservices', 'Software Engineer - Computer Vision & Image Processing', 'Software Engineer - Data Analytics', 'Software Engineer - Data Services', 'Software Engineer - Data Visualization', 'Software Engineer - DevOps', 'Software Engineer - Entry Level', 'Software Engineer - Front End', 'Software Engineer - Full Stack', 'Software Engineer - Full Stack Web Developer', 'Software Engineer - Golang', 'Software Engineer - Java', 'Software Engineer - Java Microservices', 'Software Engineer - LabView Experience', 'Software Engineer - Labs', 'Software Engineer - Level II', 'Software Engineer - Machine Learning', 'Software Engineer - Mid Level', 'Software Engineer - New Grad', 'Software Engineer - Platform', 'Software Engineer - Precision Medicine', 'Software Engineer - Python/C++', 'Software Engineer - Radar Systems', 'Software Engineer - React Native', 'Software Engineer - Robotics and Autonomous Systems (AER0003LF/LG)', 'Software Engineer - Services', 'Software Engineer - Telephony', 'Software Engineer - Think Tank Team', 'Software Engineer - Third Party Tools', 'Software Engineer - University Graduate', 'Software Engineer - Wearables', 'Software Engineer - Web', 'Software Engineer - cDVR', 'Software Engineer .NET/C#', 'Software Engineer / Application Developer', 'Software Engineer 1', 'Software Engineer 1 - Full Stack .NET (Yarmouth, ME)', 'Software Engineer 2', 'Software Engineer 3', 'Software Engineer 4', 'Software Engineer I', 'Software Engineer I (entry level)', 'Software Engineer I - Associate Development Program', 'Software Engineer I - Java', 'Software Engineer II', 'Software Engineer II - Backend', 'Software Engineer II - Data Visualization', 'Software Engineer II - Frontend', 'Software Engineer II - Technology', 'Software Engineer II, Backend, Zoro', 'Software Engineer III', 'Software Engineer IV', 'Software Engineer In Test', 'Software Engineer Intern', 'Software Engineer Intern (Boulder, CO - Summer 2020)', 'Software Engineer Intern - Application Support', 'Software Engineer Level 2', 'Software Engineer Manager', 'Software Engineer Sr.', 'Software Engineer Summer Intern', 'Software Engineer V', 'Software Engineer for Virtual Reality', 'Software Engineer in Test', 'Software Engineer in Test - Machine Learning', 'Software Engineer – Cloud team', 'Software Engineer – Jr. (DoD clearance required)', 'Software Engineer ‚Äì Automation and Testing (OpCity)', 'Software Engineer(Entry Level)', 'Software Engineer, API Platform', 'Software Engineer, Analytics', 'Software Engineer, Android Innovation', 'Software Engineer, Application Security', 'Software Engineer, Back End', 'Software Engineer, Back-End or Full Stack', 'Software Engineer, Backend', 'Software Engineer, Backend - Intern', 'Software Engineer, Data - Innography', 'Software Engineer, DevOps', 'Software Engineer, E-commerce', 'Software Engineer, Extensibility', 'Software Engineer, Frontend Product', 'Software Engineer, Full Stack', 'Software Engineer, Game Security', 'Software Engineer, Infrastructure Services', 'Software Engineer, MES', 'Software Engineer, New Grad', 'Software Engineer, Product', 'Software Engineer, RippleNet', 'Software Engineer, SRE-Database Admin', 'Software Engineer, Storage & Caching', 'Software Engineer, Web', 'Software Engineer, WoW Classic', 'Software Engineer- Android (Consumer Apps)', 'Software Engineer- Entry Level', 'Software Engineer- Level 3', 'Software Engineer- Linux  Development', 'Software Engineer- Machine Learning', 'Software Engineer- Machine Learning Internship', 'Software Engineer- Navigation and Robotics', 'Software Engineer- TS/SCI- Miami, FL', 'Software Engineer-Entry Level', 'Software Engineer-IBM Assembler, z/OS', 'Software Engineer-Java Developer - EnterWorks', 'Software Engineer-Multiple Openings', 'Software Engineer/ Designer/ C++ / Embedded', 'Software Engineer/Developer', 'Software Engineer/Scientist II', 'Software Engineer: C++ (Gaming)', 'Software Engineer: iOS Accessibility Research', 'Software Firmware Engineer', 'Software Process Engineer', 'Software Project Manager', 'Software Quality Assurance Analyst', 'Software Quality Assurance Manager', 'Software Sales Representative', 'Software Simulation Testbed Developer', 'Software Systems Engineer', 'Software and Data Engineer', 'Software and Web Developer I', 'Software engineer/developer C#, .Net, Angular, Azure', 'Special Assistant (working title: Research Data Officer 1 – Data Scientist)', 'Specialist', 'Specialist Network Engineer', 'Specialist, Corporate Security Operations', 'Specialist, Display & Paid Social', 'Sponsor Funded Professional | Project Manager', 'Spotter', 'Spring Intern', 'Sr Computer Vision / Machine Learning Engineer (Contract)', 'Sr Data Analyst', 'Sr Data Engineer - BBB- req 595-1', 'Sr Data Engineer - Hadoop', 'Sr Data Scientist', 'Sr Data Scientist - Alexa Shopping', 'Sr Database Engineer', 'Sr IT Database Engineer', 'Sr Informix Database Admin', 'Sr Mbr Engrg Staff/ Software Engineer', 'Sr Network Engineer', 'Sr Network Engineer Legal Offices', 'Sr Oracle Database Engineer', 'Sr Project Manager', 'Sr SQL Server Database Admin', 'Sr Security Implementation Engineer (Firewall)', 'Sr Software Engineer', 'Sr Software Engineer ( API , NodeJS ) - REMOTE', 'Sr Software Engineer (Data Engineer - Java/Python/AWS)', 'Sr Software Engineer I', 'Sr Technical Security Engineer', 'Sr Web Developer', 'Sr Weblogic Adminstrator', 'Sr Wireless Software Engineer', 'Sr. Associate Software Engineer', 'Sr. Associate, Advanced Analytics Modeler, Machine Learning', 'Sr. Big Data Developer /w Data Science for Leading Global Sportswear Co. W2 only, no C2C', 'Sr. Business Analyst', 'Sr. Cloud Network Engineer', 'Sr. Communications & Network Engineer', 'Sr. Construction Project Manager', 'Sr. Cybersecurity Analyst', 'Sr. Data Analyst', 'Sr. Data Analyst (Insurance)', 'Sr. Data Analyst 3', 'Sr. Data Engineer', 'Sr. Data Engineer, EIM', 'Sr. Data Engineer-Analytics', 'Sr. Data Scientist', 'Sr. Data Scientist (PwC Labs)', 'Sr. Data Warehouse Engineer (Program / Analyst)', 'Sr. Database Administrator', 'Sr. Database Engineer', 'Sr. Database Engineer - Oracle', 'Sr. Director/V.P. Clinical Operations', 'Sr. Embedded Software Engineer', 'Sr. Financial Analyst', 'Sr. Front End Software Engineer', 'Sr. Full Stack Software Engineer', 'Sr. Function Software Engineer (Powertrain)', 'Sr. IT Project Manager', 'Sr. Manager - Data Analyst', 'Sr. Network Engineer', 'Sr. Network Engineer (CCNA/CCNP)', 'Sr. Network Engineer (Routing / Switching)', 'Sr. Pricing Data Scientist', 'Sr. Product Manager', 'Sr. Product Manager - tekMountain', 'Sr. Project Data Analyst with SAS/SQL Skills', 'Sr. Project Manager', 'Sr. React JS Developers', 'Sr. Recruiter', 'Sr. Security Engineer', 'Sr. Security QA Engineer', 'Sr. Software Engineer', 'Sr. Software Engineer (AI)', 'Sr. Software Engineer (Qt)', 'Sr. Software Engineer - .Net Azure', 'Sr. Software Engineer - Big Data', 'Sr. Software Engineer - Java', 'Sr. Software Engineer - Node.js', 'Sr. Software Engineer/.NET Web Developer', 'Sr. Software Machine Learning', 'Sr. Systems Engineer', 'Sr. Tableau Developer/ Sr. Data Analyst', 'Sr. UX Designer', 'Sr. Web Developer', 'Staff Accountant', 'Staff Business Data Analysis', 'Staff Cyber Security Engineer (Remote)', 'Staff Data Engineer', 'Staff Data Engineer - Data Science', 'Staff Data Scientist', 'Staff Data Scientist (GEC11903)', 'Staff Data Scientist - Business Analytics', 'Staff Data Scientist - Deep Learning', 'Staff Data Scientist - Inference & Algorithms', 'Staff DevOps Engineer, Enterprise Network', 'Staff Engineer Web Developer Auburn Hills', 'Staff Machine Learning Engineer', 'Staff Software Engineer', 'Staff Software Engineer - Edge', 'Staff Software Engineer - Life Science Instruments', 'Staff Software Engineer - Particle Counting', 'Staff Software Engineer - Projects', 'Staff Systems Engineer, Identity and Access Management', 'Staff | Principal Software Engineer', 'Statistician (Data Scientist)', 'Statistician/Data Scientist', 'Store Director ⟡  New Store Opening', 'Store Manager/District Manager: Non-Retail Hours, $5,000 Sign-On Bonus!', 'Strategic Analytics', 'Strategic Internship Program - Machine Learning', 'Strategic Sourcing Specialist', 'Strategy & Operations Associate', 'Strategy Associate', 'Structural Bridge Engineer', 'Structural Engineering Project Manager', 'Studio Director - Affordable Housing', 'Studio Manager', 'Summer 2020 Data Engineer Intern', 'Summer 2020 Internship Program- Open Application', 'Super Star Shopify Web Developer', 'Supervisor at Hartsfield International Airport', 'Supervisory Program Manager', 'Supply Chain Administrator', 'Supply Chain Analyst', 'Supply Chain Analyst/Buyer', 'Supply Chain Operations Manager', 'Support Broker/Service Advisor/Case Manager', 'Surgical Director- CNOR', 'System Engineer', 'System Engineer - ITWorks', 'System Network Administrator', 'System Security Engineer', 'System/Data Analyst', 'Systems & Network Engineer', 'Systems Analyst', 'Systems Data Analyst', 'Systems Engineer', 'Systems Engineer (Contractor Position)- Juniper Experience a Plus', 'Systems Engineer (Linux and Windows)', 'Systems Engineer (Mid-Level)', 'Systems Engineer (OpCity)', 'Systems Engineer - Entry Level', 'Systems Engineer Clearance', 'Systems Engineer I or II', 'Systems Engineer II', 'Systems Engineer III', 'Systems Engineer Intern (Various Locations)', 'Systems Engineer ll - Full Time - Waconia', 'Systems Engineer lll - Full Time - Waconia', 'Systems Engineer | UCS, VMware, Horizon View VDI, Nimble and ADS', 'Systems Engineer – Help Desk (Contractor Position)', 'Systems Engineer – Level II', 'Systems Engineer(s)', 'Systems Engineer- DoD', 'Systems SQL Engineer', 'Systems Security Engineer (ISSE)', 'Systems Software Engineer at Vertica', 'Systems/Network Engineer', 'Systems/Software Engineer', 'TEST DO NOT APPLY', 'TITLE DATA SCIENTIST', 'TPM, Machine Learning & Data Science', 'TS/SCI Security Escort', 'Tableau Developer', 'Tableau Engineer', 'Talend Data Engineer', 'Talent Acquisition Coordinator', 'Talent Acquisition Specialist', 'Team Assistant', 'Tech & Security Career Fair January 28th!', 'Tech Lead - Data Engineer', 'Technical Data Architect', 'Technical Lead', 'Technical Product Owner - Empower & Laboratory Systems', 'Technical Project Manager', 'Technical Recruiter', 'Technology Expert (Principal Azure Data Engineer)', 'Technology Security Auditor', 'Telecom Expert', 'Temporary PHP Web Developer at UNC-Chapel Hill', 'Temporary WordPress Web Developer at UNC Chapel Hill', 'Territory Manager', 'Test Data Architect', 'Test Engineer - Machine Learning', 'Text Mining, Database Data Scientist', 'Threat Hunter', 'Threat Hunter (Remote)', 'Title IV Project manager', 'Tower Technician', 'Traffic Data Analyst', 'Translation Data Scientist, Director', 'Transportation Data Scientist', 'Transportation Planning Specialist', 'Transportation Security Manager', 'Transportation Security Specialist', 'Traveling Outdoor Construction Laborer - $19/hr. Hablo Español', 'Truck Brokerage Sales Agent', 'UI Engineer', 'UI Web Developer', 'UI/ Front-End Developer', 'UI/Front End Developer (ReactJs/Redux)', 'UI/UX Product Owner/BA (Banking/Financial Services)', 'UR - Optimized Operations (O2) Data Scientist / Statistician', 'UTS Temporary Web Developer', 'UTS Temporary WordPress Web Developer', 'UX / Web Developer', 'UX Content Strategist/ Payment', 'UiPath Developer', 'Unarmed Security Guard', 'Unarmed Security Officer', 'University Grad - Software Engineer', 'User Experience Designer', 'VP - Surveillance Data Scientist, Surveillance Design & Implementation', 'VP Engineering, Apptio Cloudability and Hybrid Products', 'VP Python Developer / Data Scientist Lead', 'VP of Commercial Real Estate Acquisitions', 'VP, Product Development Chef', 'Vice President Marketing/CMO', 'Vice President, Mobile Product Manager', 'Vice President, Security', 'Visitor Experience Associate', 'Visual Designer', 'Vulnerabilty (Nessus) Engineer', 'WEB DEVELOPER', 'WEB Developer-BBB-Req ID: 638-1', 'WPF .NET Software Engineer', 'Warehouse Coworking Manager', 'Wealth Management Advisor', 'Weather Data Engineer/Scientist', 'Web Application Developer', 'Web Application Programmer', 'Web Designer', 'Web Designer/Developer', 'Web Developer', 'Web Developer ( Contractor )', 'Web Developer (+Angular)', 'Web Developer (Full-Time, Permanent role!)', 'Web Developer (JavaScript)', 'Web Developer (Multiple openings)', 'Web Developer (some remote)', 'Web Developer - .Net', 'Web Developer - Back End', 'Web Developer - Back-end Focus', 'Web Developer - Benson Tower', 'Web Developer - CMS, Web/ Mobile', 'Web Developer - Chief Marketing Officer', 'Web Developer - Entry/Junior Level', 'Web Developer - Front End', 'Web Developer - Intermediate Level', 'Web Developer - Schriever AFB', 'Web Developer / Computer Scientist', 'Web Developer / Java', 'Web Developer / Web Design WordPress', 'Web Developer / Wordpress', 'Web Developer 2', 'Web Developer 4 - Cyber Security Innovation', 'Web Developer 5', 'Web Developer 5 - Digital Payment Micro-services', 'Web Developer 5 / Java Developer', 'Web Developer 6 / Java Web Developer', 'Web Developer 6 Lead Developer', 'Web Developer Engineer', 'Web Developer Full Stack Engineer', 'Web Developer I', 'Web Developer II', 'Web Developer III', 'Web Developer Intern - Spring', 'Web Developer Internship', 'Web Developer Journeyman', 'Web Developer Non Telecommuting', 'Web Developer SOM', 'Web Developer Senior', 'Web Developer SharePoint', 'Web Developer Tools Engineer', 'Web Developer and Designer', 'Web Developer for Digital Scholarship and Digital Collections', 'Web Developer in Marketing Technologies', 'Web Developer w/Secret Clearance', 'Web Developer – Full Stack', 'Web Developer – PHP', 'Web Developer – PHP, MySQL and LAMP', 'Web Developer, eCommerce', 'Web Developer- Full Stack', 'Web Developer/Administrator - Junior Level (1590)', 'Web Developer/Designer', 'Web Developer/Designer Internship', 'Web Developer/Engineer', 'Web Developer/Tester', 'Web Developer; Business Process Services', 'Web Engineer', 'Web Full Stack Developer', 'Web Full Stack Developer - Healthcare IT', 'Web Software Developer', 'Web UI & UX Developer', 'Web/WordPress Developer', 'Website Designer & Developer', 'Website Research and Data Analyst (E-Commerce)', 'Windows Systems Engineer', 'Wordpress Expert/Web Developer', 'Work Force Management Forecast Analyst', 'Youth Development Specialist', 'data scientist, Global Supply Chain, Advanced Analytics - Seattle, WA', 'eCommerce Data Analyst/Content Specialist', 'eCommerce Data Engineer', 'iOS Software Engineer', 'junior Data Engineer ( OPT EAD and CPT )', 'nan', 'title', 'undergraduate or graduate intern, App Developer/Data Scientist – DSETMITIOTI, Summer 2020 - Seattle, WA']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[ 524  363  524 ...  565 1436  524]\n",
      "\n",
      "\n",
      "One hot labels; 7 binary columns, one for each of the categories.\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(18453, 2404)\n"
     ]
    }
   ],
   "source": [
    "title = hope2['title'].astype(str)\n",
    "\n",
    "le = preprocessing.LabelEncoder() #Initialize. le used as abbreviation fo label encoder\n",
    "le.fit(title)\n",
    "print(\"Original class labels:\")\n",
    "print(list(le.classes_))\n",
    "print('\\n')\n",
    "title_cat = le.transform(title)  \n",
    "originals = list(le.inverse_transform([0, 1, 3, 3, 0, 6, 4])) #If you wish to retrieve the original descriptive labels post production\n",
    "\n",
    "print('New product labels:')\n",
    "print(title_cat)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('One hot labels; 7 binary columns, one for each of the categories.') #Each row will be all zeros except for the category for that observation.\n",
    "title_onehot = to_categorical(title_cat)\n",
    "print(title_onehot)\n",
    "print('\\n')\n",
    "\n",
    "print('One hot labels shape:')\n",
    "print(np.shape(title_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.519659Z",
     "start_time": "2020-01-02T04:18:09.517499Z"
    }
   },
   "outputs": [],
   "source": [
    "train_targets = title_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.524992Z",
     "start_time": "2020-01-02T04:18:09.521295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18453, 115)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train_targets = to_categorical(train_targets, num_classes=vocabulary_size+1)\n",
    "seq_len = train_inputs.shape[1]\n",
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.528612Z",
     "start_time": "2020-01-02T04:18:09.526459Z"
    }
   },
   "outputs": [],
   "source": [
    "# The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "# It is a flexible layer that can be used in a variety of ways, such as:\n",
    "# It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
    "# It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "# It can be used to load a pre-trained word embedding model, a type of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.532673Z",
     "start_time": "2020-01-02T04:18:09.530032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.537091Z",
     "start_time": "2020-01-02T04:18:09.534385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:18:09.542351Z",
     "start_time": "2020-01-02T04:18:09.538761Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dense(2404,activation='softmax'))\n",
    "    opt_adam = optimizers.adam(lr=0.01)\n",
    "    #You can simply pass 'adam' to optimizer in compile method. Default learning rate 0.001\n",
    "    #But here we are using adam optimzer from optimizer class to change the LR.\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt_adam,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:23:16.913666Z",
     "start_time": "2020-01-02T04:18:09.544585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 115, 115)          13225     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 115, 50)           33200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2404)              122604    \n",
      "=================================================================\n",
      "Total params: 191,779\n",
      "Trainable params: 191,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18453/18453 [==============================] - 31s 2ms/step - loss: 6.0889 - acc: 0.1101\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.08891, saving model to checkpoint11\n",
      "Epoch 2/10\n",
      "18453/18453 [==============================] - 30s 2ms/step - loss: 5.8443 - acc: 0.1127\n",
      "\n",
      "Epoch 00002: loss improved from 6.08891 to 5.84434, saving model to checkpoint11\n",
      "Epoch 3/10\n",
      "18453/18453 [==============================] - 30s 2ms/step - loss: 5.8279 - acc: 0.1127\n",
      "\n",
      "Epoch 00003: loss improved from 5.84434 to 5.82786, saving model to checkpoint11\n",
      "Epoch 4/10\n",
      "18453/18453 [==============================] - 31s 2ms/step - loss: 5.8216 - acc: 0.1127\n",
      "\n",
      "Epoch 00004: loss improved from 5.82786 to 5.82158, saving model to checkpoint11\n",
      "Epoch 5/10\n",
      "18453/18453 [==============================] - 31s 2ms/step - loss: 5.8156 - acc: 0.1127\n",
      "\n",
      "Epoch 00005: loss improved from 5.82158 to 5.81555, saving model to checkpoint11\n",
      "Epoch 6/10\n",
      "18453/18453 [==============================] - 30s 2ms/step - loss: 5.8148 - acc: 0.1127\n",
      "\n",
      "Epoch 00006: loss improved from 5.81555 to 5.81478, saving model to checkpoint11\n",
      "Epoch 7/10\n",
      "18453/18453 [==============================] - 30s 2ms/step - loss: 5.8085 - acc: 0.1127\n",
      "\n",
      "Epoch 00007: loss improved from 5.81478 to 5.80851, saving model to checkpoint11\n",
      "Epoch 8/10\n",
      "18453/18453 [==============================] - 31s 2ms/step - loss: 5.8093 - acc: 0.1127\n",
      "\n",
      "Epoch 00008: loss did not improve from 5.80851\n",
      "Epoch 9/10\n",
      "18453/18453 [==============================] - 31s 2ms/step - loss: 5.8042 - acc: 0.1127\n",
      "\n",
      "Epoch 00009: loss improved from 5.80851 to 5.80422, saving model to checkpoint11\n",
      "Epoch 10/10\n",
      "18453/18453 [==============================] - 30s 2ms/step - loss: 5.8038 - acc: 0.1127\n",
      "\n",
      "Epoch 00010: loss improved from 5.80422 to 5.80381, saving model to checkpoint11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141bf0748>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,115)\n",
    "path = 'checkpoint11'\n",
    "checkpoint = ModelCheckpoint(path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(train_inputs,train_targets,batch_size=128,epochs=10,verbose=1,callbacks=[checkpoint])\n",
    "# pickle.dump(tokenizer,open('tokenizer_Model4','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.807257Z",
     "start_time": "2020-01-02T04:23:16.915498Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===>Enter --exit to exit from the program\n",
      "Enter string: data scientist\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_1_input to have shape (115,) but got array with shape (42,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6f4f31f05d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gen_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print('Output: '+seed_text+' '+out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-6f4f31f05d00>\u001b[0m in \u001b[0;36mgen_text\u001b[0;34m(model, tokenizer, seq_len, seed_text, num_gen_words)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpad_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred_word_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpred_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_word_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have shape (115,) but got array with shape (42,)"
     ]
    }
   ],
   "source": [
    "model = load_model('checkpoint11')\n",
    "# tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "seq_len = 42 \n",
    "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' '+pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)\n",
    "\n",
    "print('\\n\\n===>Enter --exit to exit from the program')\n",
    "while True:\n",
    "    seed_text  = input('Enter string: ')\n",
    "    if seed_text.lower() == '--exit':\n",
    "        break\n",
    "    else:\n",
    "        out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=1000)\n",
    "#         print('Output: '+seed_text+' '+out)\n",
    "        out_list = out.split()\n",
    "        out_total = Counter(out_list)\n",
    "        total = sum(out_total.values())\n",
    "        out_length = len(out_total)\n",
    "        out_dict = [(i, out_total[i] / total * 100.0) for i in out_total]\n",
    "        out_result = pd.DataFrame(out_dict, columns=['Tech','Percentage'])\n",
    "        out_result_chart = out_result.sort_values('Percentage', ascending=False).head(10)\n",
    "        output_chart = out_result_chart.set_index('Tech', drop=True)\n",
    "        print(output_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.809564Z",
     "start_time": "2020-01-02T04:17:42.867Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.811121Z",
     "start_time": "2020-01-02T04:17:42.869Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = load_model('checkpoint4')\n",
    "# # tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "# seq_len = 3 \n",
    "# def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "#     output_text = []\n",
    "#     input_text = seed_text\n",
    "#     for i in range(num_gen_words):\n",
    "#         encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "#         pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "#         pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "#         pred_word = tokenizer.index_word[pred_word_ind]\n",
    "#         targets = str()\n",
    "#         for word in pred_word:\n",
    "#             if word in search_terms:\n",
    "#                 targets+word\n",
    "                \n",
    "#         input_text += ' '+targets\n",
    "#         output_text.append(targets)\n",
    "#     return ' '.join(output_text)\n",
    "\n",
    "# print('\\n\\n===>Enter --exit to exit from the program')\n",
    "# while True:\n",
    "#     seed_text  = input('Enter string: ')\n",
    "#     if seed_text.lower() == '--exit':\n",
    "#         break\n",
    "#     else:\n",
    "#         out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=5)\n",
    "#         print('Output: '+seed_text+' '+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.812248Z",
     "start_time": "2020-01-02T04:17:42.870Z"
    }
   },
   "outputs": [],
   "source": [
    "# target = df.title\n",
    "# data = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.813320Z",
     "start_time": "2020-01-02T04:17:42.872Z"
    }
   },
   "outputs": [],
   "source": [
    "# total_target = set(target)\n",
    "# target_classes = len(total_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.814362Z",
     "start_time": "2020-01-02T04:17:42.873Z"
    }
   },
   "outputs": [],
   "source": [
    "# total_vocabulary = set(word for description in data for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.815407Z",
     "start_time": "2020-01-02T04:17:42.875Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(total_vocabulary)\n",
    "# print(\"There are {} unique tokens in the dataset.\".format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.816483Z",
     "start_time": "2020-01-02T04:17:42.877Z"
    }
   },
   "outputs": [],
   "source": [
    "# glove = {}\n",
    "# with open('glove.6B.50d.txt', 'rb') as f:\n",
    "#     for line in f:\n",
    "#         parts = line.split()\n",
    "#         word = parts[0].decode('utf-8')\n",
    "#         if word in total_vocabulary:\n",
    "#             vector = np.array(parts[1:], dtype=np.float32)\n",
    "#             glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.817397Z",
     "start_time": "2020-01-02T04:17:42.878Z"
    }
   },
   "outputs": [],
   "source": [
    "# glove['java']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T04:27:43.818501Z",
     "start_time": "2020-01-02T04:17:42.880Z"
    }
   },
   "outputs": [],
   "source": [
    "# class W2vVectorizer(object):\n",
    "    \n",
    "#     def __init__(self, w2v):\n",
    "#         # takes in a dictionary of words and vectors as input\n",
    "#         self.w2v = w2v\n",
    "#         if len(w2v) == 0:\n",
    "#             self.dimensions = 0\n",
    "#         else:\n",
    "#             self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "#     # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "#     # It can't be used in a sklearn Pipeline. \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "            \n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "#                    or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
