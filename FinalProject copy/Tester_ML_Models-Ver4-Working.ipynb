{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.351906Z",
     "start_time": "2019-12-30T17:34:46.603500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "import WebScrape_Indeed\n",
    "import WebScrape_LinkedIn\n",
    "import streamlit as st \n",
    "import terms \n",
    "import Cities \n",
    "import functions\n",
    "import time\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig\n",
    "\n",
    "import chart_studio.plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "import pydeck as pdk\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)   \n",
    "\n",
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.357540Z",
     "start_time": "2019-12-30T17:34:48.354875Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.363411Z",
     "start_time": "2019-12-30T17:34:48.359309Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.375163Z",
     "start_time": "2019-12-30T17:34:48.364832Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.382214Z",
     "start_time": "2019-12-30T17:34:48.378184Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import (make_blobs,\n",
    "                                                make_circles,\n",
    "                                                make_moons)\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "plt.style.use('fivethirtyeight')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:48.933416Z",
     "start_time": "2019-12-30T17:34:48.927833Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:49.883331Z",
     "start_time": "2019-12-30T17:34:49.699404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:51.560859Z",
     "start_time": "2019-12-30T17:34:50.166961Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:51.567257Z",
     "start_time": "2019-12-30T17:34:51.563036Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(raw):\n",
    "    raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    raw = nltk.regexp_tokenize(raw, pattern)\n",
    "    raw = str(raw)\n",
    "    return raw\n",
    "\n",
    "def cleanC(raw):\n",
    "    raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    return raw\n",
    "\n",
    "def C_plus(raw):\n",
    "    Cplus = re.findall(r'(?i)\\bC\\+\\+(?!\\w)', str(raw))\n",
    "    return Cplus\n",
    "\n",
    "def C_sharp(raw):\n",
    "    Csharp = re.findall(r'(?i)\\bC\\#(?!\\w)', str(raw))\n",
    "    return Csharp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:52.981051Z",
     "start_time": "2019-12-30T17:34:52.734371Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco, CA 94105</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kohl's</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Palo Alto, CA 94304</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title              company  \\\n",
       "0                   Data Scientist             Esurance   \n",
       "1                   DATA SCIENTIST              Walmart   \n",
       "2                   Data Scientist               Kohl's   \n",
       "3  Staff Data Scientist (GEC11903)    Walmart eCommerce   \n",
       "4               Sr. Data Scientist  Silicon Valley Bank   \n",
       "\n",
       "                  location                                        description  \\\n",
       "0  San Francisco, CA 94105  [     Summary       Esurance is looking for a ...   \n",
       "1      Sunnyvale, CA 94087  [     Position Description    Data Scientist i...   \n",
       "2       Milpitas, CA 95035  [  Interpret and apply data analyses and expla...   \n",
       "3      Sunnyvale, CA 94087  [     Position Description      Understands an...   \n",
       "4      Palo Alto, CA 94304  [       Silicon Valley Bank is the market lead...   \n",
       "\n",
       "         date  \n",
       "0  12-01-2019  \n",
       "1  12-01-2019  \n",
       "2  12-01-2019  \n",
       "3  12-01-2019  \n",
       "4  12-01-2019  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('total_data_date.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:56.424659Z",
     "start_time": "2019-12-30T17:34:56.421517Z"
    }
   },
   "outputs": [],
   "source": [
    "search_terms = terms.total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:57.928314Z",
     "start_time": "2019-12-30T17:34:57.925173Z"
    }
   },
   "outputs": [],
   "source": [
    "search_terms = [term.lower() for term in search_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:58.503542Z",
     "start_time": "2019-12-30T17:34:58.495351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ajax',\n",
       " 'asp',\n",
       " 'asp.net',\n",
       " 'aws',\n",
       " 'acrobat',\n",
       " 'airflow',\n",
       " 'alteryx',\n",
       " 'android',\n",
       " 'angular',\n",
       " 'ansible',\n",
       " 'apache',\n",
       " 'arduino',\n",
       " 'atom',\n",
       " 'azure',\n",
       " 'bsd',\n",
       " 'bash',\n",
       " 'bigquery',\n",
       " 'c#',\n",
       " 'c++',\n",
       " 'css',\n",
       " 'caffe',\n",
       " 'cassandra',\n",
       " 'chef',\n",
       " 'couchbase',\n",
       " 'cryengine',\n",
       " 'd3',\n",
       " 'databricks',\n",
       " 'django',\n",
       " 'docker',\n",
       " 'drupal',\n",
       " 'dynamodb',\n",
       " 'elixir',\n",
       " 'excel',\n",
       " 'fastai',\n",
       " 'firebase',\n",
       " 'flask',\n",
       " 'gcp',\n",
       " 'git',\n",
       " 'google cloud',\n",
       " 'html',\n",
       " 'hadoop',\n",
       " 'hbase',\n",
       " 'hive',\n",
       " 'ibm',\n",
       " 'ipython',\n",
       " 'illustrator',\n",
       " 'indesign',\n",
       " 'intellij',\n",
       " 'java',\n",
       " 'javascript',\n",
       " 'julia',\n",
       " 'jupyter',\n",
       " 'keras',\n",
       " 'komodo',\n",
       " 'kubernetes',\n",
       " 'laravel',\n",
       " 'linux',\n",
       " 'macos',\n",
       " 'mariadb',\n",
       " 'matlab',\n",
       " 'microsoft',\n",
       " 'mongodb',\n",
       " 'mysql',\n",
       " 'net',\n",
       " 'nlp',\n",
       " 'netbeans',\n",
       " 'netsuite',\n",
       " 'nosql',\n",
       " 'node',\n",
       " 'notepad',\n",
       " 'numpy',\n",
       " 'objective c',\n",
       " 'oracle',\n",
       " 'php',\n",
       " 'phpstorm',\n",
       " 'pmp',\n",
       " 'pandas',\n",
       " 'perl',\n",
       " 'photoshop',\n",
       " 'pi',\n",
       " 'pig',\n",
       " 'postgresql',\n",
       " 'powerpoint',\n",
       " 'powershell',\n",
       " 'project management',\n",
       " 'puppet',\n",
       " 'pycharm',\n",
       " 'pytorch',\n",
       " 'python',\n",
       " 'r',\n",
       " 'rails',\n",
       " 'raspberry',\n",
       " 'react',\n",
       " 'ruby',\n",
       " 'rubymine',\n",
       " 'sap',\n",
       " 'sas',\n",
       " 'spss',\n",
       " 'sql',\n",
       " 'sqlite',\n",
       " 'salesforce',\n",
       " 'scala',\n",
       " 'scikit-learn',\n",
       " 'scrum',\n",
       " 'shell',\n",
       " 'spark',\n",
       " 'spring',\n",
       " 'sublime',\n",
       " 'swift',\n",
       " 'tableau',\n",
       " 'tensorflow',\n",
       " 'textmate',\n",
       " 'torch',\n",
       " 'unity',\n",
       " 'unreal engine',\n",
       " 'visual studio',\n",
       " 'vue',\n",
       " 'watson',\n",
       " 'webassembly',\n",
       " 'windows',\n",
       " 'wordpress',\n",
       " 'xgboost',\n",
       " 'xml',\n",
       " 'xamarin',\n",
       " 'xcode',\n",
       " 'zend',\n",
       " 'ios',\n",
       " 'jquery',\n",
       " 'mapreduce',\n",
       " 'postgresql',\n",
       " 'sklearn']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:34:59.354941Z",
     "start_time": "2019-12-30T17:34:59.352462Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = df['description'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:35:00.515659Z",
     "start_time": "2019-12-30T17:35:00.513163Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:35:01.309000Z",
     "start_time": "2019-12-30T17:35:01.305426Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.746774Z",
     "start_time": "2019-12-29T14:24:21.096666Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines have been processed\n"
     ]
    }
   ],
   "source": [
    "unique_data = []\n",
    "for i in range(len(data)):\n",
    "    if data['description'][i] not in unique_data:\n",
    "        unique_data.append(data['description'][i])\n",
    "        if i % 5000 == 0:\n",
    "            print('{0}'.format(i)+' lines have been processed')\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() #convert all the chracters into small letters\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ve\", \"have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \"will\", text)\n",
    "    text = re.sub(r\"\\'re\", \"are\", text)\n",
    "    text = re.sub(r\"\\'d\", \"would\", text)\n",
    "    text = re.sub(r\"n't\", \"not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}'+=|.!?,]\", \"\", text)\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    return text\n",
    "\n",
    "unique_data_str = []\n",
    "for i in range(len(unique_data)):\n",
    "    if type(unique_data[i]) is str:\n",
    "        unique_data_str.append(unique_data[i])\n",
    "    else:\n",
    "        None\n",
    "\n",
    "# Cleaning the data\n",
    "clean_data = []\n",
    "for text in unique_data_str:\n",
    "    a = re.sub(r'[^a-zA-z ]+', '', text).strip()\n",
    "    if len(a)>0:\n",
    "        clean_data.append(clean_text(a))\n",
    "    else:\n",
    "        None\n",
    "\n",
    "# Removing the lines which are to short or to long\n",
    "short_data = []\n",
    "for line in clean_data:\n",
    "    if 2 <= len(line.split()):\n",
    "        short_data.append(line)\n",
    "    else:\n",
    "        None\n",
    "\n",
    "# Counting the appearnce of each word in the corpus also calculates the number of unique words also\n",
    "word2count = {}\n",
    "total_words = 0\n",
    "for text in clean_data:\n",
    "    for word in text.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "        total_words += 1\n",
    "        \n",
    "# creating a list that will only contain the words that appear more than 15 times\n",
    "word10 = []\n",
    "threshold = 10\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        if len(word) > 1:\n",
    "            word10.append(word)\n",
    "            \n",
    "# Removing the words from each string which appear less than 15 times\n",
    "data10 = []\n",
    "for line in short_data:\n",
    "    str1=''\n",
    "    for word in line.split():\n",
    "        if word in word10:\n",
    "            str1 = \" \".join((str1, word))\n",
    "    data10.append(str1)\n",
    "\n",
    "# Removing the lines which are to short or to long after removing the unnecssary words.     \n",
    "short_data_consize = []\n",
    "for line in data10:\n",
    "    if 3 <= len(line.split()):\n",
    "        short_data_consize.append(line)\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "clean_unique_data = []\n",
    "for i in range(len(short_data_consize)):\n",
    "    if short_data_consize[i] not in clean_unique_data:\n",
    "        clean_unique_data.append(short_data_consize[i])\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "# # Total number of words in corpus after removing the words which appears less than 15 times and further cleaning\n",
    "total_words_d10 = 0\n",
    "for line in data10:\n",
    "    for word in line.split():\n",
    "        total_words_d10 += 1 \n",
    "# # \"\"\" Initially we had 437579 lines in our data after cleaning and preprocessing the data\n",
    "#     now our complete data will have 126003 lines, that means we removed 71.20% data which was useless\"\"\"   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.752830Z",
     "start_time": "2019-12-29T14:24:46.748919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.757946Z",
     "start_time": "2019-12-29T14:24:46.754356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17424"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.764536Z",
     "start_time": "2019-12-29T14:24:46.760291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.770517Z",
     "start_time": "2019-12-29T14:24:46.767182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1813489"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words_d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:46.774638Z",
     "start_time": "2019-12-29T14:24:46.772476Z"
    }
   },
   "outputs": [],
   "source": [
    "data = clean_unique_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:54.944824Z",
     "start_time": "2019-12-29T14:24:54.941425Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Splitting the cleaned and preprocessd data into 4 equal parts      \n",
    "# clean_unique_data_qtr1 = clean_unique_data[0:int(len(clean_unique_data)*0.25)]      \n",
    "# clean_unique_data_qtr2 = clean_unique_data[int(len(clean_unique_data)*0.25):int(len(clean_unique_data)*0.5)]  \n",
    "# clean_unique_data_qtr3 = clean_unique_data[int(len(clean_unique_data)*0.5):int(len(clean_unique_data)*0.75)]  \n",
    "# clean_unique_data_qtr4 = clean_unique_data[int(len(clean_unique_data)*0.75):len(clean_unique_data)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:58.244624Z",
     "start_time": "2019-12-29T14:24:55.349619Z"
    }
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') + list(string.punctuation)\n",
    "stop += [\"''\", '\"\"', '...', '``','--','and','a','an','of']\n",
    "\n",
    "new_data = []\n",
    "for word in str(data).split():\n",
    "    if word not in stop:\n",
    "        new_data.append(word)\n",
    "        \n",
    "# data = data.map(word_tokenize).values\n",
    "# tokens = str(data).split()\n",
    "# stopwords_removed = [token for token in tokens if token not in stop]\n",
    "# stopwords_removed = [x for x in data if x not in stop]\n",
    "# data = data.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:24:59.474623Z",
     "start_time": "2019-12-29T14:24:59.470632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215721"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:11.198571Z",
     "start_time": "2019-12-29T14:25:11.184774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['\",\n",
       " 'summary',\n",
       " 'looking',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'join',\n",
       " 'dynamic',\n",
       " 'awardwinning',\n",
       " 'team',\n",
       " 'individuals',\n",
       " 'committed',\n",
       " 'making',\n",
       " 'insurance',\n",
       " 'smarter',\n",
       " 'easier',\n",
       " 'say',\n",
       " 'part',\n",
       " 'growing',\n",
       " 'company',\n",
       " 'focused',\n",
       " 'providing',\n",
       " 'outstanding',\n",
       " 'customer',\n",
       " 'experience',\n",
       " 'youll',\n",
       " 'opportunity',\n",
       " 'expand',\n",
       " 'skills',\n",
       " 'discover',\n",
       " 'potential',\n",
       " 'youre',\n",
       " 'looking',\n",
       " 'career',\n",
       " 'conscious',\n",
       " 'company',\n",
       " 'offers',\n",
       " 'great',\n",
       " 'benefits',\n",
       " 'including',\n",
       " 'matching',\n",
       " 'tuition',\n",
       " 'reimbursement',\n",
       " 'may',\n",
       " 'found',\n",
       " 'new',\n",
       " 'home',\n",
       " 'combines',\n",
       " 'startup',\n",
       " 'company',\n",
       " 'backing',\n",
       " 'allstate',\n",
       " 'largest',\n",
       " 'publicly',\n",
       " 'held',\n",
       " 'personal',\n",
       " 'lines',\n",
       " 'us',\n",
       " 'create',\n",
       " 'unique',\n",
       " 'energized',\n",
       " 'exciting',\n",
       " 'place',\n",
       " 'work',\n",
       " 'responsibilities',\n",
       " 'created',\n",
       " 'centralized',\n",
       " 'data',\n",
       " 'science',\n",
       " 'group',\n",
       " 'responsible',\n",
       " 'helping',\n",
       " 'business',\n",
       " 'units',\n",
       " 'make',\n",
       " 'objective',\n",
       " 'decisions',\n",
       " 'using',\n",
       " 'science',\n",
       " 'group',\n",
       " 'supports',\n",
       " 'overall',\n",
       " 'business',\n",
       " 'operations',\n",
       " 'delivering',\n",
       " 'critical',\n",
       " 'analytical',\n",
       " 'insights',\n",
       " 'indepth',\n",
       " 'consultative',\n",
       " 'analyses',\n",
       " 'group',\n",
       " 'also',\n",
       " 'develops',\n",
       " 'applications',\n",
       " 'platforms',\n",
       " 'used',\n",
       " 'deploy',\n",
       " 'analytics',\n",
       " 'real',\n",
       " 'time',\n",
       " 'job',\n",
       " 'responsibilities',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'group',\n",
       " 'develop',\n",
       " 'tangible',\n",
       " 'actionable',\n",
       " 'recommendations',\n",
       " 'implemented',\n",
       " 'realtime',\n",
       " 'improve',\n",
       " 'business',\n",
       " 'operations',\n",
       " 'key',\n",
       " 'responsibilities',\n",
       " 'include',\n",
       " 'working',\n",
       " 'business',\n",
       " 'stakeholders',\n",
       " 'deeply',\n",
       " 'understand',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'pain',\n",
       " 'points',\n",
       " 'developing',\n",
       " 'algorithms',\n",
       " 'predictive',\n",
       " 'models',\n",
       " 'using',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " 'collaborating',\n",
       " 'internal',\n",
       " 'technology',\n",
       " 'team',\n",
       " 'deploy',\n",
       " 'solutions',\n",
       " 'realtime',\n",
       " 'decisions',\n",
       " 'designing',\n",
       " 'experiments',\n",
       " 'determine',\n",
       " 'efficacy',\n",
       " 'solutions',\n",
       " 'providing',\n",
       " 'ongoing',\n",
       " 'performance',\n",
       " 'monitoring',\n",
       " 'decision',\n",
       " 'systems',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'qualifications',\n",
       " 'excellent',\n",
       " 'knowledge',\n",
       " 'highlevel',\n",
       " 'language',\n",
       " 'statistical',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " 'python',\n",
       " 'similar',\n",
       " 'extensive',\n",
       " 'experience',\n",
       " 'data',\n",
       " 'management',\n",
       " 'data',\n",
       " 'strong',\n",
       " 'aptitude',\n",
       " 'towards',\n",
       " 'math',\n",
       " 'programming',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'complex',\n",
       " 'information',\n",
       " 'way',\n",
       " 'clear',\n",
       " 'easily',\n",
       " 'understood',\n",
       " 'experience',\n",
       " 'education',\n",
       " 'bachelor',\n",
       " 'degree',\n",
       " 'statistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'related',\n",
       " 'field',\n",
       " 'equivalent',\n",
       " 'educationexperience',\n",
       " 'required',\n",
       " 'phd',\n",
       " 'master',\n",
       " 'degree',\n",
       " 'preferred',\n",
       " 'years',\n",
       " 'relevant',\n",
       " 'quantitative',\n",
       " 'qualitative',\n",
       " 'research',\n",
       " 'analytics',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'deploying',\n",
       " 'machinelearning',\n",
       " 'techniques',\n",
       " 'dimensionality',\n",
       " 'reduction',\n",
       " 'regression',\n",
       " 'clustering',\n",
       " 'classification',\n",
       " 'solve',\n",
       " 'realworld',\n",
       " 'problems',\n",
       " 'physical',\n",
       " 'demands',\n",
       " 'work',\n",
       " 'environment',\n",
       " 'representative',\n",
       " 'must',\n",
       " 'met',\n",
       " 'employee',\n",
       " 'successfully',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'functions',\n",
       " 'job',\n",
       " 'must',\n",
       " 'able',\n",
       " 'operate',\n",
       " 'pc',\n",
       " 'sit',\n",
       " 'extended',\n",
       " 'periods',\n",
       " 'time',\n",
       " 'reasonable',\n",
       " 'accommodations',\n",
       " 'may',\n",
       " 'made',\n",
       " 'enable',\n",
       " 'individuals',\n",
       " 'disabilities',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'functions',\n",
       " 'youll',\n",
       " 'love',\n",
       " 'working',\n",
       " 'us',\n",
       " 'offers',\n",
       " 'exciting',\n",
       " 'total',\n",
       " 'rewards',\n",
       " 'package',\n",
       " 'include',\n",
       " 'bonus',\n",
       " 'potential',\n",
       " 'positions',\n",
       " 'benefits',\n",
       " 'eligibility',\n",
       " 'day',\n",
       " 'company',\n",
       " 'matching',\n",
       " 'tuition',\n",
       " 'reimbursement',\n",
       " 'amp',\n",
       " 'student',\n",
       " 'loan',\n",
       " 'program',\n",
       " 'pet',\n",
       " 'insurance',\n",
       " 'discount',\n",
       " 'give',\n",
       " 'time',\n",
       " 'get',\n",
       " 'time',\n",
       " 'volunteer',\n",
       " 'program',\n",
       " 'much',\n",
       " 'perform',\n",
       " 'job',\n",
       " 'successfully',\n",
       " 'individual',\n",
       " 'must',\n",
       " 'able',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'job',\n",
       " 'duty',\n",
       " 'satisfactorily',\n",
       " 'reasonable',\n",
       " 'accommodations',\n",
       " 'may',\n",
       " 'made',\n",
       " 'enable',\n",
       " 'qualified',\n",
       " 'individuals',\n",
       " 'disabilities',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'job',\n",
       " \"functions',\",\n",
       " 'position',\n",
       " 'description',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'responsible',\n",
       " 'analyzing',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'models',\n",
       " 'algorithms',\n",
       " 'drive',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'work',\n",
       " 'project',\n",
       " 'teams',\n",
       " 'order',\n",
       " 'provide',\n",
       " 'analytical',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'building',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'order',\n",
       " 'build',\n",
       " 'algorithms',\n",
       " 'predicting',\n",
       " 'future',\n",
       " 'data',\n",
       " 'characteristics',\n",
       " 'algorithms',\n",
       " 'tested',\n",
       " 'validated',\n",
       " 'applied',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'training',\n",
       " 'algorithms',\n",
       " 'applied',\n",
       " 'future',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'provide',\n",
       " 'appropriate',\n",
       " 'search',\n",
       " 'results',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'researching',\n",
       " 'new',\n",
       " 'trends',\n",
       " 'industry',\n",
       " 'utilizing',\n",
       " 'uptodate',\n",
       " 'technology',\n",
       " 'minimum',\n",
       " 'qualifications',\n",
       " 'key',\n",
       " 'responsibilities',\n",
       " 'understands',\n",
       " 'translates',\n",
       " 'business',\n",
       " 'functional',\n",
       " 'needs',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'problem',\n",
       " 'statements',\n",
       " 'build',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'internally',\n",
       " 'externally',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'data',\n",
       " 'models',\n",
       " 'drive',\n",
       " 'innovative',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'write',\n",
       " 'complex',\n",
       " 'queries',\n",
       " 'extract',\n",
       " 'data',\n",
       " 'build',\n",
       " 'database',\n",
       " 'architecture',\n",
       " 'integrate',\n",
       " 'data',\n",
       " 'products',\n",
       " 'dashboards',\n",
       " 'user',\n",
       " 'interfaces',\n",
       " 'needed',\n",
       " 'collaborating',\n",
       " 'engineering',\n",
       " 'team',\n",
       " 'sift',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'multiple',\n",
       " 'angles',\n",
       " 'looking',\n",
       " 'trends',\n",
       " 'highlight',\n",
       " 'problems',\n",
       " 'opportunities',\n",
       " 'use',\n",
       " 'strong',\n",
       " 'business',\n",
       " 'acumen',\n",
       " 'well',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'findings',\n",
       " 'mine',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'useful',\n",
       " 'insights',\n",
       " 'apply',\n",
       " 'innovative',\n",
       " 'analytical',\n",
       " 'approaches',\n",
       " 'draw',\n",
       " 'conclusions',\n",
       " 'make',\n",
       " 'recommendations',\n",
       " 'answer',\n",
       " 'business',\n",
       " 'objectives',\n",
       " 'skills',\n",
       " 'proficiency',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'classifications',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machines',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'strong',\n",
       " 'understanding',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'generative',\n",
       " 'descriptive',\n",
       " 'models',\n",
       " 'ability',\n",
       " 'run',\n",
       " 'experiments',\n",
       " 'scientifically',\n",
       " 'analyze',\n",
       " 'results',\n",
       " 'ability',\n",
       " 'effectively',\n",
       " 'communicate',\n",
       " 'technical',\n",
       " 'concepts',\n",
       " 'results',\n",
       " 'technical',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'comprehensive',\n",
       " 'manner',\n",
       " 'ability',\n",
       " 'collaborate',\n",
       " 'effectively',\n",
       " 'across',\n",
       " 'multiple',\n",
       " 'teams',\n",
       " 'stakeholders',\n",
       " 'including',\n",
       " 'analytics',\n",
       " 'teams',\n",
       " 'development',\n",
       " 'teams',\n",
       " 'product',\n",
       " 'management',\n",
       " 'operations',\n",
       " 'additional',\n",
       " 'preferred',\n",
       " 'qualifications',\n",
       " 'company',\n",
       " 'summary',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'team',\n",
       " 'rapidly',\n",
       " 'innovating',\n",
       " 'evolve',\n",
       " 'define',\n",
       " 'future',\n",
       " 'state',\n",
       " 'shopping',\n",
       " 'worlds',\n",
       " 'largest',\n",
       " 'retailer',\n",
       " 'mission',\n",
       " 'help',\n",
       " 'people',\n",
       " 'save',\n",
       " 'money',\n",
       " 'live',\n",
       " 'better',\n",
       " 'help',\n",
       " 'brightest',\n",
       " 'minds',\n",
       " 'technology',\n",
       " 'merchandising',\n",
       " 'marketing',\n",
       " 'supply',\n",
       " 'chain',\n",
       " 'talent',\n",
       " 'reimagining',\n",
       " 'intersection',\n",
       " 'digital',\n",
       " 'physical',\n",
       " 'shopping',\n",
       " 'help',\n",
       " 'achieve',\n",
       " 'mission',\n",
       " 'position',\n",
       " 'summary',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'responsible',\n",
       " 'analyzing',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'models',\n",
       " 'algorithms',\n",
       " 'drive',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'work',\n",
       " 'project',\n",
       " 'teams',\n",
       " 'order',\n",
       " 'provide',\n",
       " 'analytical',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'building',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'order',\n",
       " 'build',\n",
       " 'algorithms',\n",
       " 'predicting',\n",
       " 'future',\n",
       " 'data',\n",
       " 'characteristics',\n",
       " 'algorithms',\n",
       " 'tested',\n",
       " 'validated',\n",
       " 'applied',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'training',\n",
       " 'algorithms',\n",
       " 'applied',\n",
       " 'future',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'provide',\n",
       " 'appropriate',\n",
       " 'search',\n",
       " 'results',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'researching',\n",
       " 'new',\n",
       " 'trends',\n",
       " 'industry',\n",
       " 'utilizing',\n",
       " 'uptodate',\n",
       " \"technology',\",\n",
       " 'interpret',\n",
       " 'apply',\n",
       " 'data',\n",
       " 'analyses',\n",
       " 'explain',\n",
       " 'findings',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'improve',\n",
       " 'products',\n",
       " 'processes',\n",
       " 'support',\n",
       " 'business',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'design',\n",
       " 'create',\n",
       " 'implement',\n",
       " 'manage',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " 'leverage',\n",
       " 'large',\n",
       " 'varied',\n",
       " 'datasets',\n",
       " 'using',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'analytical',\n",
       " 'tools',\n",
       " 'methods',\n",
       " 'platforms',\n",
       " 'interpret',\n",
       " 'apply',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'provide',\n",
       " 'recommendations',\n",
       " 'business',\n",
       " 'implement',\n",
       " 'activities',\n",
       " 'impact',\n",
       " 'singular',\n",
       " 'work',\n",
       " 'develop',\n",
       " 'execute',\n",
       " 'statistical',\n",
       " 'mathematical',\n",
       " 'solutions',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'frame',\n",
       " 'problems',\n",
       " 'determine',\n",
       " 'intended',\n",
       " 'approach',\n",
       " 'quantitative',\n",
       " 'methods',\n",
       " 'develop',\n",
       " 'solution',\n",
       " 'using',\n",
       " 'analytical',\n",
       " 'rigor',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'analyze',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'actionable',\n",
       " 'insights',\n",
       " 'using',\n",
       " 'advanced',\n",
       " 'statistical',\n",
       " 'techniques',\n",
       " 'predictive',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'customer',\n",
       " 'profiling',\n",
       " 'segmentation',\n",
       " 'analysis',\n",
       " 'survey',\n",
       " 'design',\n",
       " 'analysis',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'design',\n",
       " 'experiments',\n",
       " 'answer',\n",
       " 'targeted',\n",
       " 'questions',\n",
       " 'document',\n",
       " 'projects',\n",
       " 'including',\n",
       " 'business',\n",
       " 'objectives',\n",
       " 'data',\n",
       " 'gathering',\n",
       " 'processing',\n",
       " 'leading',\n",
       " 'approaches',\n",
       " 'final',\n",
       " 'algorithms',\n",
       " 'detailed',\n",
       " 'set',\n",
       " 'results',\n",
       " 'analytical',\n",
       " 'metrics',\n",
       " 'develop',\n",
       " 'materials',\n",
       " 'explain',\n",
       " 'project',\n",
       " 'findings',\n",
       " 'management',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'algorithms',\n",
       " 'mathematical',\n",
       " 'approaches',\n",
       " 'understand',\n",
       " 'companys',\n",
       " 'audiences',\n",
       " 'solve',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'optimizing',\n",
       " 'product',\n",
       " 'performance',\n",
       " 'review',\n",
       " 'adoption',\n",
       " 'make',\n",
       " 'tactical',\n",
       " 'decisions',\n",
       " 'driven',\n",
       " 'priorities',\n",
       " 'project',\n",
       " 'fall',\n",
       " 'within',\n",
       " 'defined',\n",
       " 'procedures',\n",
       " 'communicate',\n",
       " 'manager',\n",
       " 'status',\n",
       " 'issues',\n",
       " 'decisions',\n",
       " 'create',\n",
       " 'deliver',\n",
       " 'presentations',\n",
       " 'communication',\n",
       " 'managers',\n",
       " 'external',\n",
       " 'partners',\n",
       " 'issues',\n",
       " 'defined',\n",
       " 'best',\n",
       " 'practices',\n",
       " 'masters',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'lieu',\n",
       " 'masters',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'employer',\n",
       " 'accept',\n",
       " 'bachelors',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'experience',\n",
       " 'job',\n",
       " 'offered',\n",
       " 'related',\n",
       " 'position',\n",
       " 'also',\n",
       " 'requires',\n",
       " 'demonstrated',\n",
       " 'coursework',\n",
       " 'project',\n",
       " 'background',\n",
       " 'following',\n",
       " 'data',\n",
       " 'science',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'apply',\n",
       " 'mail',\n",
       " 'resume',\n",
       " 'dr',\n",
       " 'falls',\n",
       " 'wi',\n",
       " 'job',\n",
       " 'title',\n",
       " 'online',\n",
       " \"at',\",\n",
       " 'position',\n",
       " 'description',\n",
       " 'understands',\n",
       " 'translates',\n",
       " 'business',\n",
       " 'functional',\n",
       " 'needs',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'problem',\n",
       " 'statements',\n",
       " 'build',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'internally',\n",
       " 'externally',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'data',\n",
       " 'models',\n",
       " 'drive',\n",
       " 'innovative',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'write',\n",
       " 'complex',\n",
       " 'queries',\n",
       " 'extract',\n",
       " 'data',\n",
       " 'build',\n",
       " 'database',\n",
       " 'architecture',\n",
       " 'integrate',\n",
       " 'data',\n",
       " 'products',\n",
       " 'dashboards',\n",
       " 'user',\n",
       " 'interfaces',\n",
       " 'needed',\n",
       " 'collaborating',\n",
       " 'engineering',\n",
       " 'team',\n",
       " 'sift',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'multiple',\n",
       " 'angles',\n",
       " 'looking',\n",
       " 'trends',\n",
       " 'highlight',\n",
       " 'problems',\n",
       " 'opportunities',\n",
       " 'use',\n",
       " 'strong',\n",
       " 'business',\n",
       " 'acumen',\n",
       " 'well',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'findings',\n",
       " 'mine',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'useful',\n",
       " 'insights',\n",
       " 'apply',\n",
       " 'innovative',\n",
       " 'analytical',\n",
       " 'approaches',\n",
       " 'draw',\n",
       " 'conclusions',\n",
       " 'make',\n",
       " 'recommendations',\n",
       " 'answer',\n",
       " 'business',\n",
       " 'proficiency',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'classifications',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machines',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'strong',\n",
       " 'understanding',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'generative',\n",
       " 'descriptive',\n",
       " 'models',\n",
       " 'ability',\n",
       " 'run',\n",
       " 'experiments',\n",
       " 'scientifically',\n",
       " 'analyze',\n",
       " 'results',\n",
       " 'ability',\n",
       " 'effectively',\n",
       " 'communicate',\n",
       " 'technical',\n",
       " 'concepts',\n",
       " 'results',\n",
       " 'technical',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'comprehensive',\n",
       " 'manner',\n",
       " 'ability',\n",
       " 'collaborate',\n",
       " 'effectively',\n",
       " 'across',\n",
       " 'multiple',\n",
       " 'teams',\n",
       " 'stakeholders',\n",
       " 'including',\n",
       " 'analytics',\n",
       " 'teams',\n",
       " 'development',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:38.287875Z",
     "start_time": "2019-12-29T14:25:26.295760Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_again = []\n",
    "for text in new_data:\n",
    "    a = re.sub(r'[^a-zA-z ]+', '', text).strip()\n",
    "    if len(a)>0:\n",
    "        clean_again.append(clean_text(a))\n",
    "    else:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:38.294904Z",
     "start_time": "2019-12-29T14:25:38.290873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215721"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:38.308512Z",
     "start_time": "2019-12-29T14:25:38.297113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'summary',\n",
       " 'looking',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'join',\n",
       " 'dynamic',\n",
       " 'awardwinning',\n",
       " 'team',\n",
       " 'individuals',\n",
       " 'committed',\n",
       " 'making',\n",
       " 'insurance',\n",
       " 'smarter',\n",
       " 'easier',\n",
       " 'say',\n",
       " 'part',\n",
       " 'growing',\n",
       " 'company',\n",
       " 'focused',\n",
       " 'providing',\n",
       " 'outstanding',\n",
       " 'customer',\n",
       " 'experience',\n",
       " 'youll',\n",
       " 'opportunity',\n",
       " 'expand',\n",
       " 'skills',\n",
       " 'discover',\n",
       " 'potential',\n",
       " 'youre',\n",
       " 'looking',\n",
       " 'career',\n",
       " 'conscious',\n",
       " 'company',\n",
       " 'offers',\n",
       " 'great',\n",
       " 'benefits',\n",
       " 'including',\n",
       " 'matching',\n",
       " 'tuition',\n",
       " 'reimbursement',\n",
       " 'may',\n",
       " 'found',\n",
       " 'new',\n",
       " 'home',\n",
       " 'combines',\n",
       " 'startup',\n",
       " 'company',\n",
       " 'backing',\n",
       " 'allstate',\n",
       " 'largest',\n",
       " 'publicly',\n",
       " 'held',\n",
       " 'personal',\n",
       " 'lines',\n",
       " 'us',\n",
       " 'create',\n",
       " 'unique',\n",
       " 'energized',\n",
       " 'exciting',\n",
       " 'place',\n",
       " 'work',\n",
       " 'responsibilities',\n",
       " 'created',\n",
       " 'centralized',\n",
       " 'data',\n",
       " 'science',\n",
       " 'group',\n",
       " 'responsible',\n",
       " 'helping',\n",
       " 'business',\n",
       " 'units',\n",
       " 'make',\n",
       " 'objective',\n",
       " 'decisions',\n",
       " 'using',\n",
       " 'science',\n",
       " 'group',\n",
       " 'supports',\n",
       " 'overall',\n",
       " 'business',\n",
       " 'operations',\n",
       " 'delivering',\n",
       " 'critical',\n",
       " 'analytical',\n",
       " 'insights',\n",
       " 'indepth',\n",
       " 'consultative',\n",
       " 'analyses',\n",
       " 'group',\n",
       " 'also',\n",
       " 'develops',\n",
       " 'applications',\n",
       " 'platforms',\n",
       " 'used',\n",
       " 'deploy',\n",
       " 'analytics',\n",
       " 'real',\n",
       " 'time',\n",
       " 'job',\n",
       " 'responsibilities',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'group',\n",
       " 'develop',\n",
       " 'tangible',\n",
       " 'actionable',\n",
       " 'recommendations',\n",
       " 'implemented',\n",
       " 'realtime',\n",
       " 'improve',\n",
       " 'business',\n",
       " 'operations',\n",
       " 'key',\n",
       " 'responsibilities',\n",
       " 'include',\n",
       " 'working',\n",
       " 'business',\n",
       " 'stakeholders',\n",
       " 'deeply',\n",
       " 'understand',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'pain',\n",
       " 'points',\n",
       " 'developing',\n",
       " 'algorithms',\n",
       " 'predictive',\n",
       " 'models',\n",
       " 'using',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " 'collaborating',\n",
       " 'internal',\n",
       " 'technology',\n",
       " 'team',\n",
       " 'deploy',\n",
       " 'solutions',\n",
       " 'realtime',\n",
       " 'decisions',\n",
       " 'designing',\n",
       " 'experiments',\n",
       " 'determine',\n",
       " 'efficacy',\n",
       " 'solutions',\n",
       " 'providing',\n",
       " 'ongoing',\n",
       " 'performance',\n",
       " 'monitoring',\n",
       " 'decision',\n",
       " 'systems',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'qualifications',\n",
       " 'excellent',\n",
       " 'knowledge',\n",
       " 'highlevel',\n",
       " 'language',\n",
       " 'statistical',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " 'python',\n",
       " 'similar',\n",
       " 'extensive',\n",
       " 'experience',\n",
       " 'data',\n",
       " 'management',\n",
       " 'data',\n",
       " 'strong',\n",
       " 'aptitude',\n",
       " 'towards',\n",
       " 'math',\n",
       " 'programming',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'complex',\n",
       " 'information',\n",
       " 'way',\n",
       " 'clear',\n",
       " 'easily',\n",
       " 'understood',\n",
       " 'experience',\n",
       " 'education',\n",
       " 'bachelor',\n",
       " 'degree',\n",
       " 'statistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'related',\n",
       " 'field',\n",
       " 'equivalent',\n",
       " 'educationexperience',\n",
       " 'required',\n",
       " 'phd',\n",
       " 'master',\n",
       " 'degree',\n",
       " 'preferred',\n",
       " 'years',\n",
       " 'relevant',\n",
       " 'quantitative',\n",
       " 'qualitative',\n",
       " 'research',\n",
       " 'analytics',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'deploying',\n",
       " 'machinelearning',\n",
       " 'techniques',\n",
       " 'dimensionality',\n",
       " 'reduction',\n",
       " 'regression',\n",
       " 'clustering',\n",
       " 'classification',\n",
       " 'solve',\n",
       " 'realworld',\n",
       " 'problems',\n",
       " 'physical',\n",
       " 'demands',\n",
       " 'work',\n",
       " 'environment',\n",
       " 'representative',\n",
       " 'must',\n",
       " 'met',\n",
       " 'employee',\n",
       " 'successfully',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'functions',\n",
       " 'job',\n",
       " 'must',\n",
       " 'able',\n",
       " 'operate',\n",
       " 'pc',\n",
       " 'sit',\n",
       " 'extended',\n",
       " 'periods',\n",
       " 'time',\n",
       " 'reasonable',\n",
       " 'accommodations',\n",
       " 'may',\n",
       " 'made',\n",
       " 'enable',\n",
       " 'individuals',\n",
       " 'disabilities',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'functions',\n",
       " 'youll',\n",
       " 'love',\n",
       " 'working',\n",
       " 'us',\n",
       " 'offers',\n",
       " 'exciting',\n",
       " 'total',\n",
       " 'rewards',\n",
       " 'package',\n",
       " 'include',\n",
       " 'bonus',\n",
       " 'potential',\n",
       " 'positions',\n",
       " 'benefits',\n",
       " 'eligibility',\n",
       " 'day',\n",
       " 'company',\n",
       " 'matching',\n",
       " 'tuition',\n",
       " 'reimbursement',\n",
       " 'amp',\n",
       " 'student',\n",
       " 'loan',\n",
       " 'program',\n",
       " 'pet',\n",
       " 'insurance',\n",
       " 'discount',\n",
       " 'give',\n",
       " 'time',\n",
       " 'get',\n",
       " 'time',\n",
       " 'volunteer',\n",
       " 'program',\n",
       " 'much',\n",
       " 'perform',\n",
       " 'job',\n",
       " 'successfully',\n",
       " 'individual',\n",
       " 'must',\n",
       " 'able',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'job',\n",
       " 'duty',\n",
       " 'satisfactorily',\n",
       " 'reasonable',\n",
       " 'accommodations',\n",
       " 'may',\n",
       " 'made',\n",
       " 'enable',\n",
       " 'qualified',\n",
       " 'individuals',\n",
       " 'disabilities',\n",
       " 'perform',\n",
       " 'essential',\n",
       " 'job',\n",
       " 'functions',\n",
       " 'position',\n",
       " 'description',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'responsible',\n",
       " 'analyzing',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'models',\n",
       " 'algorithms',\n",
       " 'drive',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'work',\n",
       " 'project',\n",
       " 'teams',\n",
       " 'order',\n",
       " 'provide',\n",
       " 'analytical',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'building',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'order',\n",
       " 'build',\n",
       " 'algorithms',\n",
       " 'predicting',\n",
       " 'future',\n",
       " 'data',\n",
       " 'characteristics',\n",
       " 'algorithms',\n",
       " 'tested',\n",
       " 'validated',\n",
       " 'applied',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'training',\n",
       " 'algorithms',\n",
       " 'applied',\n",
       " 'future',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'provide',\n",
       " 'appropriate',\n",
       " 'search',\n",
       " 'results',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'researching',\n",
       " 'new',\n",
       " 'trends',\n",
       " 'industry',\n",
       " 'utilizing',\n",
       " 'uptodate',\n",
       " 'technology',\n",
       " 'minimum',\n",
       " 'qualifications',\n",
       " 'key',\n",
       " 'responsibilities',\n",
       " 'understands',\n",
       " 'translates',\n",
       " 'business',\n",
       " 'functional',\n",
       " 'needs',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'problem',\n",
       " 'statements',\n",
       " 'build',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'internally',\n",
       " 'externally',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'data',\n",
       " 'models',\n",
       " 'drive',\n",
       " 'innovative',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'write',\n",
       " 'complex',\n",
       " 'queries',\n",
       " 'extract',\n",
       " 'data',\n",
       " 'build',\n",
       " 'database',\n",
       " 'architecture',\n",
       " 'integrate',\n",
       " 'data',\n",
       " 'products',\n",
       " 'dashboards',\n",
       " 'user',\n",
       " 'interfaces',\n",
       " 'needed',\n",
       " 'collaborating',\n",
       " 'engineering',\n",
       " 'team',\n",
       " 'sift',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'multiple',\n",
       " 'angles',\n",
       " 'looking',\n",
       " 'trends',\n",
       " 'highlight',\n",
       " 'problems',\n",
       " 'opportunities',\n",
       " 'use',\n",
       " 'strong',\n",
       " 'business',\n",
       " 'acumen',\n",
       " 'well',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'findings',\n",
       " 'mine',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'useful',\n",
       " 'insights',\n",
       " 'apply',\n",
       " 'innovative',\n",
       " 'analytical',\n",
       " 'approaches',\n",
       " 'draw',\n",
       " 'conclusions',\n",
       " 'make',\n",
       " 'recommendations',\n",
       " 'answer',\n",
       " 'business',\n",
       " 'objectives',\n",
       " 'skills',\n",
       " 'proficiency',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'classifications',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machines',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'strong',\n",
       " 'understanding',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'generative',\n",
       " 'descriptive',\n",
       " 'models',\n",
       " 'ability',\n",
       " 'run',\n",
       " 'experiments',\n",
       " 'scientifically',\n",
       " 'analyze',\n",
       " 'results',\n",
       " 'ability',\n",
       " 'effectively',\n",
       " 'communicate',\n",
       " 'technical',\n",
       " 'concepts',\n",
       " 'results',\n",
       " 'technical',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'comprehensive',\n",
       " 'manner',\n",
       " 'ability',\n",
       " 'collaborate',\n",
       " 'effectively',\n",
       " 'across',\n",
       " 'multiple',\n",
       " 'teams',\n",
       " 'stakeholders',\n",
       " 'including',\n",
       " 'analytics',\n",
       " 'teams',\n",
       " 'development',\n",
       " 'teams',\n",
       " 'product',\n",
       " 'management',\n",
       " 'operations',\n",
       " 'additional',\n",
       " 'preferred',\n",
       " 'qualifications',\n",
       " 'company',\n",
       " 'summary',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'team',\n",
       " 'rapidly',\n",
       " 'innovating',\n",
       " 'evolve',\n",
       " 'define',\n",
       " 'future',\n",
       " 'state',\n",
       " 'shopping',\n",
       " 'worlds',\n",
       " 'largest',\n",
       " 'retailer',\n",
       " 'mission',\n",
       " 'help',\n",
       " 'people',\n",
       " 'save',\n",
       " 'money',\n",
       " 'live',\n",
       " 'better',\n",
       " 'help',\n",
       " 'brightest',\n",
       " 'minds',\n",
       " 'technology',\n",
       " 'merchandising',\n",
       " 'marketing',\n",
       " 'supply',\n",
       " 'chain',\n",
       " 'talent',\n",
       " 'reimagining',\n",
       " 'intersection',\n",
       " 'digital',\n",
       " 'physical',\n",
       " 'shopping',\n",
       " 'help',\n",
       " 'achieve',\n",
       " 'mission',\n",
       " 'position',\n",
       " 'summary',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'responsible',\n",
       " 'analyzing',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'models',\n",
       " 'algorithms',\n",
       " 'drive',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'work',\n",
       " 'project',\n",
       " 'teams',\n",
       " 'order',\n",
       " 'provide',\n",
       " 'analytical',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'walmart',\n",
       " 'ecommerce',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'building',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'order',\n",
       " 'build',\n",
       " 'algorithms',\n",
       " 'predicting',\n",
       " 'future',\n",
       " 'data',\n",
       " 'characteristics',\n",
       " 'algorithms',\n",
       " 'tested',\n",
       " 'validated',\n",
       " 'applied',\n",
       " 'large',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'training',\n",
       " 'algorithms',\n",
       " 'applied',\n",
       " 'future',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'provide',\n",
       " 'appropriate',\n",
       " 'search',\n",
       " 'results',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'responsible',\n",
       " 'researching',\n",
       " 'new',\n",
       " 'trends',\n",
       " 'industry',\n",
       " 'utilizing',\n",
       " 'uptodate',\n",
       " 'technology',\n",
       " 'interpret',\n",
       " 'apply',\n",
       " 'data',\n",
       " 'analyses',\n",
       " 'explain',\n",
       " 'findings',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'improve',\n",
       " 'products',\n",
       " 'processes',\n",
       " 'support',\n",
       " 'business',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'design',\n",
       " 'create',\n",
       " 'implement',\n",
       " 'manage',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " 'leverage',\n",
       " 'large',\n",
       " 'varied',\n",
       " 'datasets',\n",
       " 'using',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'analytical',\n",
       " 'tools',\n",
       " 'methods',\n",
       " 'platforms',\n",
       " 'interpret',\n",
       " 'apply',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'provide',\n",
       " 'recommendations',\n",
       " 'business',\n",
       " 'implement',\n",
       " 'activities',\n",
       " 'impact',\n",
       " 'singular',\n",
       " 'work',\n",
       " 'develop',\n",
       " 'execute',\n",
       " 'statistical',\n",
       " 'mathematical',\n",
       " 'solutions',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'frame',\n",
       " 'problems',\n",
       " 'determine',\n",
       " 'intended',\n",
       " 'approach',\n",
       " 'quantitative',\n",
       " 'methods',\n",
       " 'develop',\n",
       " 'solution',\n",
       " 'using',\n",
       " 'analytical',\n",
       " 'rigor',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'analyze',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'actionable',\n",
       " 'insights',\n",
       " 'using',\n",
       " 'advanced',\n",
       " 'statistical',\n",
       " 'techniques',\n",
       " 'predictive',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'customer',\n",
       " 'profiling',\n",
       " 'segmentation',\n",
       " 'analysis',\n",
       " 'survey',\n",
       " 'design',\n",
       " 'analysis',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'design',\n",
       " 'experiments',\n",
       " 'answer',\n",
       " 'targeted',\n",
       " 'questions',\n",
       " 'document',\n",
       " 'projects',\n",
       " 'including',\n",
       " 'business',\n",
       " 'objectives',\n",
       " 'data',\n",
       " 'gathering',\n",
       " 'processing',\n",
       " 'leading',\n",
       " 'approaches',\n",
       " 'final',\n",
       " 'algorithms',\n",
       " 'detailed',\n",
       " 'set',\n",
       " 'results',\n",
       " 'analytical',\n",
       " 'metrics',\n",
       " 'develop',\n",
       " 'materials',\n",
       " 'explain',\n",
       " 'project',\n",
       " 'findings',\n",
       " 'management',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'algorithms',\n",
       " 'mathematical',\n",
       " 'approaches',\n",
       " 'understand',\n",
       " 'companys',\n",
       " 'audiences',\n",
       " 'solve',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'optimizing',\n",
       " 'product',\n",
       " 'performance',\n",
       " 'review',\n",
       " 'adoption',\n",
       " 'make',\n",
       " 'tactical',\n",
       " 'decisions',\n",
       " 'driven',\n",
       " 'priorities',\n",
       " 'project',\n",
       " 'fall',\n",
       " 'within',\n",
       " 'defined',\n",
       " 'procedures',\n",
       " 'communicate',\n",
       " 'manager',\n",
       " 'status',\n",
       " 'issues',\n",
       " 'decisions',\n",
       " 'create',\n",
       " 'deliver',\n",
       " 'presentations',\n",
       " 'communication',\n",
       " 'managers',\n",
       " 'external',\n",
       " 'partners',\n",
       " 'issues',\n",
       " 'defined',\n",
       " 'best',\n",
       " 'practices',\n",
       " 'masters',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'lieu',\n",
       " 'masters',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'employer',\n",
       " 'accept',\n",
       " 'bachelors',\n",
       " 'degree',\n",
       " 'foreign',\n",
       " 'equivalent',\n",
       " 'management',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'data',\n",
       " 'science',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'related',\n",
       " 'field',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'experience',\n",
       " 'job',\n",
       " 'offered',\n",
       " 'related',\n",
       " 'position',\n",
       " 'also',\n",
       " 'requires',\n",
       " 'demonstrated',\n",
       " 'coursework',\n",
       " 'project',\n",
       " 'background',\n",
       " 'following',\n",
       " 'data',\n",
       " 'science',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'apply',\n",
       " 'mail',\n",
       " 'resume',\n",
       " 'dr',\n",
       " 'falls',\n",
       " 'wi',\n",
       " 'job',\n",
       " 'title',\n",
       " 'online',\n",
       " 'at',\n",
       " 'position',\n",
       " 'description',\n",
       " 'understands',\n",
       " 'translates',\n",
       " 'business',\n",
       " 'functional',\n",
       " 'needs',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'problem',\n",
       " 'statements',\n",
       " 'build',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'multiple',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'internally',\n",
       " 'externally',\n",
       " 'develop',\n",
       " 'custom',\n",
       " 'data',\n",
       " 'models',\n",
       " 'drive',\n",
       " 'innovative',\n",
       " 'business',\n",
       " 'solutions',\n",
       " 'write',\n",
       " 'complex',\n",
       " 'queries',\n",
       " 'extract',\n",
       " 'data',\n",
       " 'build',\n",
       " 'database',\n",
       " 'architecture',\n",
       " 'integrate',\n",
       " 'data',\n",
       " 'products',\n",
       " 'dashboards',\n",
       " 'user',\n",
       " 'interfaces',\n",
       " 'needed',\n",
       " 'collaborating',\n",
       " 'engineering',\n",
       " 'team',\n",
       " 'sift',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'multiple',\n",
       " 'angles',\n",
       " 'looking',\n",
       " 'trends',\n",
       " 'highlight',\n",
       " 'problems',\n",
       " 'opportunities',\n",
       " 'use',\n",
       " 'strong',\n",
       " 'business',\n",
       " 'acumen',\n",
       " 'well',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'findings',\n",
       " 'mine',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'data',\n",
       " 'useful',\n",
       " 'insights',\n",
       " 'apply',\n",
       " 'innovative',\n",
       " 'analytical',\n",
       " 'approaches',\n",
       " 'draw',\n",
       " 'conclusions',\n",
       " 'make',\n",
       " 'recommendations',\n",
       " 'answer',\n",
       " 'business',\n",
       " 'proficiency',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'classifications',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machines',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'strong',\n",
       " 'understanding',\n",
       " 'probability',\n",
       " 'statistical',\n",
       " 'models',\n",
       " 'generative',\n",
       " 'descriptive',\n",
       " 'models',\n",
       " 'ability',\n",
       " 'run',\n",
       " 'experiments',\n",
       " 'scientifically',\n",
       " 'analyze',\n",
       " 'results',\n",
       " 'ability',\n",
       " 'effectively',\n",
       " 'communicate',\n",
       " 'technical',\n",
       " 'concepts',\n",
       " 'results',\n",
       " 'technical',\n",
       " 'business',\n",
       " 'audiences',\n",
       " 'comprehensive',\n",
       " 'manner',\n",
       " 'ability',\n",
       " 'collaborate',\n",
       " 'effectively',\n",
       " 'across',\n",
       " 'multiple',\n",
       " 'teams',\n",
       " 'stakeholders',\n",
       " 'including',\n",
       " 'analytics',\n",
       " 'teams',\n",
       " 'development',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:52.952047Z",
     "start_time": "2019-12-29T14:25:52.948685Z"
    }
   },
   "outputs": [],
   "source": [
    "data = clean_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:53.423516Z",
     "start_time": "2019-12-29T14:25:53.421439Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = str(data).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:25:53.951414Z",
     "start_time": "2019-12-29T14:25:53.946074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215721"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:03.704109Z",
     "start_time": "2019-12-29T14:26:01.991628Z"
    }
   },
   "outputs": [],
   "source": [
    "train_len = 3+1\n",
    "text_sequences = []\n",
    "for i in range(train_len,len(data)):\n",
    "    seq = data[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "\n",
    "sequences = {}\n",
    "count = 1\n",
    "for i in range(len(data)):\n",
    "    if data[i] not in sequences:\n",
    "        sequences[data[i]] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:04.889631Z",
     "start_time": "2019-12-29T14:26:04.837736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'summary', 'looking', 'data'],\n",
       " ['summary', 'looking', 'data', 'scientist'],\n",
       " ['looking', 'data', 'scientist', 'join'],\n",
       " ['data', 'scientist', 'join', 'dynamic'],\n",
       " ['scientist', 'join', 'dynamic', 'awardwinning'],\n",
       " ['join', 'dynamic', 'awardwinning', 'team'],\n",
       " ['dynamic', 'awardwinning', 'team', 'individuals'],\n",
       " ['awardwinning', 'team', 'individuals', 'committed'],\n",
       " ['team', 'individuals', 'committed', 'making'],\n",
       " ['individuals', 'committed', 'making', 'insurance'],\n",
       " ['committed', 'making', 'insurance', 'smarter'],\n",
       " ['making', 'insurance', 'smarter', 'easier'],\n",
       " ['insurance', 'smarter', 'easier', 'say'],\n",
       " ['smarter', 'easier', 'say', 'part'],\n",
       " ['easier', 'say', 'part', 'growing'],\n",
       " ['say', 'part', 'growing', 'company'],\n",
       " ['part', 'growing', 'company', 'focused'],\n",
       " ['growing', 'company', 'focused', 'providing'],\n",
       " ['company', 'focused', 'providing', 'outstanding'],\n",
       " ['focused', 'providing', 'outstanding', 'customer'],\n",
       " ['providing', 'outstanding', 'customer', 'experience'],\n",
       " ['outstanding', 'customer', 'experience', 'youll'],\n",
       " ['customer', 'experience', 'youll', 'opportunity'],\n",
       " ['experience', 'youll', 'opportunity', 'expand'],\n",
       " ['youll', 'opportunity', 'expand', 'skills'],\n",
       " ['opportunity', 'expand', 'skills', 'discover'],\n",
       " ['expand', 'skills', 'discover', 'potential'],\n",
       " ['skills', 'discover', 'potential', 'youre'],\n",
       " ['discover', 'potential', 'youre', 'looking'],\n",
       " ['potential', 'youre', 'looking', 'career'],\n",
       " ['youre', 'looking', 'career', 'conscious'],\n",
       " ['looking', 'career', 'conscious', 'company'],\n",
       " ['career', 'conscious', 'company', 'offers'],\n",
       " ['conscious', 'company', 'offers', 'great'],\n",
       " ['company', 'offers', 'great', 'benefits'],\n",
       " ['offers', 'great', 'benefits', 'including'],\n",
       " ['great', 'benefits', 'including', 'matching'],\n",
       " ['benefits', 'including', 'matching', 'tuition'],\n",
       " ['including', 'matching', 'tuition', 'reimbursement'],\n",
       " ['matching', 'tuition', 'reimbursement', 'may'],\n",
       " ['tuition', 'reimbursement', 'may', 'found'],\n",
       " ['reimbursement', 'may', 'found', 'new'],\n",
       " ['may', 'found', 'new', 'home'],\n",
       " ['found', 'new', 'home', 'combines'],\n",
       " ['new', 'home', 'combines', 'startup'],\n",
       " ['home', 'combines', 'startup', 'company'],\n",
       " ['combines', 'startup', 'company', 'backing'],\n",
       " ['startup', 'company', 'backing', 'allstate'],\n",
       " ['company', 'backing', 'allstate', 'largest'],\n",
       " ['backing', 'allstate', 'largest', 'publicly'],\n",
       " ['allstate', 'largest', 'publicly', 'held'],\n",
       " ['largest', 'publicly', 'held', 'personal'],\n",
       " ['publicly', 'held', 'personal', 'lines'],\n",
       " ['held', 'personal', 'lines', 'us'],\n",
       " ['personal', 'lines', 'us', 'create'],\n",
       " ['lines', 'us', 'create', 'unique'],\n",
       " ['us', 'create', 'unique', 'energized'],\n",
       " ['create', 'unique', 'energized', 'exciting'],\n",
       " ['unique', 'energized', 'exciting', 'place'],\n",
       " ['energized', 'exciting', 'place', 'work'],\n",
       " ['exciting', 'place', 'work', 'responsibilities'],\n",
       " ['place', 'work', 'responsibilities', 'created'],\n",
       " ['work', 'responsibilities', 'created', 'centralized'],\n",
       " ['responsibilities', 'created', 'centralized', 'data'],\n",
       " ['created', 'centralized', 'data', 'science'],\n",
       " ['centralized', 'data', 'science', 'group'],\n",
       " ['data', 'science', 'group', 'responsible'],\n",
       " ['science', 'group', 'responsible', 'helping'],\n",
       " ['group', 'responsible', 'helping', 'business'],\n",
       " ['responsible', 'helping', 'business', 'units'],\n",
       " ['helping', 'business', 'units', 'make'],\n",
       " ['business', 'units', 'make', 'objective'],\n",
       " ['units', 'make', 'objective', 'decisions'],\n",
       " ['make', 'objective', 'decisions', 'using'],\n",
       " ['objective', 'decisions', 'using', 'science'],\n",
       " ['decisions', 'using', 'science', 'group'],\n",
       " ['using', 'science', 'group', 'supports'],\n",
       " ['science', 'group', 'supports', 'overall'],\n",
       " ['group', 'supports', 'overall', 'business'],\n",
       " ['supports', 'overall', 'business', 'operations'],\n",
       " ['overall', 'business', 'operations', 'delivering'],\n",
       " ['business', 'operations', 'delivering', 'critical'],\n",
       " ['operations', 'delivering', 'critical', 'analytical'],\n",
       " ['delivering', 'critical', 'analytical', 'insights'],\n",
       " ['critical', 'analytical', 'insights', 'indepth'],\n",
       " ['analytical', 'insights', 'indepth', 'consultative'],\n",
       " ['insights', 'indepth', 'consultative', 'analyses'],\n",
       " ['indepth', 'consultative', 'analyses', 'group'],\n",
       " ['consultative', 'analyses', 'group', 'also'],\n",
       " ['analyses', 'group', 'also', 'develops'],\n",
       " ['group', 'also', 'develops', 'applications'],\n",
       " ['also', 'develops', 'applications', 'platforms'],\n",
       " ['develops', 'applications', 'platforms', 'used'],\n",
       " ['applications', 'platforms', 'used', 'deploy'],\n",
       " ['platforms', 'used', 'deploy', 'analytics'],\n",
       " ['used', 'deploy', 'analytics', 'real'],\n",
       " ['deploy', 'analytics', 'real', 'time'],\n",
       " ['analytics', 'real', 'time', 'job'],\n",
       " ['real', 'time', 'job', 'responsibilities'],\n",
       " ['time', 'job', 'responsibilities', 'data'],\n",
       " ['job', 'responsibilities', 'data', 'scientists'],\n",
       " ['responsibilities', 'data', 'scientists', 'group'],\n",
       " ['data', 'scientists', 'group', 'develop'],\n",
       " ['scientists', 'group', 'develop', 'tangible'],\n",
       " ['group', 'develop', 'tangible', 'actionable'],\n",
       " ['develop', 'tangible', 'actionable', 'recommendations'],\n",
       " ['tangible', 'actionable', 'recommendations', 'implemented'],\n",
       " ['actionable', 'recommendations', 'implemented', 'realtime'],\n",
       " ['recommendations', 'implemented', 'realtime', 'improve'],\n",
       " ['implemented', 'realtime', 'improve', 'business'],\n",
       " ['realtime', 'improve', 'business', 'operations'],\n",
       " ['improve', 'business', 'operations', 'key'],\n",
       " ['business', 'operations', 'key', 'responsibilities'],\n",
       " ['operations', 'key', 'responsibilities', 'include'],\n",
       " ['key', 'responsibilities', 'include', 'working'],\n",
       " ['responsibilities', 'include', 'working', 'business'],\n",
       " ['include', 'working', 'business', 'stakeholders'],\n",
       " ['working', 'business', 'stakeholders', 'deeply'],\n",
       " ['business', 'stakeholders', 'deeply', 'understand'],\n",
       " ['stakeholders', 'deeply', 'understand', 'business'],\n",
       " ['deeply', 'understand', 'business', 'problems'],\n",
       " ['understand', 'business', 'problems', 'pain'],\n",
       " ['business', 'problems', 'pain', 'points'],\n",
       " ['problems', 'pain', 'points', 'developing'],\n",
       " ['pain', 'points', 'developing', 'algorithms'],\n",
       " ['points', 'developing', 'algorithms', 'predictive'],\n",
       " ['developing', 'algorithms', 'predictive', 'models'],\n",
       " ['algorithms', 'predictive', 'models', 'using'],\n",
       " ['predictive', 'models', 'using', 'large'],\n",
       " ['models', 'using', 'large', 'amounts'],\n",
       " ['using', 'large', 'amounts', 'structured'],\n",
       " ['large', 'amounts', 'structured', 'unstructured'],\n",
       " ['amounts', 'structured', 'unstructured', 'data'],\n",
       " ['structured', 'unstructured', 'data', 'collaborating'],\n",
       " ['unstructured', 'data', 'collaborating', 'internal'],\n",
       " ['data', 'collaborating', 'internal', 'technology'],\n",
       " ['collaborating', 'internal', 'technology', 'team'],\n",
       " ['internal', 'technology', 'team', 'deploy'],\n",
       " ['technology', 'team', 'deploy', 'solutions'],\n",
       " ['team', 'deploy', 'solutions', 'realtime'],\n",
       " ['deploy', 'solutions', 'realtime', 'decisions'],\n",
       " ['solutions', 'realtime', 'decisions', 'designing'],\n",
       " ['realtime', 'decisions', 'designing', 'experiments'],\n",
       " ['decisions', 'designing', 'experiments', 'determine'],\n",
       " ['designing', 'experiments', 'determine', 'efficacy'],\n",
       " ['experiments', 'determine', 'efficacy', 'solutions'],\n",
       " ['determine', 'efficacy', 'solutions', 'providing'],\n",
       " ['efficacy', 'solutions', 'providing', 'ongoing'],\n",
       " ['solutions', 'providing', 'ongoing', 'performance'],\n",
       " ['providing', 'ongoing', 'performance', 'monitoring'],\n",
       " ['ongoing', 'performance', 'monitoring', 'decision'],\n",
       " ['performance', 'monitoring', 'decision', 'systems'],\n",
       " ['monitoring', 'decision', 'systems', 'statistical'],\n",
       " ['decision', 'systems', 'statistical', 'models'],\n",
       " ['systems', 'statistical', 'models', 'qualifications'],\n",
       " ['statistical', 'models', 'qualifications', 'excellent'],\n",
       " ['models', 'qualifications', 'excellent', 'knowledge'],\n",
       " ['qualifications', 'excellent', 'knowledge', 'highlevel'],\n",
       " ['excellent', 'knowledge', 'highlevel', 'language'],\n",
       " ['knowledge', 'highlevel', 'language', 'statistical'],\n",
       " ['highlevel', 'language', 'statistical', 'scientific'],\n",
       " ['language', 'statistical', 'scientific', 'computing'],\n",
       " ['statistical', 'scientific', 'computing', 'python'],\n",
       " ['scientific', 'computing', 'python', 'similar'],\n",
       " ['computing', 'python', 'similar', 'extensive'],\n",
       " ['python', 'similar', 'extensive', 'experience'],\n",
       " ['similar', 'extensive', 'experience', 'data'],\n",
       " ['extensive', 'experience', 'data', 'management'],\n",
       " ['experience', 'data', 'management', 'data'],\n",
       " ['data', 'management', 'data', 'strong'],\n",
       " ['management', 'data', 'strong', 'aptitude'],\n",
       " ['data', 'strong', 'aptitude', 'towards'],\n",
       " ['strong', 'aptitude', 'towards', 'math'],\n",
       " ['aptitude', 'towards', 'math', 'programming'],\n",
       " ['towards', 'math', 'programming', 'ability'],\n",
       " ['math', 'programming', 'ability', 'communicate'],\n",
       " ['programming', 'ability', 'communicate', 'complex'],\n",
       " ['ability', 'communicate', 'complex', 'information'],\n",
       " ['communicate', 'complex', 'information', 'way'],\n",
       " ['complex', 'information', 'way', 'clear'],\n",
       " ['information', 'way', 'clear', 'easily'],\n",
       " ['way', 'clear', 'easily', 'understood'],\n",
       " ['clear', 'easily', 'understood', 'experience'],\n",
       " ['easily', 'understood', 'experience', 'education'],\n",
       " ['understood', 'experience', 'education', 'bachelor'],\n",
       " ['experience', 'education', 'bachelor', 'degree'],\n",
       " ['education', 'bachelor', 'degree', 'statistics'],\n",
       " ['bachelor', 'degree', 'statistics', 'computer'],\n",
       " ['degree', 'statistics', 'computer', 'science'],\n",
       " ['statistics', 'computer', 'science', 'related'],\n",
       " ['computer', 'science', 'related', 'field'],\n",
       " ['science', 'related', 'field', 'equivalent'],\n",
       " ['related', 'field', 'equivalent', 'educationexperience'],\n",
       " ['field', 'equivalent', 'educationexperience', 'required'],\n",
       " ['equivalent', 'educationexperience', 'required', 'phd'],\n",
       " ['educationexperience', 'required', 'phd', 'master'],\n",
       " ['required', 'phd', 'master', 'degree'],\n",
       " ['phd', 'master', 'degree', 'preferred'],\n",
       " ['master', 'degree', 'preferred', 'years'],\n",
       " ['degree', 'preferred', 'years', 'relevant'],\n",
       " ['preferred', 'years', 'relevant', 'quantitative'],\n",
       " ['years', 'relevant', 'quantitative', 'qualitative'],\n",
       " ['relevant', 'quantitative', 'qualitative', 'research'],\n",
       " ['quantitative', 'qualitative', 'research', 'analytics'],\n",
       " ['qualitative', 'research', 'analytics', 'experience'],\n",
       " ['research', 'analytics', 'experience', 'experience'],\n",
       " ['analytics', 'experience', 'experience', 'deploying'],\n",
       " ['experience', 'experience', 'deploying', 'machinelearning'],\n",
       " ['experience', 'deploying', 'machinelearning', 'techniques'],\n",
       " ['deploying', 'machinelearning', 'techniques', 'dimensionality'],\n",
       " ['machinelearning', 'techniques', 'dimensionality', 'reduction'],\n",
       " ['techniques', 'dimensionality', 'reduction', 'regression'],\n",
       " ['dimensionality', 'reduction', 'regression', 'clustering'],\n",
       " ['reduction', 'regression', 'clustering', 'classification'],\n",
       " ['regression', 'clustering', 'classification', 'solve'],\n",
       " ['clustering', 'classification', 'solve', 'realworld'],\n",
       " ['classification', 'solve', 'realworld', 'problems'],\n",
       " ['solve', 'realworld', 'problems', 'physical'],\n",
       " ['realworld', 'problems', 'physical', 'demands'],\n",
       " ['problems', 'physical', 'demands', 'work'],\n",
       " ['physical', 'demands', 'work', 'environment'],\n",
       " ['demands', 'work', 'environment', 'representative'],\n",
       " ['work', 'environment', 'representative', 'must'],\n",
       " ['environment', 'representative', 'must', 'met'],\n",
       " ['representative', 'must', 'met', 'employee'],\n",
       " ['must', 'met', 'employee', 'successfully'],\n",
       " ['met', 'employee', 'successfully', 'perform'],\n",
       " ['employee', 'successfully', 'perform', 'essential'],\n",
       " ['successfully', 'perform', 'essential', 'functions'],\n",
       " ['perform', 'essential', 'functions', 'job'],\n",
       " ['essential', 'functions', 'job', 'must'],\n",
       " ['functions', 'job', 'must', 'able'],\n",
       " ['job', 'must', 'able', 'operate'],\n",
       " ['must', 'able', 'operate', 'pc'],\n",
       " ['able', 'operate', 'pc', 'sit'],\n",
       " ['operate', 'pc', 'sit', 'extended'],\n",
       " ['pc', 'sit', 'extended', 'periods'],\n",
       " ['sit', 'extended', 'periods', 'time'],\n",
       " ['extended', 'periods', 'time', 'reasonable'],\n",
       " ['periods', 'time', 'reasonable', 'accommodations'],\n",
       " ['time', 'reasonable', 'accommodations', 'may'],\n",
       " ['reasonable', 'accommodations', 'may', 'made'],\n",
       " ['accommodations', 'may', 'made', 'enable'],\n",
       " ['may', 'made', 'enable', 'individuals'],\n",
       " ['made', 'enable', 'individuals', 'disabilities'],\n",
       " ['enable', 'individuals', 'disabilities', 'perform'],\n",
       " ['individuals', 'disabilities', 'perform', 'essential'],\n",
       " ['disabilities', 'perform', 'essential', 'functions'],\n",
       " ['perform', 'essential', 'functions', 'youll'],\n",
       " ['essential', 'functions', 'youll', 'love'],\n",
       " ['functions', 'youll', 'love', 'working'],\n",
       " ['youll', 'love', 'working', 'us'],\n",
       " ['love', 'working', 'us', 'offers'],\n",
       " ['working', 'us', 'offers', 'exciting'],\n",
       " ['us', 'offers', 'exciting', 'total'],\n",
       " ['offers', 'exciting', 'total', 'rewards'],\n",
       " ['exciting', 'total', 'rewards', 'package'],\n",
       " ['total', 'rewards', 'package', 'include'],\n",
       " ['rewards', 'package', 'include', 'bonus'],\n",
       " ['package', 'include', 'bonus', 'potential'],\n",
       " ['include', 'bonus', 'potential', 'positions'],\n",
       " ['bonus', 'potential', 'positions', 'benefits'],\n",
       " ['potential', 'positions', 'benefits', 'eligibility'],\n",
       " ['positions', 'benefits', 'eligibility', 'day'],\n",
       " ['benefits', 'eligibility', 'day', 'company'],\n",
       " ['eligibility', 'day', 'company', 'matching'],\n",
       " ['day', 'company', 'matching', 'tuition'],\n",
       " ['company', 'matching', 'tuition', 'reimbursement'],\n",
       " ['matching', 'tuition', 'reimbursement', 'amp'],\n",
       " ['tuition', 'reimbursement', 'amp', 'student'],\n",
       " ['reimbursement', 'amp', 'student', 'loan'],\n",
       " ['amp', 'student', 'loan', 'program'],\n",
       " ['student', 'loan', 'program', 'pet'],\n",
       " ['loan', 'program', 'pet', 'insurance'],\n",
       " ['program', 'pet', 'insurance', 'discount'],\n",
       " ['pet', 'insurance', 'discount', 'give'],\n",
       " ['insurance', 'discount', 'give', 'time'],\n",
       " ['discount', 'give', 'time', 'get'],\n",
       " ['give', 'time', 'get', 'time'],\n",
       " ['time', 'get', 'time', 'volunteer'],\n",
       " ['get', 'time', 'volunteer', 'program'],\n",
       " ['time', 'volunteer', 'program', 'much'],\n",
       " ['volunteer', 'program', 'much', 'perform'],\n",
       " ['program', 'much', 'perform', 'job'],\n",
       " ['much', 'perform', 'job', 'successfully'],\n",
       " ['perform', 'job', 'successfully', 'individual'],\n",
       " ['job', 'successfully', 'individual', 'must'],\n",
       " ['successfully', 'individual', 'must', 'able'],\n",
       " ['individual', 'must', 'able', 'perform'],\n",
       " ['must', 'able', 'perform', 'essential'],\n",
       " ['able', 'perform', 'essential', 'job'],\n",
       " ['perform', 'essential', 'job', 'duty'],\n",
       " ['essential', 'job', 'duty', 'satisfactorily'],\n",
       " ['job', 'duty', 'satisfactorily', 'reasonable'],\n",
       " ['duty', 'satisfactorily', 'reasonable', 'accommodations'],\n",
       " ['satisfactorily', 'reasonable', 'accommodations', 'may'],\n",
       " ['reasonable', 'accommodations', 'may', 'made'],\n",
       " ['accommodations', 'may', 'made', 'enable'],\n",
       " ['may', 'made', 'enable', 'qualified'],\n",
       " ['made', 'enable', 'qualified', 'individuals'],\n",
       " ['enable', 'qualified', 'individuals', 'disabilities'],\n",
       " ['qualified', 'individuals', 'disabilities', 'perform'],\n",
       " ['individuals', 'disabilities', 'perform', 'essential'],\n",
       " ['disabilities', 'perform', 'essential', 'job'],\n",
       " ['perform', 'essential', 'job', 'functions'],\n",
       " ['essential', 'job', 'functions', 'position'],\n",
       " ['job', 'functions', 'position', 'description'],\n",
       " ['functions', 'position', 'description', 'data'],\n",
       " ['position', 'description', 'data', 'scientist'],\n",
       " ['description', 'data', 'scientist', 'responsible'],\n",
       " ['data', 'scientist', 'responsible', 'analyzing'],\n",
       " ['scientist', 'responsible', 'analyzing', 'large'],\n",
       " ['responsible', 'analyzing', 'large', 'data'],\n",
       " ['analyzing', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'develop'],\n",
       " ['data', 'sets', 'develop', 'custom'],\n",
       " ['sets', 'develop', 'custom', 'models'],\n",
       " ['develop', 'custom', 'models', 'algorithms'],\n",
       " ['custom', 'models', 'algorithms', 'drive'],\n",
       " ['models', 'algorithms', 'drive', 'business'],\n",
       " ['algorithms', 'drive', 'business', 'solutions'],\n",
       " ['drive', 'business', 'solutions', 'data'],\n",
       " ['business', 'solutions', 'data', 'scientists'],\n",
       " ['solutions', 'data', 'scientists', 'work'],\n",
       " ['data', 'scientists', 'work', 'project'],\n",
       " ['scientists', 'work', 'project', 'teams'],\n",
       " ['work', 'project', 'teams', 'order'],\n",
       " ['project', 'teams', 'order', 'provide'],\n",
       " ['teams', 'order', 'provide', 'analytical'],\n",
       " ['order', 'provide', 'analytical', 'support'],\n",
       " ['provide', 'analytical', 'support', 'projects'],\n",
       " ['analytical', 'support', 'projects', 'walmart'],\n",
       " ['support', 'projects', 'walmart', 'ecommerce'],\n",
       " ['projects', 'walmart', 'ecommerce', 'data'],\n",
       " ['walmart', 'ecommerce', 'data', 'scientists'],\n",
       " ['ecommerce', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'building'],\n",
       " ['scientists', 'responsible', 'building', 'large'],\n",
       " ['responsible', 'building', 'large', 'data'],\n",
       " ['building', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'multiple'],\n",
       " ['data', 'sets', 'multiple', 'sources'],\n",
       " ['sets', 'multiple', 'sources', 'order'],\n",
       " ['multiple', 'sources', 'order', 'build'],\n",
       " ['sources', 'order', 'build', 'algorithms'],\n",
       " ['order', 'build', 'algorithms', 'predicting'],\n",
       " ['build', 'algorithms', 'predicting', 'future'],\n",
       " ['algorithms', 'predicting', 'future', 'data'],\n",
       " ['predicting', 'future', 'data', 'characteristics'],\n",
       " ['future', 'data', 'characteristics', 'algorithms'],\n",
       " ['data', 'characteristics', 'algorithms', 'tested'],\n",
       " ['characteristics', 'algorithms', 'tested', 'validated'],\n",
       " ['algorithms', 'tested', 'validated', 'applied'],\n",
       " ['tested', 'validated', 'applied', 'large'],\n",
       " ['validated', 'applied', 'large', 'data'],\n",
       " ['applied', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'data'],\n",
       " ['data', 'sets', 'data', 'scientists'],\n",
       " ['sets', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'training'],\n",
       " ['scientists', 'responsible', 'training', 'algorithms'],\n",
       " ['responsible', 'training', 'algorithms', 'applied'],\n",
       " ['training', 'algorithms', 'applied', 'future'],\n",
       " ['algorithms', 'applied', 'future', 'data'],\n",
       " ['applied', 'future', 'data', 'sets'],\n",
       " ['future', 'data', 'sets', 'provide'],\n",
       " ['data', 'sets', 'provide', 'appropriate'],\n",
       " ['sets', 'provide', 'appropriate', 'search'],\n",
       " ['provide', 'appropriate', 'search', 'results'],\n",
       " ['appropriate', 'search', 'results', 'data'],\n",
       " ['search', 'results', 'data', 'scientists'],\n",
       " ['results', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'researching'],\n",
       " ['scientists', 'responsible', 'researching', 'new'],\n",
       " ['responsible', 'researching', 'new', 'trends'],\n",
       " ['researching', 'new', 'trends', 'industry'],\n",
       " ['new', 'trends', 'industry', 'utilizing'],\n",
       " ['trends', 'industry', 'utilizing', 'uptodate'],\n",
       " ['industry', 'utilizing', 'uptodate', 'technology'],\n",
       " ['utilizing', 'uptodate', 'technology', 'minimum'],\n",
       " ['uptodate', 'technology', 'minimum', 'qualifications'],\n",
       " ['technology', 'minimum', 'qualifications', 'key'],\n",
       " ['minimum', 'qualifications', 'key', 'responsibilities'],\n",
       " ['qualifications', 'key', 'responsibilities', 'understands'],\n",
       " ['key', 'responsibilities', 'understands', 'translates'],\n",
       " ['responsibilities', 'understands', 'translates', 'business'],\n",
       " ['understands', 'translates', 'business', 'functional'],\n",
       " ['translates', 'business', 'functional', 'needs'],\n",
       " ['business', 'functional', 'needs', 'data'],\n",
       " ['functional', 'needs', 'data', 'scientist'],\n",
       " ['needs', 'data', 'scientist', 'problem'],\n",
       " ['data', 'scientist', 'problem', 'statements'],\n",
       " ['scientist', 'problem', 'statements', 'build'],\n",
       " ['problem', 'statements', 'build', 'complex'],\n",
       " ['statements', 'build', 'complex', 'data'],\n",
       " ['build', 'complex', 'data', 'sets'],\n",
       " ['complex', 'data', 'sets', 'multiple'],\n",
       " ['data', 'sets', 'multiple', 'data'],\n",
       " ['sets', 'multiple', 'data', 'sources'],\n",
       " ['multiple', 'data', 'sources', 'internally'],\n",
       " ['data', 'sources', 'internally', 'externally'],\n",
       " ['sources', 'internally', 'externally', 'develop'],\n",
       " ['internally', 'externally', 'develop', 'custom'],\n",
       " ['externally', 'develop', 'custom', 'data'],\n",
       " ['develop', 'custom', 'data', 'models'],\n",
       " ['custom', 'data', 'models', 'drive'],\n",
       " ['data', 'models', 'drive', 'innovative'],\n",
       " ['models', 'drive', 'innovative', 'business'],\n",
       " ['drive', 'innovative', 'business', 'solutions'],\n",
       " ['innovative', 'business', 'solutions', 'write'],\n",
       " ['business', 'solutions', 'write', 'complex'],\n",
       " ['solutions', 'write', 'complex', 'queries'],\n",
       " ['write', 'complex', 'queries', 'extract'],\n",
       " ['complex', 'queries', 'extract', 'data'],\n",
       " ['queries', 'extract', 'data', 'build'],\n",
       " ['extract', 'data', 'build', 'database'],\n",
       " ['data', 'build', 'database', 'architecture'],\n",
       " ['build', 'database', 'architecture', 'integrate'],\n",
       " ['database', 'architecture', 'integrate', 'data'],\n",
       " ['architecture', 'integrate', 'data', 'products'],\n",
       " ['integrate', 'data', 'products', 'dashboards'],\n",
       " ['data', 'products', 'dashboards', 'user'],\n",
       " ['products', 'dashboards', 'user', 'interfaces'],\n",
       " ['dashboards', 'user', 'interfaces', 'needed'],\n",
       " ['user', 'interfaces', 'needed', 'collaborating'],\n",
       " ['interfaces', 'needed', 'collaborating', 'engineering'],\n",
       " ['needed', 'collaborating', 'engineering', 'team'],\n",
       " ['collaborating', 'engineering', 'team', 'sift'],\n",
       " ['engineering', 'team', 'sift', 'analyze'],\n",
       " ['team', 'sift', 'analyze', 'data'],\n",
       " ['sift', 'analyze', 'data', 'multiple'],\n",
       " ['analyze', 'data', 'multiple', 'angles'],\n",
       " ['data', 'multiple', 'angles', 'looking'],\n",
       " ['multiple', 'angles', 'looking', 'trends'],\n",
       " ['angles', 'looking', 'trends', 'highlight'],\n",
       " ['looking', 'trends', 'highlight', 'problems'],\n",
       " ['trends', 'highlight', 'problems', 'opportunities'],\n",
       " ['highlight', 'problems', 'opportunities', 'use'],\n",
       " ['problems', 'opportunities', 'use', 'strong'],\n",
       " ['opportunities', 'use', 'strong', 'business'],\n",
       " ['use', 'strong', 'business', 'acumen'],\n",
       " ['strong', 'business', 'acumen', 'well'],\n",
       " ['business', 'acumen', 'well', 'ability'],\n",
       " ['acumen', 'well', 'ability', 'communicate'],\n",
       " ['well', 'ability', 'communicate', 'findings'],\n",
       " ['ability', 'communicate', 'findings', 'mine'],\n",
       " ['communicate', 'findings', 'mine', 'vast'],\n",
       " ['findings', 'mine', 'vast', 'amounts'],\n",
       " ['mine', 'vast', 'amounts', 'data'],\n",
       " ['vast', 'amounts', 'data', 'useful'],\n",
       " ['amounts', 'data', 'useful', 'insights'],\n",
       " ['data', 'useful', 'insights', 'apply'],\n",
       " ['useful', 'insights', 'apply', 'innovative'],\n",
       " ['insights', 'apply', 'innovative', 'analytical'],\n",
       " ['apply', 'innovative', 'analytical', 'approaches'],\n",
       " ['innovative', 'analytical', 'approaches', 'draw'],\n",
       " ['analytical', 'approaches', 'draw', 'conclusions'],\n",
       " ['approaches', 'draw', 'conclusions', 'make'],\n",
       " ['draw', 'conclusions', 'make', 'recommendations'],\n",
       " ['conclusions', 'make', 'recommendations', 'answer'],\n",
       " ['make', 'recommendations', 'answer', 'business'],\n",
       " ['recommendations', 'answer', 'business', 'objectives'],\n",
       " ['answer', 'business', 'objectives', 'skills'],\n",
       " ['business', 'objectives', 'skills', 'proficiency'],\n",
       " ['objectives', 'skills', 'proficiency', 'machine'],\n",
       " ['skills', 'proficiency', 'machine', 'learning'],\n",
       " ['proficiency', 'machine', 'learning', 'algorithms'],\n",
       " ['machine', 'learning', 'algorithms', 'classifications'],\n",
       " ['learning', 'algorithms', 'classifications', 'decision'],\n",
       " ['algorithms', 'classifications', 'decision', 'trees'],\n",
       " ['classifications', 'decision', 'trees', 'support'],\n",
       " ['decision', 'trees', 'support', 'vector'],\n",
       " ['trees', 'support', 'vector', 'machines'],\n",
       " ['support', 'vector', 'machines', 'deep'],\n",
       " ['vector', 'machines', 'deep', 'learning'],\n",
       " ['machines', 'deep', 'learning', 'strong'],\n",
       " ['deep', 'learning', 'strong', 'understanding'],\n",
       " ['learning', 'strong', 'understanding', 'probability'],\n",
       " ['strong', 'understanding', 'probability', 'statistical'],\n",
       " ['understanding', 'probability', 'statistical', 'models'],\n",
       " ['probability', 'statistical', 'models', 'generative'],\n",
       " ['statistical', 'models', 'generative', 'descriptive'],\n",
       " ['models', 'generative', 'descriptive', 'models'],\n",
       " ['generative', 'descriptive', 'models', 'ability'],\n",
       " ['descriptive', 'models', 'ability', 'run'],\n",
       " ['models', 'ability', 'run', 'experiments'],\n",
       " ['ability', 'run', 'experiments', 'scientifically'],\n",
       " ['run', 'experiments', 'scientifically', 'analyze'],\n",
       " ['experiments', 'scientifically', 'analyze', 'results'],\n",
       " ['scientifically', 'analyze', 'results', 'ability'],\n",
       " ['analyze', 'results', 'ability', 'effectively'],\n",
       " ['results', 'ability', 'effectively', 'communicate'],\n",
       " ['ability', 'effectively', 'communicate', 'technical'],\n",
       " ['effectively', 'communicate', 'technical', 'concepts'],\n",
       " ['communicate', 'technical', 'concepts', 'results'],\n",
       " ['technical', 'concepts', 'results', 'technical'],\n",
       " ['concepts', 'results', 'technical', 'business'],\n",
       " ['results', 'technical', 'business', 'audiences'],\n",
       " ['technical', 'business', 'audiences', 'comprehensive'],\n",
       " ['business', 'audiences', 'comprehensive', 'manner'],\n",
       " ['audiences', 'comprehensive', 'manner', 'ability'],\n",
       " ['comprehensive', 'manner', 'ability', 'collaborate'],\n",
       " ['manner', 'ability', 'collaborate', 'effectively'],\n",
       " ['ability', 'collaborate', 'effectively', 'across'],\n",
       " ['collaborate', 'effectively', 'across', 'multiple'],\n",
       " ['effectively', 'across', 'multiple', 'teams'],\n",
       " ['across', 'multiple', 'teams', 'stakeholders'],\n",
       " ['multiple', 'teams', 'stakeholders', 'including'],\n",
       " ['teams', 'stakeholders', 'including', 'analytics'],\n",
       " ['stakeholders', 'including', 'analytics', 'teams'],\n",
       " ['including', 'analytics', 'teams', 'development'],\n",
       " ['analytics', 'teams', 'development', 'teams'],\n",
       " ['teams', 'development', 'teams', 'product'],\n",
       " ['development', 'teams', 'product', 'management'],\n",
       " ['teams', 'product', 'management', 'operations'],\n",
       " ['product', 'management', 'operations', 'additional'],\n",
       " ['management', 'operations', 'additional', 'preferred'],\n",
       " ['operations', 'additional', 'preferred', 'qualifications'],\n",
       " ['additional', 'preferred', 'qualifications', 'company'],\n",
       " ['preferred', 'qualifications', 'company', 'summary'],\n",
       " ['qualifications', 'company', 'summary', 'walmart'],\n",
       " ['company', 'summary', 'walmart', 'ecommerce'],\n",
       " ['summary', 'walmart', 'ecommerce', 'team'],\n",
       " ['walmart', 'ecommerce', 'team', 'rapidly'],\n",
       " ['ecommerce', 'team', 'rapidly', 'innovating'],\n",
       " ['team', 'rapidly', 'innovating', 'evolve'],\n",
       " ['rapidly', 'innovating', 'evolve', 'define'],\n",
       " ['innovating', 'evolve', 'define', 'future'],\n",
       " ['evolve', 'define', 'future', 'state'],\n",
       " ['define', 'future', 'state', 'shopping'],\n",
       " ['future', 'state', 'shopping', 'worlds'],\n",
       " ['state', 'shopping', 'worlds', 'largest'],\n",
       " ['shopping', 'worlds', 'largest', 'retailer'],\n",
       " ['worlds', 'largest', 'retailer', 'mission'],\n",
       " ['largest', 'retailer', 'mission', 'help'],\n",
       " ['retailer', 'mission', 'help', 'people'],\n",
       " ['mission', 'help', 'people', 'save'],\n",
       " ['help', 'people', 'save', 'money'],\n",
       " ['people', 'save', 'money', 'live'],\n",
       " ['save', 'money', 'live', 'better'],\n",
       " ['money', 'live', 'better', 'help'],\n",
       " ['live', 'better', 'help', 'brightest'],\n",
       " ['better', 'help', 'brightest', 'minds'],\n",
       " ['help', 'brightest', 'minds', 'technology'],\n",
       " ['brightest', 'minds', 'technology', 'merchandising'],\n",
       " ['minds', 'technology', 'merchandising', 'marketing'],\n",
       " ['technology', 'merchandising', 'marketing', 'supply'],\n",
       " ['merchandising', 'marketing', 'supply', 'chain'],\n",
       " ['marketing', 'supply', 'chain', 'talent'],\n",
       " ['supply', 'chain', 'talent', 'reimagining'],\n",
       " ['chain', 'talent', 'reimagining', 'intersection'],\n",
       " ['talent', 'reimagining', 'intersection', 'digital'],\n",
       " ['reimagining', 'intersection', 'digital', 'physical'],\n",
       " ['intersection', 'digital', 'physical', 'shopping'],\n",
       " ['digital', 'physical', 'shopping', 'help'],\n",
       " ['physical', 'shopping', 'help', 'achieve'],\n",
       " ['shopping', 'help', 'achieve', 'mission'],\n",
       " ['help', 'achieve', 'mission', 'position'],\n",
       " ['achieve', 'mission', 'position', 'summary'],\n",
       " ['mission', 'position', 'summary', 'data'],\n",
       " ['position', 'summary', 'data', 'scientist'],\n",
       " ['summary', 'data', 'scientist', 'responsible'],\n",
       " ['data', 'scientist', 'responsible', 'analyzing'],\n",
       " ['scientist', 'responsible', 'analyzing', 'large'],\n",
       " ['responsible', 'analyzing', 'large', 'data'],\n",
       " ['analyzing', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'develop'],\n",
       " ['data', 'sets', 'develop', 'custom'],\n",
       " ['sets', 'develop', 'custom', 'models'],\n",
       " ['develop', 'custom', 'models', 'algorithms'],\n",
       " ['custom', 'models', 'algorithms', 'drive'],\n",
       " ['models', 'algorithms', 'drive', 'business'],\n",
       " ['algorithms', 'drive', 'business', 'solutions'],\n",
       " ['drive', 'business', 'solutions', 'data'],\n",
       " ['business', 'solutions', 'data', 'scientists'],\n",
       " ['solutions', 'data', 'scientists', 'work'],\n",
       " ['data', 'scientists', 'work', 'project'],\n",
       " ['scientists', 'work', 'project', 'teams'],\n",
       " ['work', 'project', 'teams', 'order'],\n",
       " ['project', 'teams', 'order', 'provide'],\n",
       " ['teams', 'order', 'provide', 'analytical'],\n",
       " ['order', 'provide', 'analytical', 'support'],\n",
       " ['provide', 'analytical', 'support', 'projects'],\n",
       " ['analytical', 'support', 'projects', 'walmart'],\n",
       " ['support', 'projects', 'walmart', 'ecommerce'],\n",
       " ['projects', 'walmart', 'ecommerce', 'data'],\n",
       " ['walmart', 'ecommerce', 'data', 'scientists'],\n",
       " ['ecommerce', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'building'],\n",
       " ['scientists', 'responsible', 'building', 'large'],\n",
       " ['responsible', 'building', 'large', 'data'],\n",
       " ['building', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'multiple'],\n",
       " ['data', 'sets', 'multiple', 'sources'],\n",
       " ['sets', 'multiple', 'sources', 'order'],\n",
       " ['multiple', 'sources', 'order', 'build'],\n",
       " ['sources', 'order', 'build', 'algorithms'],\n",
       " ['order', 'build', 'algorithms', 'predicting'],\n",
       " ['build', 'algorithms', 'predicting', 'future'],\n",
       " ['algorithms', 'predicting', 'future', 'data'],\n",
       " ['predicting', 'future', 'data', 'characteristics'],\n",
       " ['future', 'data', 'characteristics', 'algorithms'],\n",
       " ['data', 'characteristics', 'algorithms', 'tested'],\n",
       " ['characteristics', 'algorithms', 'tested', 'validated'],\n",
       " ['algorithms', 'tested', 'validated', 'applied'],\n",
       " ['tested', 'validated', 'applied', 'large'],\n",
       " ['validated', 'applied', 'large', 'data'],\n",
       " ['applied', 'large', 'data', 'sets'],\n",
       " ['large', 'data', 'sets', 'data'],\n",
       " ['data', 'sets', 'data', 'scientists'],\n",
       " ['sets', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'training'],\n",
       " ['scientists', 'responsible', 'training', 'algorithms'],\n",
       " ['responsible', 'training', 'algorithms', 'applied'],\n",
       " ['training', 'algorithms', 'applied', 'future'],\n",
       " ['algorithms', 'applied', 'future', 'data'],\n",
       " ['applied', 'future', 'data', 'sets'],\n",
       " ['future', 'data', 'sets', 'provide'],\n",
       " ['data', 'sets', 'provide', 'appropriate'],\n",
       " ['sets', 'provide', 'appropriate', 'search'],\n",
       " ['provide', 'appropriate', 'search', 'results'],\n",
       " ['appropriate', 'search', 'results', 'data'],\n",
       " ['search', 'results', 'data', 'scientists'],\n",
       " ['results', 'data', 'scientists', 'responsible'],\n",
       " ['data', 'scientists', 'responsible', 'researching'],\n",
       " ['scientists', 'responsible', 'researching', 'new'],\n",
       " ['responsible', 'researching', 'new', 'trends'],\n",
       " ['researching', 'new', 'trends', 'industry'],\n",
       " ['new', 'trends', 'industry', 'utilizing'],\n",
       " ['trends', 'industry', 'utilizing', 'uptodate'],\n",
       " ['industry', 'utilizing', 'uptodate', 'technology'],\n",
       " ['utilizing', 'uptodate', 'technology', 'interpret'],\n",
       " ['uptodate', 'technology', 'interpret', 'apply'],\n",
       " ['technology', 'interpret', 'apply', 'data'],\n",
       " ['interpret', 'apply', 'data', 'analyses'],\n",
       " ['apply', 'data', 'analyses', 'explain'],\n",
       " ['data', 'analyses', 'explain', 'findings'],\n",
       " ['analyses', 'explain', 'findings', 'business'],\n",
       " ['explain', 'findings', 'business', 'audiences'],\n",
       " ['findings', 'business', 'audiences', 'improve'],\n",
       " ['business', 'audiences', 'improve', 'products'],\n",
       " ['audiences', 'improve', 'products', 'processes'],\n",
       " ['improve', 'products', 'processes', 'support'],\n",
       " ['products', 'processes', 'support', 'business'],\n",
       " ['processes', 'support', 'business', 'decision'],\n",
       " ['support', 'business', 'decision', 'making'],\n",
       " ['business', 'decision', 'making', 'design'],\n",
       " ['decision', 'making', 'design', 'create'],\n",
       " ['making', 'design', 'create', 'implement'],\n",
       " ['design', 'create', 'implement', 'manage'],\n",
       " ['create', 'implement', 'manage', 'predictive'],\n",
       " ['implement', 'manage', 'predictive', 'analytics'],\n",
       " ['manage', 'predictive', 'analytics', 'leverage'],\n",
       " ['predictive', 'analytics', 'leverage', 'large'],\n",
       " ['analytics', 'leverage', 'large', 'varied'],\n",
       " ['leverage', 'large', 'varied', 'datasets'],\n",
       " ['large', 'varied', 'datasets', 'using'],\n",
       " ['varied', 'datasets', 'using', 'wide'],\n",
       " ['datasets', 'using', 'wide', 'range'],\n",
       " ['using', 'wide', 'range', 'analytical'],\n",
       " ['wide', 'range', 'analytical', 'tools'],\n",
       " ['range', 'analytical', 'tools', 'methods'],\n",
       " ['analytical', 'tools', 'methods', 'platforms'],\n",
       " ['tools', 'methods', 'platforms', 'interpret'],\n",
       " ['methods', 'platforms', 'interpret', 'apply'],\n",
       " ['platforms', 'interpret', 'apply', 'data'],\n",
       " ['interpret', 'apply', 'data', 'analytics'],\n",
       " ['apply', 'data', 'analytics', 'provide'],\n",
       " ['data', 'analytics', 'provide', 'recommendations'],\n",
       " ['analytics', 'provide', 'recommendations', 'business'],\n",
       " ['provide', 'recommendations', 'business', 'implement'],\n",
       " ['recommendations', 'business', 'implement', 'activities'],\n",
       " ['business', 'implement', 'activities', 'impact'],\n",
       " ['implement', 'activities', 'impact', 'singular'],\n",
       " ['activities', 'impact', 'singular', 'work'],\n",
       " ['impact', 'singular', 'work', 'develop'],\n",
       " ['singular', 'work', 'develop', 'execute'],\n",
       " ['work', 'develop', 'execute', 'statistical'],\n",
       " ['develop', 'execute', 'statistical', 'mathematical'],\n",
       " ['execute', 'statistical', 'mathematical', 'solutions'],\n",
       " ['statistical', 'mathematical', 'solutions', 'business'],\n",
       " ['mathematical', 'solutions', 'business', 'problems'],\n",
       " ['solutions', 'business', 'problems', 'frame'],\n",
       " ['business', 'problems', 'frame', 'problems'],\n",
       " ['problems', 'frame', 'problems', 'determine'],\n",
       " ['frame', 'problems', 'determine', 'intended'],\n",
       " ['problems', 'determine', 'intended', 'approach'],\n",
       " ['determine', 'intended', 'approach', 'quantitative'],\n",
       " ['intended', 'approach', 'quantitative', 'methods'],\n",
       " ['approach', 'quantitative', 'methods', 'develop'],\n",
       " ['quantitative', 'methods', 'develop', 'solution'],\n",
       " ['methods', 'develop', 'solution', 'using'],\n",
       " ['develop', 'solution', 'using', 'analytical'],\n",
       " ['solution', 'using', 'analytical', 'rigor'],\n",
       " ['using', 'analytical', 'rigor', 'statistical'],\n",
       " ['analytical', 'rigor', 'statistical', 'methods'],\n",
       " ['rigor', 'statistical', 'methods', 'analyze'],\n",
       " ['statistical', 'methods', 'analyze', 'large'],\n",
       " ['methods', 'analyze', 'large', 'amounts'],\n",
       " ['analyze', 'large', 'amounts', 'data'],\n",
       " ['large', 'amounts', 'data', 'actionable'],\n",
       " ['amounts', 'data', 'actionable', 'insights'],\n",
       " ['data', 'actionable', 'insights', 'using'],\n",
       " ['actionable', 'insights', 'using', 'advanced'],\n",
       " ['insights', 'using', 'advanced', 'statistical'],\n",
       " ['using', 'advanced', 'statistical', 'techniques'],\n",
       " ['advanced', 'statistical', 'techniques', 'predictive'],\n",
       " ['statistical', 'techniques', 'predictive', 'statistical'],\n",
       " ['techniques', 'predictive', 'statistical', 'models'],\n",
       " ['predictive', 'statistical', 'models', 'customer'],\n",
       " ['statistical', 'models', 'customer', 'profiling'],\n",
       " ['models', 'customer', 'profiling', 'segmentation'],\n",
       " ['customer', 'profiling', 'segmentation', 'analysis'],\n",
       " ['profiling', 'segmentation', 'analysis', 'survey'],\n",
       " ['segmentation', 'analysis', 'survey', 'design'],\n",
       " ['analysis', 'survey', 'design', 'analysis'],\n",
       " ['survey', 'design', 'analysis', 'data'],\n",
       " ['design', 'analysis', 'data', 'mining'],\n",
       " ['analysis', 'data', 'mining', 'design'],\n",
       " ['data', 'mining', 'design', 'experiments'],\n",
       " ['mining', 'design', 'experiments', 'answer'],\n",
       " ['design', 'experiments', 'answer', 'targeted'],\n",
       " ['experiments', 'answer', 'targeted', 'questions'],\n",
       " ['answer', 'targeted', 'questions', 'document'],\n",
       " ['targeted', 'questions', 'document', 'projects'],\n",
       " ['questions', 'document', 'projects', 'including'],\n",
       " ['document', 'projects', 'including', 'business'],\n",
       " ['projects', 'including', 'business', 'objectives'],\n",
       " ['including', 'business', 'objectives', 'data'],\n",
       " ['business', 'objectives', 'data', 'gathering'],\n",
       " ['objectives', 'data', 'gathering', 'processing'],\n",
       " ['data', 'gathering', 'processing', 'leading'],\n",
       " ['gathering', 'processing', 'leading', 'approaches'],\n",
       " ['processing', 'leading', 'approaches', 'final'],\n",
       " ['leading', 'approaches', 'final', 'algorithms'],\n",
       " ['approaches', 'final', 'algorithms', 'detailed'],\n",
       " ['final', 'algorithms', 'detailed', 'set'],\n",
       " ['algorithms', 'detailed', 'set', 'results'],\n",
       " ['detailed', 'set', 'results', 'analytical'],\n",
       " ['set', 'results', 'analytical', 'metrics'],\n",
       " ['results', 'analytical', 'metrics', 'develop'],\n",
       " ['analytical', 'metrics', 'develop', 'materials'],\n",
       " ['metrics', 'develop', 'materials', 'explain'],\n",
       " ['develop', 'materials', 'explain', 'project'],\n",
       " ['materials', 'explain', 'project', 'findings'],\n",
       " ['explain', 'project', 'findings', 'management'],\n",
       " ['project', 'findings', 'management', 'develop'],\n",
       " ['findings', 'management', 'develop', 'new'],\n",
       " ['management', 'develop', 'new', 'algorithms'],\n",
       " ['develop', 'new', 'algorithms', 'mathematical'],\n",
       " ['new', 'algorithms', 'mathematical', 'approaches'],\n",
       " ['algorithms', 'mathematical', 'approaches', 'understand'],\n",
       " ['mathematical', 'approaches', 'understand', 'companys'],\n",
       " ['approaches', 'understand', 'companys', 'audiences'],\n",
       " ['understand', 'companys', 'audiences', 'solve'],\n",
       " ['companys', 'audiences', 'solve', 'complex'],\n",
       " ['audiences', 'solve', 'complex', 'business'],\n",
       " ['solve', 'complex', 'business', 'problems'],\n",
       " ['complex', 'business', 'problems', 'optimizing'],\n",
       " ['business', 'problems', 'optimizing', 'product'],\n",
       " ['problems', 'optimizing', 'product', 'performance'],\n",
       " ['optimizing', 'product', 'performance', 'review'],\n",
       " ['product', 'performance', 'review', 'adoption'],\n",
       " ['performance', 'review', 'adoption', 'make'],\n",
       " ['review', 'adoption', 'make', 'tactical'],\n",
       " ['adoption', 'make', 'tactical', 'decisions'],\n",
       " ['make', 'tactical', 'decisions', 'driven'],\n",
       " ['tactical', 'decisions', 'driven', 'priorities'],\n",
       " ['decisions', 'driven', 'priorities', 'project'],\n",
       " ['driven', 'priorities', 'project', 'fall'],\n",
       " ['priorities', 'project', 'fall', 'within'],\n",
       " ['project', 'fall', 'within', 'defined'],\n",
       " ['fall', 'within', 'defined', 'procedures'],\n",
       " ['within', 'defined', 'procedures', 'communicate'],\n",
       " ['defined', 'procedures', 'communicate', 'manager'],\n",
       " ['procedures', 'communicate', 'manager', 'status'],\n",
       " ['communicate', 'manager', 'status', 'issues'],\n",
       " ['manager', 'status', 'issues', 'decisions'],\n",
       " ['status', 'issues', 'decisions', 'create'],\n",
       " ['issues', 'decisions', 'create', 'deliver'],\n",
       " ['decisions', 'create', 'deliver', 'presentations'],\n",
       " ['create', 'deliver', 'presentations', 'communication'],\n",
       " ['deliver', 'presentations', 'communication', 'managers'],\n",
       " ['presentations', 'communication', 'managers', 'external'],\n",
       " ['communication', 'managers', 'external', 'partners'],\n",
       " ['managers', 'external', 'partners', 'issues'],\n",
       " ['external', 'partners', 'issues', 'defined'],\n",
       " ['partners', 'issues', 'defined', 'best'],\n",
       " ['issues', 'defined', 'best', 'practices'],\n",
       " ['defined', 'best', 'practices', 'masters'],\n",
       " ['best', 'practices', 'masters', 'degree'],\n",
       " ['practices', 'masters', 'degree', 'foreign'],\n",
       " ['masters', 'degree', 'foreign', 'equivalent'],\n",
       " ['degree', 'foreign', 'equivalent', 'management'],\n",
       " ['foreign', 'equivalent', 'management', 'information'],\n",
       " ['equivalent', 'management', 'information', 'systems'],\n",
       " ['management', 'information', 'systems', 'computer'],\n",
       " ['information', 'systems', 'computer', 'science'],\n",
       " ['systems', 'computer', 'science', 'data'],\n",
       " ['computer', 'science', 'data', 'science'],\n",
       " ['science', 'data', 'science', 'software'],\n",
       " ['data', 'science', 'software', 'engineering'],\n",
       " ['science', 'software', 'engineering', 'related'],\n",
       " ['software', 'engineering', 'related', 'field'],\n",
       " ['engineering', 'related', 'field', 'lieu'],\n",
       " ['related', 'field', 'lieu', 'masters'],\n",
       " ['field', 'lieu', 'masters', 'degree'],\n",
       " ['lieu', 'masters', 'degree', 'foreign'],\n",
       " ['masters', 'degree', 'foreign', 'equivalent'],\n",
       " ['degree', 'foreign', 'equivalent', 'management'],\n",
       " ['foreign', 'equivalent', 'management', 'information'],\n",
       " ['equivalent', 'management', 'information', 'systems'],\n",
       " ['management', 'information', 'systems', 'computer'],\n",
       " ['information', 'systems', 'computer', 'science'],\n",
       " ['systems', 'computer', 'science', 'data'],\n",
       " ['computer', 'science', 'data', 'science'],\n",
       " ['science', 'data', 'science', 'software'],\n",
       " ['data', 'science', 'software', 'engineering'],\n",
       " ['science', 'software', 'engineering', 'related'],\n",
       " ['software', 'engineering', 'related', 'field'],\n",
       " ['engineering', 'related', 'field', 'employer'],\n",
       " ['related', 'field', 'employer', 'accept'],\n",
       " ['field', 'employer', 'accept', 'bachelors'],\n",
       " ['employer', 'accept', 'bachelors', 'degree'],\n",
       " ['accept', 'bachelors', 'degree', 'foreign'],\n",
       " ['bachelors', 'degree', 'foreign', 'equivalent'],\n",
       " ['degree', 'foreign', 'equivalent', 'management'],\n",
       " ['foreign', 'equivalent', 'management', 'information'],\n",
       " ['equivalent', 'management', 'information', 'systems'],\n",
       " ['management', 'information', 'systems', 'computer'],\n",
       " ['information', 'systems', 'computer', 'science'],\n",
       " ['systems', 'computer', 'science', 'data'],\n",
       " ['computer', 'science', 'data', 'science'],\n",
       " ['science', 'data', 'science', 'software'],\n",
       " ['data', 'science', 'software', 'engineering'],\n",
       " ['science', 'software', 'engineering', 'related'],\n",
       " ['software', 'engineering', 'related', 'field'],\n",
       " ['engineering', 'related', 'field', 'plus'],\n",
       " ['related', 'field', 'plus', 'years'],\n",
       " ['field', 'plus', 'years', 'experience'],\n",
       " ['plus', 'years', 'experience', 'job'],\n",
       " ['years', 'experience', 'job', 'offered'],\n",
       " ['experience', 'job', 'offered', 'related'],\n",
       " ['job', 'offered', 'related', 'position'],\n",
       " ['offered', 'related', 'position', 'also'],\n",
       " ['related', 'position', 'also', 'requires'],\n",
       " ['position', 'also', 'requires', 'demonstrated'],\n",
       " ['also', 'requires', 'demonstrated', 'coursework'],\n",
       " ['requires', 'demonstrated', 'coursework', 'project'],\n",
       " ['demonstrated', 'coursework', 'project', 'background'],\n",
       " ['coursework', 'project', 'background', 'following'],\n",
       " ['project', 'background', 'following', 'data'],\n",
       " ['background', 'following', 'data', 'science'],\n",
       " ['following', 'data', 'science', 'data'],\n",
       " ['data', 'science', 'data', 'analytics'],\n",
       " ['science', 'data', 'analytics', 'data'],\n",
       " ['data', 'analytics', 'data', 'manipulation'],\n",
       " ['analytics', 'data', 'manipulation', 'data'],\n",
       " ['data', 'manipulation', 'data', 'visualization'],\n",
       " ['manipulation', 'data', 'visualization', 'apply'],\n",
       " ['data', 'visualization', 'apply', 'mail'],\n",
       " ['visualization', 'apply', 'mail', 'resume'],\n",
       " ['apply', 'mail', 'resume', 'dr'],\n",
       " ['mail', 'resume', 'dr', 'falls'],\n",
       " ['resume', 'dr', 'falls', 'wi'],\n",
       " ['dr', 'falls', 'wi', 'job'],\n",
       " ['falls', 'wi', 'job', 'title'],\n",
       " ['wi', 'job', 'title', 'online'],\n",
       " ['job', 'title', 'online', 'at'],\n",
       " ['title', 'online', 'at', 'position'],\n",
       " ['online', 'at', 'position', 'description'],\n",
       " ['at', 'position', 'description', 'understands'],\n",
       " ['position', 'description', 'understands', 'translates'],\n",
       " ['description', 'understands', 'translates', 'business'],\n",
       " ['understands', 'translates', 'business', 'functional'],\n",
       " ['translates', 'business', 'functional', 'needs'],\n",
       " ['business', 'functional', 'needs', 'data'],\n",
       " ['functional', 'needs', 'data', 'scientist'],\n",
       " ['needs', 'data', 'scientist', 'problem'],\n",
       " ['data', 'scientist', 'problem', 'statements'],\n",
       " ['scientist', 'problem', 'statements', 'build'],\n",
       " ['problem', 'statements', 'build', 'complex'],\n",
       " ['statements', 'build', 'complex', 'data'],\n",
       " ['build', 'complex', 'data', 'sets'],\n",
       " ['complex', 'data', 'sets', 'multiple'],\n",
       " ['data', 'sets', 'multiple', 'data'],\n",
       " ['sets', 'multiple', 'data', 'sources'],\n",
       " ['multiple', 'data', 'sources', 'internally'],\n",
       " ['data', 'sources', 'internally', 'externally'],\n",
       " ['sources', 'internally', 'externally', 'develop'],\n",
       " ['internally', 'externally', 'develop', 'custom'],\n",
       " ['externally', 'develop', 'custom', 'data'],\n",
       " ['develop', 'custom', 'data', 'models'],\n",
       " ['custom', 'data', 'models', 'drive'],\n",
       " ['data', 'models', 'drive', 'innovative'],\n",
       " ['models', 'drive', 'innovative', 'business'],\n",
       " ['drive', 'innovative', 'business', 'solutions'],\n",
       " ['innovative', 'business', 'solutions', 'write'],\n",
       " ['business', 'solutions', 'write', 'complex'],\n",
       " ['solutions', 'write', 'complex', 'queries'],\n",
       " ['write', 'complex', 'queries', 'extract'],\n",
       " ['complex', 'queries', 'extract', 'data'],\n",
       " ['queries', 'extract', 'data', 'build'],\n",
       " ['extract', 'data', 'build', 'database'],\n",
       " ['data', 'build', 'database', 'architecture'],\n",
       " ['build', 'database', 'architecture', 'integrate'],\n",
       " ['database', 'architecture', 'integrate', 'data'],\n",
       " ['architecture', 'integrate', 'data', 'products'],\n",
       " ['integrate', 'data', 'products', 'dashboards'],\n",
       " ['data', 'products', 'dashboards', 'user'],\n",
       " ['products', 'dashboards', 'user', 'interfaces'],\n",
       " ['dashboards', 'user', 'interfaces', 'needed'],\n",
       " ['user', 'interfaces', 'needed', 'collaborating'],\n",
       " ['interfaces', 'needed', 'collaborating', 'engineering'],\n",
       " ['needed', 'collaborating', 'engineering', 'team'],\n",
       " ['collaborating', 'engineering', 'team', 'sift'],\n",
       " ['engineering', 'team', 'sift', 'analyze'],\n",
       " ['team', 'sift', 'analyze', 'data'],\n",
       " ['sift', 'analyze', 'data', 'multiple'],\n",
       " ['analyze', 'data', 'multiple', 'angles'],\n",
       " ['data', 'multiple', 'angles', 'looking'],\n",
       " ['multiple', 'angles', 'looking', 'trends'],\n",
       " ['angles', 'looking', 'trends', 'highlight'],\n",
       " ['looking', 'trends', 'highlight', 'problems'],\n",
       " ['trends', 'highlight', 'problems', 'opportunities'],\n",
       " ['highlight', 'problems', 'opportunities', 'use'],\n",
       " ['problems', 'opportunities', 'use', 'strong'],\n",
       " ['opportunities', 'use', 'strong', 'business'],\n",
       " ['use', 'strong', 'business', 'acumen'],\n",
       " ['strong', 'business', 'acumen', 'well'],\n",
       " ['business', 'acumen', 'well', 'ability'],\n",
       " ['acumen', 'well', 'ability', 'communicate'],\n",
       " ['well', 'ability', 'communicate', 'findings'],\n",
       " ['ability', 'communicate', 'findings', 'mine'],\n",
       " ['communicate', 'findings', 'mine', 'vast'],\n",
       " ['findings', 'mine', 'vast', 'amounts'],\n",
       " ['mine', 'vast', 'amounts', 'data'],\n",
       " ['vast', 'amounts', 'data', 'useful'],\n",
       " ['amounts', 'data', 'useful', 'insights'],\n",
       " ['data', 'useful', 'insights', 'apply'],\n",
       " ['useful', 'insights', 'apply', 'innovative'],\n",
       " ['insights', 'apply', 'innovative', 'analytical'],\n",
       " ['apply', 'innovative', 'analytical', 'approaches'],\n",
       " ['innovative', 'analytical', 'approaches', 'draw'],\n",
       " ['analytical', 'approaches', 'draw', 'conclusions'],\n",
       " ['approaches', 'draw', 'conclusions', 'make'],\n",
       " ['draw', 'conclusions', 'make', 'recommendations'],\n",
       " ['conclusions', 'make', 'recommendations', 'answer'],\n",
       " ['make', 'recommendations', 'answer', 'business'],\n",
       " ['recommendations', 'answer', 'business', 'proficiency'],\n",
       " ['answer', 'business', 'proficiency', 'machine'],\n",
       " ['business', 'proficiency', 'machine', 'learning'],\n",
       " ['proficiency', 'machine', 'learning', 'algorithms'],\n",
       " ['machine', 'learning', 'algorithms', 'classifications'],\n",
       " ['learning', 'algorithms', 'classifications', 'decision'],\n",
       " ['algorithms', 'classifications', 'decision', 'trees'],\n",
       " ['classifications', 'decision', 'trees', 'support'],\n",
       " ['decision', 'trees', 'support', 'vector'],\n",
       " ['trees', 'support', 'vector', 'machines'],\n",
       " ['support', 'vector', 'machines', 'deep'],\n",
       " ['vector', 'machines', 'deep', 'learning'],\n",
       " ['machines', 'deep', 'learning', 'strong'],\n",
       " ['deep', 'learning', 'strong', 'understanding'],\n",
       " ['learning', 'strong', 'understanding', 'probability'],\n",
       " ['strong', 'understanding', 'probability', 'statistical'],\n",
       " ['understanding', 'probability', 'statistical', 'models'],\n",
       " ['probability', 'statistical', 'models', 'generative'],\n",
       " ['statistical', 'models', 'generative', 'descriptive'],\n",
       " ['models', 'generative', 'descriptive', 'models'],\n",
       " ['generative', 'descriptive', 'models', 'ability'],\n",
       " ['descriptive', 'models', 'ability', 'run'],\n",
       " ['models', 'ability', 'run', 'experiments'],\n",
       " ['ability', 'run', 'experiments', 'scientifically'],\n",
       " ['run', 'experiments', 'scientifically', 'analyze'],\n",
       " ['experiments', 'scientifically', 'analyze', 'results'],\n",
       " ['scientifically', 'analyze', 'results', 'ability'],\n",
       " ['analyze', 'results', 'ability', 'effectively'],\n",
       " ['results', 'ability', 'effectively', 'communicate'],\n",
       " ['ability', 'effectively', 'communicate', 'technical'],\n",
       " ['effectively', 'communicate', 'technical', 'concepts'],\n",
       " ['communicate', 'technical', 'concepts', 'results'],\n",
       " ['technical', 'concepts', 'results', 'technical'],\n",
       " ['concepts', 'results', 'technical', 'business'],\n",
       " ['results', 'technical', 'business', 'audiences'],\n",
       " ['technical', 'business', 'audiences', 'comprehensive'],\n",
       " ['business', 'audiences', 'comprehensive', 'manner'],\n",
       " ['audiences', 'comprehensive', 'manner', 'ability'],\n",
       " ['comprehensive', 'manner', 'ability', 'collaborate'],\n",
       " ['manner', 'ability', 'collaborate', 'effectively'],\n",
       " ['ability', 'collaborate', 'effectively', 'across'],\n",
       " ['collaborate', 'effectively', 'across', 'multiple'],\n",
       " ['effectively', 'across', 'multiple', 'teams'],\n",
       " ['across', 'multiple', 'teams', 'stakeholders'],\n",
       " ['multiple', 'teams', 'stakeholders', 'including'],\n",
       " ['teams', 'stakeholders', 'including', 'analytics'],\n",
       " ['stakeholders', 'including', 'analytics', 'teams'],\n",
       " ['including', 'analytics', 'teams', 'development'],\n",
       " ['analytics', 'teams', 'development', 'teams'],\n",
       " ['teams', 'development', 'teams', 'product'],\n",
       " ['development', 'teams', 'product', 'management'],\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:09.656942Z",
     "start_time": "2019-12-29T14:26:09.654096Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:19.486382Z",
     "start_time": "2019-12-29T14:26:12.233453Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english') + list(string.punctuation)\n",
    "# stop += [\"''\", '\"\"', '...', '``','--']\n",
    "# data = data.apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences) \n",
    "\n",
    "#Collecting some information   \n",
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
    "for i in range(len(sequences)):\n",
    "    n_sequences[i] = sequences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:21.000327Z",
     "start_time": "2019-12-29T14:26:20.996001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7492"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:24.660565Z",
     "start_time": "2019-12-29T14:26:24.657495Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs = n_sequences[:,:-1]\n",
    "train_targets = n_sequences[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:31.556253Z",
     "start_time": "2019-12-29T14:26:31.543009Z"
    }
   },
   "outputs": [],
   "source": [
    "train_targets = train_targets.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:32.184615Z",
     "start_time": "2019-12-29T14:26:32.178992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 2.170e+02, 1.480e+02, ..., 1.800e+03, 1.369e+03,\n",
       "       9.240e+02], dtype=float16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:38.694409Z",
     "start_time": "2019-12-29T14:26:37.283519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1215717, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_targets = to_categorical(train_targets, num_classes=vocabulary_size+1)\n",
    "seq_len = train_inputs.shape[1]\n",
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:49.764189Z",
     "start_time": "2019-12-29T14:26:49.761168Z"
    }
   },
   "outputs": [],
   "source": [
    "# The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "# It is a flexible layer that can be used in a variety of ways, such as:\n",
    "# It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
    "# It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "# It can be used to load a pre-trained word embedding model, a type of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:50.235716Z",
     "start_time": "2019-12-29T14:26:50.231612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7492"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:26:50.678000Z",
     "start_time": "2019-12-29T14:26:50.673183Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    opt_adam = optimizers.adam(lr=0.01)\n",
    "    #You can simply pass 'adam' to optimizer in compile method. Default learning rate 0.001\n",
    "    #But here we are using adam optimzer from optimizer class to change the LR.\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt_adam,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:28:10.254876Z",
     "start_time": "2019-12-29T14:27:11.748260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3, 3)              22479     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3, 50)             10800     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7493)              382143    \n",
      "=================================================================\n",
      "Total params: 438,172\n",
      "Trainable params: 438,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      " 118912/1215717 [=>............................] - ETA: 8:43 - loss: 7.3424 - acc: 0.0235"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-053c7a4511e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoint1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# pickle.dump(tokenizer,open('tokenizer_Model4','wb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)\n",
    "path = 'checkpoint1'\n",
    "checkpoint = ModelCheckpoint(path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(train_inputs,train_targets,batch_size=128,epochs=3,verbose=1,callbacks=[checkpoint])\n",
    "# pickle.dump(tokenizer,open('tokenizer_Model4','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoint1')\n",
    "# tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "seq_len = 3 \n",
    "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' '+pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)\n",
    "\n",
    "print('\\n\\n===>Enter --exit to exit from the program')\n",
    "while True:\n",
    "    seed_text  = input('Enter string: ')\n",
    "    if seed_text.lower() == '--exit':\n",
    "        break\n",
    "    else:\n",
    "        out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=5)\n",
    "        print('Output: '+seed_text+' '+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoint4')\n",
    "# tokenizer = pickle.load(open('tokenizer_Model4','rb'))\n",
    "seq_len = 3 \n",
    "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        targets = str()\n",
    "        for word in pred_word:\n",
    "            if word in search_terms:\n",
    "                targets+word\n",
    "                \n",
    "        input_text += ' '+targets\n",
    "        output_text.append(targets)\n",
    "    return ' '.join(output_text)\n",
    "\n",
    "print('\\n\\n===>Enter --exit to exit from the program')\n",
    "while True:\n",
    "    seed_text  = input('Enter string: ')\n",
    "    if seed_text.lower() == '--exit':\n",
    "        break\n",
    "    else:\n",
    "        out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=5)\n",
    "        print('Output: '+seed_text+' '+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df.title\n",
    "# data = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_target = set(target)\n",
    "# target_classes = len(total_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_vocabulary = set(word for description in data for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(total_vocabulary)\n",
    "# print(\"There are {} unique tokens in the dataset.\".format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove = {}\n",
    "# with open('glove.6B.50d.txt', 'rb') as f:\n",
    "#     for line in f:\n",
    "#         parts = line.split()\n",
    "#         word = parts[0].decode('utf-8')\n",
    "#         if word in total_vocabulary:\n",
    "#             vector = np.array(parts[1:], dtype=np.float32)\n",
    "#             glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove['java']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class W2vVectorizer(object):\n",
    "    \n",
    "#     def __init__(self, w2v):\n",
    "#         # takes in a dictionary of words and vectors as input\n",
    "#         self.w2v = w2v\n",
    "#         if len(w2v) == 0:\n",
    "#             self.dimensions = 0\n",
    "#         else:\n",
    "#             self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "#     # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "#     # It can't be used in a sklearn Pipeline. \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "            \n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "#                    or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
