{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:29.085382Z",
     "start_time": "2019-12-20T14:19:27.361341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "import lxml\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "from collections import defaultdict, Counter\n",
    "import WebScrape_Indeed\n",
    "import WebScrape_LinkedIn\n",
    "import streamlit as st \n",
    "import terms \n",
    "import Cities \n",
    "import functions\n",
    "import time\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig\n",
    "\n",
    "import chart_studio.plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "import pydeck as pdk\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)   \n",
    "\n",
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:29.091095Z",
     "start_time": "2019-12-20T14:19:29.087355Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(raw):\n",
    "    raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    raw = nltk.regexp_tokenize(raw, pattern)\n",
    "    raw = str(raw)\n",
    "    return raw\n",
    "\n",
    "def cleanC(raw):\n",
    "    raw = ' '.join(raw.tolist())\n",
    "    for char in '-.,\\n':\n",
    "        raw = raw.replace(char,' ')\n",
    "    return raw\n",
    "\n",
    "def C_plus(raw):\n",
    "    Cplus = re.findall(r'(?i)\\bC\\+\\+(?!\\w)', str(raw))\n",
    "    return Cplus\n",
    "\n",
    "def C_sharp(raw):\n",
    "    Csharp = re.findall(r'(?i)\\bC\\#(?!\\w)', str(raw))\n",
    "    return Csharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:29.112648Z",
     "start_time": "2019-12-20T14:19:29.092737Z"
    }
   },
   "outputs": [],
   "source": [
    "one = pd.read_csv('Indeed.csv')\n",
    "one = one['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:20:37.125923Z",
     "start_time": "2019-12-20T14:20:37.012237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco, CA 94105</td>\n",
       "      <td>[     Summary       Esurance is looking for a ...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description    Data Scientist i...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kohl's</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>[  Interpret and apply data analyses and expla...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist (GEC11903)</td>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>Sunnyvale, CA 94087</td>\n",
       "      <td>[     Position Description      Understands an...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Palo Alto, CA 94304</td>\n",
       "      <td>[       Silicon Valley Bank is the market lead...</td>\n",
       "      <td>12-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>Assistant Bursar</td>\n",
       "      <td>Keiser University</td>\n",
       "      <td>Miami, FL, US</td>\n",
       "      <td>ASSISTANT BURSAR Location: Miami, FL School Na...</td>\n",
       "      <td>12-19-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>Buyer</td>\n",
       "      <td>Blue Nile</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>At  Blue Nile , we believe that love deserves ...</td>\n",
       "      <td>12-19-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>Merchant- Grains and Commodities</td>\n",
       "      <td>Southwest Iowa Renewable Energy, LLC</td>\n",
       "      <td>Greater Omaha Area</td>\n",
       "      <td>Work with a fast paced, small Commodities team...</td>\n",
       "      <td>12-19-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>Client Services Partner</td>\n",
       "      <td>Babich &amp; Associates</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>(EXCLUSIVE and CONFIDENTIAL)     CLIENT SERVIC...</td>\n",
       "      <td>12-19-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>Project Coordinator</td>\n",
       "      <td>The Parker Company</td>\n",
       "      <td>Miami, Florida, United States</td>\n",
       "      <td>The Project Coordinator will support the Proje...</td>\n",
       "      <td>12-19-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5630 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title                               company  \\\n",
       "0                       Data Scientist                              Esurance   \n",
       "1                       DATA SCIENTIST                               Walmart   \n",
       "2                       Data Scientist                                Kohl's   \n",
       "3      Staff Data Scientist (GEC11903)                     Walmart eCommerce   \n",
       "4                   Sr. Data Scientist                   Silicon Valley Bank   \n",
       "...                                ...                                   ...   \n",
       "5625                  Assistant Bursar                     Keiser University   \n",
       "5626                             Buyer                             Blue Nile   \n",
       "5627  Merchant- Grains and Commodities  Southwest Iowa Renewable Energy, LLC   \n",
       "5628           Client Services Partner                   Babich & Associates   \n",
       "5629               Project Coordinator                    The Parker Company   \n",
       "\n",
       "                                location  \\\n",
       "0                San Francisco, CA 94105   \n",
       "1                    Sunnyvale, CA 94087   \n",
       "2                     Milpitas, CA 95035   \n",
       "3                    Sunnyvale, CA 94087   \n",
       "4                    Palo Alto, CA 94304   \n",
       "...                                  ...   \n",
       "5625                       Miami, FL, US   \n",
       "5626  Seattle, Washington, United States   \n",
       "5627                  Greater Omaha Area   \n",
       "5628                       Dallas, Texas   \n",
       "5629       Miami, Florida, United States   \n",
       "\n",
       "                                            description        date  \n",
       "0     [     Summary       Esurance is looking for a ...  12-01-2019  \n",
       "1     [     Position Description    Data Scientist i...  12-01-2019  \n",
       "2     [  Interpret and apply data analyses and expla...  12-01-2019  \n",
       "3     [     Position Description      Understands an...  12-01-2019  \n",
       "4     [       Silicon Valley Bank is the market lead...  12-01-2019  \n",
       "...                                                 ...         ...  \n",
       "5625  ASSISTANT BURSAR Location: Miami, FL School Na...  12-19-2019  \n",
       "5626  At  Blue Nile , we believe that love deserves ...  12-19-2019  \n",
       "5627  Work with a fast paced, small Commodities team...  12-19-2019  \n",
       "5628  (EXCLUSIVE and CONFIDENTIAL)     CLIENT SERVIC...  12-19-2019  \n",
       "5629  The Project Coordinator will support the Proje...  12-19-2019  \n",
       "\n",
       "[5630 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtotal = pd.read_csv('total_data_date.csv')\n",
    "dtotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:30.191246Z",
     "start_time": "2019-12-20T14:19:29.114523Z"
    }
   },
   "outputs": [],
   "source": [
    "search_terms = terms.total_terms\n",
    "\n",
    "# st.title('Skill Distribution + Trends')\n",
    "\n",
    "option1 = 'Data Engineer'\n",
    "\n",
    "\n",
    "dtotal_full = dtotal['description']\n",
    "dtotal_full = clean(dtotal_full)\n",
    "dtotal1a= dtotal[dtotal['title'].astype(str).str.contains(option1)]\n",
    "dtotal1b = dtotal1a['description']\n",
    "dtotal1c = clean(dtotal1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:30.312708Z",
     "start_time": "2019-12-20T14:19:30.193764Z"
    }
   },
   "outputs": [],
   "source": [
    "option2 = 'Data Analyst'\n",
    "\n",
    "dtotal2a= dtotal[dtotal['title'].astype(str).str.contains(option2)]\n",
    "dtotal2b = dtotal2a['description']\n",
    "dtotal2c = clean(dtotal2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:30.510009Z",
     "start_time": "2019-12-20T14:19:30.315006Z"
    }
   },
   "outputs": [],
   "source": [
    "option3 = 'Data Scientist'\n",
    "\n",
    "dtotal3a= dtotal[dtotal['title'].astype(str).str.contains(option3)]\n",
    "dtotal3b = dtotal3a['description']\n",
    "dtotal3c = clean(dtotal3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:30.642652Z",
     "start_time": "2019-12-20T14:19:30.511848Z"
    }
   },
   "outputs": [],
   "source": [
    "option4 = 'Software Engineer'\n",
    "\n",
    "dtotal4a= dtotal[dtotal['title'].astype(str).str.contains(option4)]\n",
    "dtotal4b = dtotal4a['description']\n",
    "dtotal4c = clean(dtotal4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:19:32.059005Z",
     "start_time": "2019-12-20T14:19:30.644272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [3], 1: [0, 1, 2]}\n"
     ]
    }
   ],
   "source": [
    "def cluster_texts(texts, clusters=2):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(tokenizer=None,\n",
    "                                 stop_words=stopwords.words('english'),\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=0.0,\n",
    "                                 lowercase=True)\n",
    " \n",
    "    tfidf_model = vectorizer.fit_transform(texts)\n",
    "    km = KMeans(n_clusters=clusters)\n",
    "    km.fit(tfidf_model)\n",
    " \n",
    "    clustering = collections.defaultdict(list)\n",
    " \n",
    "    for idx, label in enumerate(km.labels_):\n",
    "        clustering[label].append(idx)\n",
    " \n",
    "    return clustering\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    articles = [dtotal1c,dtotal2c,dtotal3c,dtotal4c]\n",
    "    clusters = cluster_texts(articles, 2)\n",
    "    pprint(dict(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cluster_texts(texts, clusters=2):\n",
    "#     \"\"\" Transform texts to Tf-Idf coordinates and cluster texts using K-Means \"\"\"\n",
    "#     vectorizer = TfidfVectorizer(tokenizer=None,\n",
    "#                                  stop_words=stopwords.words('english'),\n",
    "#                                  max_df=1.0,\n",
    "#                                  min_df=0.0,\n",
    "#                                  lowercase=True)\n",
    " \n",
    "#     tfidf_model = vectorizer.fit_transform(texts)\n",
    "#     km = KMeans(n_clusters=clusters, max_iter=100)\n",
    "#     km.fit(tfidf_model)\n",
    "# #     centroids = km.centroids\n",
    " \n",
    "#     clustering = collections.defaultdict(list)\n",
    " \n",
    "#     for idx, label in enumerate(km.labels_):\n",
    "#         clustering[label].append(idx)\n",
    " \n",
    "#     return clustering\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [dtotal1c,dtotal2c,dtotal3c,dtotal4c]\n",
    "# clusters = cluster_texts(articles, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=None,\n",
    "                                 stop_words=stopwords.words('english'),\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=0.0,\n",
    "                                 lowercase=True)\n",
    " \n",
    "X = vectorizer.fit_transform(articles)\n",
    "km = KMeans(n_clusters=3, max_iter=100)\n",
    "km.fit(X)\n",
    "# y_hat = km.predict(X)\n",
    "\n",
    "clustering = collections.defaultdict(list)\n",
    " \n",
    "for idx, label in enumerate(km.labels_):\n",
    "    clustering[label].append(idx)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    articles = [dtotal1c,dtotal2c,dtotal3c,dtotal4c]\n",
    "    clusters = cluster_texts(articles, 2)\n",
    "    pprint(dict(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c = y_hat, s = 25)\n",
    "cl_centers = km.cluster_centers_\n",
    "plt.scatter(cl_centers[:, 0], cl_centers[:, 1], s=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = km.labels_\n",
    "\n",
    "metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.calinski_harabasz_score(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# plt.scatter(tfidf_model[km.labels_], tfidf_model[km.labels_], label='cluster 1')\n",
    "# plt.scatter(tfidf_model[km.labels_ == 1, 0], tfidf_model[km.labels_ == 1, 1],c='blue', label='cluster 2')\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,c='r', label='centroid')\n",
    "# plt.legend()\n",
    "# plt.xlim([-2, 2])\n",
    "# plt.ylim([-2, 2])\n",
    "# plt.xlabel('Eruption time in mins')\n",
    "# plt.ylabel('Waiting time to next eruption')\n",
    "# plt.title('Visualization of clustered data', fontweight='bold')\n",
    "# ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(tokenizer=None,\n",
    "#                                  stop_words=stopwords.words('english'),\n",
    "#                                  max_df=1.0,\n",
    "#                                  min_df=0.0,\n",
    "#                                  lowercase=True)\n",
    " \n",
    "# tfidf_model = vectorizer.fit_transform(dtotal_full)\n",
    "# km = KMeans(n_clusters=2, max_iter=100)\n",
    "# km.fit(tfidf_model)\n",
    "# centroids = km.centroids\n",
    "\n",
    "# Plot the clustered data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_embedded = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cluster_texts_tsne(texts, nclusters=3):\n",
    "# #     vectorizer = TfidfVectorizer(tokenizer=None,\n",
    "# #                                  stop_words=stopwords.words('english'),\n",
    "# #                                  max_df=1.0,\n",
    "# #                                  min_df=0.0,\n",
    "# #                                  lowercase=True)\n",
    "    \n",
    "    \n",
    "#     tsne = TSNE(n_components=4, init='random', random_state=0)\n",
    "#     tsne_proj = tsne.fit_transform(texts)\n",
    "#     km_model = KMeans(n_clusters=nclusters, random_state=0)\n",
    "#     km_model.fit(tsne_proj)\n",
    "    \n",
    "# #     labels = np.zeros_like(clusters)\n",
    "# #     for i in range(nclusters):\n",
    "# #         mask = (clusters == i)\n",
    "# #         labels[mask] = mode(texts.target[mask])[0]\n",
    "        \n",
    "# #     accuracy_score(texts.target, labels)\n",
    " \n",
    "#     clustering = collections.defaultdict(list)\n",
    " \n",
    "#     for idx, label in enumerate(km_model.labels_):\n",
    "#         clustering[label].append(idx)\n",
    " \n",
    "#     return clustering\n",
    " \n",
    "# if __name__ == \"__main__\":\n",
    "#     articles = [dtotal1c,dtotal2c,dtotal3c,dtotal4c]\n",
    "#     clusters = cluster_texts_tsne(articles, 2)\n",
    "#     pprint(dict(clusters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
